[
    {
        "text": "Ok, correlations and causation footnotes:\nIn the main video I said that when you find",
        "start": 1.49,
        "duration": 4.02
    },
    {
        "text": "a correlation, it’s natural to look for\nexplanations or causes of it. This is called Reichenbach's Principle.",
        "start": 5.51,
        "duration": 4.9
    },
    {
        "text": "But sometimes correlations occur just by chance,\nlike those on the website “spurious correlations”",
        "start": 10.41,
        "duration": 4.78
    },
    {
        "text": "which selectively cherry-picks data points\nfrom different stats that randomly happen",
        "start": 15.19,
        "duration": 3.48
    },
    {
        "text": "to line up.",
        "start": 18.67,
        "duration": 1.0
    },
    {
        "text": "As an example of a chance correlation, if\nI flip two coins enough times, eventually",
        "start": 19.67,
        "duration": 3.929
    },
    {
        "text": "there’ll be a long string of matching heads\nor tails just by chance, and if I just cherrypick",
        "start": 23.599,
        "duration": 4.0
    },
    {
        "text": "those flips I can make it look like the coins\nare super correlated.",
        "start": 27.599,
        "duration": 3.501
    },
    {
        "text": "But when an apparent correlation is actually\nrandom in origin (like in this case), then",
        "start": 31.1,
        "duration": 4.07
    },
    {
        "text": "if you keep looking at larger and larger samples,\nthe correlation should go away.",
        "start": 35.17,
        "duration": 3.95
    },
    {
        "text": "This is it sometimes looks like particle physicists\nhave discovered a new particle, only for that",
        "start": 39.12,
        "duration": 4.29
    },
    {
        "text": "to go away when they collect more data.",
        "start": 43.41,
        "duration": 1.81
    },
    {
        "text": "Also, you may have noticed there was no mention\nof feedback loops in the main video – that’s",
        "start": 45.22,
        "duration": 4.51
    },
    {
        "text": "because, from a causal point of view, feedback\nloops, like how more grass means more sheep",
        "start": 49.73,
        "duration": 5.06
    },
    {
        "text": "means less grass means less sheep means more\ngrass and so on – from a causal point of",
        "start": 54.79,
        "duration": 4.71
    },
    {
        "text": "view, this isn’t actually a loop.",
        "start": 59.5,
        "duration": 1.61
    },
    {
        "text": "It’s more of a chain, where the amount of\ngrass and sheep now affect the amounts of",
        "start": 61.11,
        "duration": 3.96
    },
    {
        "text": "grass and sheep next year, and the year after\nand so on, so from year to year there’s",
        "start": 65.07,
        "duration": 4.38
    },
    {
        "text": "feedback between the amount of grass and the\namount of sheep which we kind of draw as a",
        "start": 69.45,
        "duration": 3.64
    },
    {
        "text": "loop, but the causal relationship always goes\nfrom the present to the future, which we should",
        "start": 73.09,
        "duration": 3.86
    },
    {
        "text": "draw as some sort of spirally helix thing.",
        "start": 76.95,
        "duration": 7.42
    }
]