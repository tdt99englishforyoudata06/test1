[
    {
        "text": "Our brief today for this panel is to explore\nthe ways in which artificial intelligence",
        "start": 8.47,
        "duration": 6.73
    },
    {
        "text": "can work for us.",
        "start": 15.2,
        "duration": 1.49
    },
    {
        "text": "Augmented intelligence is the phrase, and\nit's the benevolent face of artificial intelligence.",
        "start": 16.69,
        "duration": 8.69
    },
    {
        "text": "But let's step back for a moment for a little\nbit of history.",
        "start": 25.38,
        "duration": 4.21
    },
    {
        "text": "John J.C. Licklider was a Harvard trained\npsychologist at MIT teacher and he was the",
        "start": 29.59,
        "duration": 7.41
    },
    {
        "text": "first head of the technology office, at the\nadvanced research projects agency.",
        "start": 37.0,
        "duration": 5.59
    },
    {
        "text": "He funded some of the basic research behind\nthe personal computer and what became the",
        "start": 42.59,
        "duration": 6.57
    },
    {
        "text": "Internet.",
        "start": 49.16,
        "duration": 1.0
    },
    {
        "text": "And in 1960 he wrote a classic essay man,\ncomputer symbiosis.",
        "start": 50.16,
        "duration": 4.69
    },
    {
        "text": "And in it he said that the appropriate role\nfor computing was to augment same word, a",
        "start": 54.85,
        "duration": 9.73
    },
    {
        "text": "human knowledge and intelligence rather than\nsupplanted.",
        "start": 64.58,
        "duration": 3.49
    },
    {
        "text": "And so for decades we've been debating this\nissue back and forth, always in a new context.",
        "start": 68.07,
        "duration": 5.65
    },
    {
        "text": "And it is, the theme seems familiar.",
        "start": 73.72,
        "duration": 3.5
    },
    {
        "text": "The context today seems drastically different\nand that's what our panel is going to explore",
        "start": 77.22,
        "duration": 6.36
    },
    {
        "text": "today.",
        "start": 83.58,
        "duration": 1.0
    },
    {
        "text": "Our first guest is an IBM fellow and manager\nof Multimedia Division at IBM Watson Research",
        "start": 84.58,
        "duration": 4.49
    },
    {
        "text": "Center.",
        "start": 89.07,
        "duration": 1.0
    },
    {
        "text": "He reads IBM's research and development on\nvisual comprehension, including its use in",
        "start": 90.07,
        "duration": 6.29
    },
    {
        "text": "IBM Watson.",
        "start": 96.36,
        "duration": 1.06
    },
    {
        "text": "Please welcome John R Smith.",
        "start": 97.42,
        "duration": 6.27
    },
    {
        "text": "Next is the Arthur Zitrin professor of bioethics\nand the director of the Center for bioethics",
        "start": 103.69,
        "duration": 4.42
    },
    {
        "text": "at New York University.",
        "start": 108.11,
        "duration": 1.5
    },
    {
        "text": "He is also the author of current controversies\nin bioethics and is the editor in chief for",
        "start": 109.61,
        "duration": 6.02
    },
    {
        "text": "the Journal of moral philosophy.",
        "start": 115.63,
        "duration": 2.22
    },
    {
        "text": "Please welcome Matthew Liao.",
        "start": 117.85,
        "duration": 5.0
    },
    {
        "text": "Our next panelist is vice president for products\nand strategy for integrating AI, a Toronto",
        "start": 122.85,
        "duration": 5.1
    },
    {
        "text": "based startup.",
        "start": 127.95,
        "duration": 1.039
    },
    {
        "text": "Her company uses artificial intelligence to\nhelp businesses improve and transform customer",
        "start": 128.989,
        "duration": 4.881
    },
    {
        "text": "experiences to make those experiences more\nnatural, more human like.",
        "start": 133.87,
        "duration": 4.729
    },
    {
        "text": "Please welcome Kathryn Hume",
        "start": 138.599,
        "duration": 4.791
    },
    {
        "text": "Also joining us is a professor at the NYU\nStern School of business and it's center for",
        "start": 143.39,
        "duration": 4.48
    },
    {
        "text": "data science.",
        "start": 147.87,
        "duration": 1.55
    },
    {
        "text": "He is editor in chief of the journal big data\nand he is also the founder of set capital",
        "start": 149.42,
        "duration": 5.66
    },
    {
        "text": "management tools.",
        "start": 155.08,
        "duration": 1.2
    },
    {
        "text": "Machine learning software is used to make\nautomated trading decisions in the financial",
        "start": 156.28,
        "duration": 3.96
    },
    {
        "text": "markets.",
        "start": 160.24,
        "duration": 1.01
    },
    {
        "text": "Please welcome Vasant Dar.",
        "start": 161.25,
        "duration": 1.73
    },
    {
        "text": "So John, we'll start with you.",
        "start": 162.98,
        "duration": 3.57
    },
    {
        "text": "Give us your take on artificial intelligence\nand you what, what is different now and where",
        "start": 166.55,
        "duration": 7.0
    },
    {
        "text": "is it, where are we, where is it headed?",
        "start": 173.55,
        "duration": 2.17
    },
    {
        "text": "And give us a few examples from the work that\nIBM is doing currently since you guys have",
        "start": 175.72,
        "duration": 5.69
    },
    {
        "text": "been doing this for decades to it.",
        "start": 181.41,
        "duration": 4.47
    },
    {
        "text": "However it's been defined over the years.",
        "start": 185.88,
        "duration": 1.94
    },
    {
        "text": "Sure, so I'm a research scientist at the IBM\nand by training, you know, I'm an expert in",
        "start": 187.82,
        "duration": 6.45
    },
    {
        "text": "computer vision and at IBM, what this has\nmeant is I'm teaching Watson to see.",
        "start": 194.27,
        "duration": 7.59
    },
    {
        "text": "But let me take a step back a little bit from\nthat, there was a seminal moment more recently,",
        "start": 201.86,
        "duration": 7.53
    },
    {
        "text": "in AI and in 2011 where IBM built a computer\nsystem in a lot of ways right at the cusp",
        "start": 209.39,
        "duration": 8.77
    },
    {
        "text": "of this second push in AI that was able to\nparticipate on Jeopardy.",
        "start": 218.16,
        "duration": 7.27
    },
    {
        "text": "Not only was it able to compete against humans,\nit was able to defeat the world champions",
        "start": 225.43,
        "duration": 7.669
    },
    {
        "text": "at Jeopardy.",
        "start": 233.099,
        "duration": 2.491
    },
    {
        "text": "So this really opened the minds of a lot of\nresearchers and of course a lot of work has",
        "start": 235.59,
        "duration": 6.64
    },
    {
        "text": "continued since then.",
        "start": 242.23,
        "duration": 1.929
    },
    {
        "text": "And I think we're finding ourselves in a period\nof AI where, again, it seems like amazing",
        "start": 244.159,
        "duration": 5.94
    },
    {
        "text": "things are possible.",
        "start": 250.099,
        "duration": 2.671
    },
    {
        "text": "Since then, since 2011 of course, you know,\nwith Jeopardy all of the questions, we're",
        "start": 252.77,
        "duration": 7.279
    },
    {
        "text": "basically dealing with language.",
        "start": 260.049,
        "duration": 1.511
    },
    {
        "text": "So there were no images on Jeopardy.",
        "start": 261.56,
        "duration": 2.24
    },
    {
        "text": "However, since then the challenges around\ncomputer vision where I, where I do work around",
        "start": 263.8,
        "duration": 7.8
    },
    {
        "text": "language translation, around speech recognition,\nyou know, many perceptual tasks, AI has been",
        "start": 271.6,
        "duration": 7.56
    },
    {
        "text": "able to make really great, great advances.",
        "start": 279.16,
        "duration": 3.28
    },
    {
        "text": "And I think it's put us in a position now\nwhere we can think of many different industries",
        "start": 282.44,
        "duration": 5.93
    },
    {
        "text": "and how we can take these capabilities, which\nyou know, are now doing amazing things and",
        "start": 288.37,
        "duration": 7.93
    },
    {
        "text": "combine them together with human expertise\nto make really significant impact.",
        "start": 296.3,
        "duration": 5.28
    },
    {
        "text": "Kathryn, you've written a bit about this,\nbut what, what do you think is the biggest",
        "start": 301.58,
        "duration": 4.57
    },
    {
        "text": "misperception about artificial intelligence?",
        "start": 306.15,
        "duration": 2.12
    },
    {
        "text": "Oh God, I think there's all sorts of misperceptions\nthat are out there.",
        "start": 308.27,
        "duration": 4.179
    },
    {
        "text": "It makes headlines to talk about the end of\nwork and in and announced panel, we're talking",
        "start": 312.449,
        "duration": 4.25
    },
    {
        "text": "about augmented intelligence versus the machine\nsuddenly replacing us all and we can all just",
        "start": 316.699,
        "duration": 4.661
    },
    {
        "text": "sit around for the rest of our lives and play\nvideo games and smoke pot and try to figure",
        "start": 321.36,
        "duration": 3.63
    },
    {
        "text": "out what to do with ourselves, so I think\nthat's a misperception.",
        "start": 324.99,
        "duration": 3.58
    },
    {
        "text": "I think, my perception, my perspective here\nis coming from doing a lot of work with large",
        "start": 328.57,
        "duration": 5.9
    },
    {
        "text": "enterprises who are in the process of trying\nto adopt and make real applications from a",
        "start": 334.47,
        "duration": 7.15
    },
    {
        "text": "lot of the theoretical research coming out\nof academic research units and things like",
        "start": 341.62,
        "duration": 3.17
    },
    {
        "text": "computer vision.",
        "start": 344.79,
        "duration": 1.0
    },
    {
        "text": "So using computers and showing them pictures\nof a puppy or pictures of a glass of wine",
        "start": 345.79,
        "duration": 4.45
    },
    {
        "text": "and without any associated metadata they can,\nthey can recognize that and they can accurately",
        "start": 350.24,
        "duration": 4.709
    },
    {
        "text": "label those tasks.",
        "start": 354.949,
        "duration": 2.781
    },
    {
        "text": "So in doing this work with enterprises, I've\nseen that this is just a lot harder than one",
        "start": 357.73,
        "duration": 4.56
    },
    {
        "text": "would think.",
        "start": 362.29,
        "duration": 1.0
    },
    {
        "text": "It's not like you can as in the Matrix, right?",
        "start": 363.29,
        "duration": 1.68
    },
    {
        "text": "If anybody's seen the Matrix where Keanu reeves\nputs little chip in his brain and the next",
        "start": 364.97,
        "duration": 3.982
    },
    {
        "text": "thing you know he can.",
        "start": 368.952,
        "duration": 1.0
    },
    {
        "text": "He's an expert karate master right?",
        "start": 369.952,
        "duration": 1.398
    },
    {
        "text": "We have this impression when we think about\naugmented intelligence that the systems will",
        "start": 371.35,
        "duration": 4.11
    },
    {
        "text": "get so smart that we can put our little chips\nin and then we're, we'll be fluent in German",
        "start": 375.46,
        "duration": 3.36
    },
    {
        "text": "after one day of work as opposed to passing\nthe Malcolm Gladwell 10,000 hours in order",
        "start": 378.82,
        "duration": 5.5
    },
    {
        "text": "to learn some new skill.",
        "start": 384.32,
        "duration": 1.689
    },
    {
        "text": "But in practice it does take time and it often\ntakes an articulated, artfully articulated",
        "start": 386.009,
        "duration": 7.071
    },
    {
        "text": "collaboration between men and machine in order\nto get going with systems.",
        "start": 393.08,
        "duration": 5.03
    },
    {
        "text": "When I'm working with large Wall Street banks\nor insurance companies or media companies,",
        "start": 398.11,
        "duration": 5.89
    },
    {
        "text": "often I'll meet with sort of an executive\nlayer and the impression that they have is",
        "start": 404.0,
        "duration": 4.259
    },
    {
        "text": "that they can go from absolutely manual processes\nto complete Netflix like automation in three",
        "start": 408.259,
        "duration": 7.431
    },
    {
        "text": "or four months.",
        "start": 415.69,
        "duration": 1.099
    },
    {
        "text": "And they ask us to scope out projects like\nthis where they can just plug in a machine",
        "start": 416.789,
        "duration": 2.981
    },
    {
        "text": "and, you know, we're sort of ready to go,\nand what I like about Stitch Fix, and I'll",
        "start": 419.77,
        "duration": 6.04
    },
    {
        "text": "use this as a metaphor to help them understand\nwhat this might really look like…",
        "start": 425.81,
        "duration": 3.37
    },
    {
        "text": "Does everyone know what it is?",
        "start": 429.18,
        "duration": 1.37
    },
    {
        "text": "I'll explain it, so this is a, it's an e-commerce\nshopping personal shopping site.",
        "start": 430.55,
        "duration": 6.399
    },
    {
        "text": "So you go in and, say you're a woman and you're\nsick and tired of shopping so you can sign",
        "start": 436.949,
        "duration": 5.97
    },
    {
        "text": "up for an account and they ask you to fill\nout a form that tells you some data about",
        "start": 442.919,
        "duration": 5.041
    },
    {
        "text": "yourself.",
        "start": 447.96,
        "duration": 1.0
    },
    {
        "text": "So you know, your height, your weight, your\nsize, some of your taste in clothing.",
        "start": 448.96,
        "duration": 4.0
    },
    {
        "text": "So you can go on Pinterest and pick out examples\nof, of images, of clothing that you might",
        "start": 452.96,
        "duration": 5.0
    },
    {
        "text": "like and you send this off into the ether.",
        "start": 457.96,
        "duration": 3.739
    },
    {
        "text": "And the next thing you know, a month later\nthey get a little box that has five items",
        "start": 461.699,
        "duration": 4.87
    },
    {
        "text": "of clothing that the Stitch Fix assumes and\npredicts might be, might be something that",
        "start": 466.569,
        "duration": 4.681
    },
    {
        "text": "you'd like.",
        "start": 471.25,
        "duration": 1.0
    },
    {
        "text": "So this is partially algorithmic, right?",
        "start": 472.25,
        "duration": 2.09
    },
    {
        "text": "So the first past that Stitch Fix does is\nto put this into some big algorithmic recommender",
        "start": 474.34,
        "duration": 5.4
    },
    {
        "text": "system where it parses the features that you've\ninput and then outputs recommended items,",
        "start": 479.74,
        "duration": 5.579
    },
    {
        "text": "but then they pass it to a set of personal\nstylists who are just 1099 workers who go",
        "start": 485.319,
        "duration": 6.862
    },
    {
        "text": "through and they curate a selection that that\nwill likely be of interest to the final and",
        "start": 492.181,
        "duration": 5.759
    },
    {
        "text": "end consumer of the service.",
        "start": 497.94,
        "duration": 1.379
    },
    {
        "text": "So basically they've artfully combined human\nintelligence to give feedback to those algorithms.",
        "start": 499.319,
        "duration": 5.451
    },
    {
        "text": "And then all of the data oriented algorithmic\nwork, and I liked this as a metaphor or I",
        "start": 504.77,
        "duration": 6.05
    },
    {
        "text": "mean literal business model as well as a metaphor\nfor enterprises that are trying to get started",
        "start": 510.82,
        "duration": 3.74
    },
    {
        "text": "with these tools.",
        "start": 514.56,
        "duration": 1.56
    },
    {
        "text": "Because if we take an example of say automating\na sales process in a large bank, there's a",
        "start": 516.12,
        "duration": 5.18
    },
    {
        "text": "lot of know how and knowledge and subject\nmatter expertise trapped within the heads",
        "start": 521.3,
        "duration": 4.87
    },
    {
        "text": "of the current employees.",
        "start": 526.17,
        "duration": 2.109
    },
    {
        "text": "And the task here is to tease out some of\nthose insights and transform them into statistical",
        "start": 528.279,
        "duration": 6.68
    },
    {
        "text": "patterns and systems so that there can be\nthis give and take and always with a feedback",
        "start": 534.959,
        "duration": 3.63
    },
    {
        "text": "loop to eventually five years down the line,\nmaybe get to the point where the scales tip",
        "start": 538.589,
        "duration": 5.48
    },
    {
        "text": "to the system's doing more of the work than\nthe people, but certainly not over overnight.",
        "start": 544.069,
        "duration": 4.5
    },
    {
        "text": "So, the big misperception here I think is\nthe sort of inflated hyperbole around the",
        "start": 548.569,
        "duration": 5.31
    },
    {
        "text": "fact that the machines are getting so smart,\nthey're gonna take over jobs tomorrow.",
        "start": 553.879,
        "duration": 3.7
    },
    {
        "text": "Vassant, why don't you pick up on that, since\nyou’re in a domain it is, you know, quant",
        "start": 557.579,
        "duration": 8.3
    },
    {
        "text": "hedge fund, if you will,",
        "start": 565.879,
        "duration": 1.25
    },
    {
        "text": "Sure.",
        "start": 567.129,
        "duration": 1.0
    },
    {
        "text": "So the way I sort of look at the financial\nlandscape is in terms of sort of high frequency",
        "start": 568.129,
        "duration": 7.31
    },
    {
        "text": "trading where the machines out at the end\nof the day just very short term decisions",
        "start": 575.439,
        "duration": 5.43
    },
    {
        "text": "on one extreme and on the other hand you have\na long term decision making a la Warren Buffet",
        "start": 580.869,
        "duration": 6.88
    },
    {
        "text": "style where you're looking at factors that\nyou know, the machine really has no basis",
        "start": 587.749,
        "duration": 7.611
    },
    {
        "text": "for picking up on and that's a very human",
        "start": 595.36,
        "duration": 2.899
    },
    {
        "text": "The management team",
        "start": 598.259,
        "duration": 1.651
    },
    {
        "text": "Yes.",
        "start": 599.91,
        "duration": 1.0
    },
    {
        "text": "And it's just much more qualitative and there's\nnot enough data, right?",
        "start": 600.91,
        "duration": 2.95
    },
    {
        "text": "So it really boils down to does the machine\nhave enough data?",
        "start": 603.86,
        "duration": 4.24
    },
    {
        "text": "And then the middle you have sort of short\nterm trading where you might hold for days",
        "start": 608.1,
        "duration": 3.789
    },
    {
        "text": "a weeks.",
        "start": 611.889,
        "duration": 1.37
    },
    {
        "text": "So in the on the left hand side and the high\nfrequency side, there's lots of examples,",
        "start": 613.259,
        "duration": 3.92
    },
    {
        "text": "lots of repeated instances, and you can learn\nthe machine has a basis for learning and that",
        "start": 617.179,
        "duration": 5.1
    },
    {
        "text": "game was over a long time ago.",
        "start": 622.279,
        "duration": 1.761
    },
    {
        "text": "Machines took that over from humans.",
        "start": 624.04,
        "duration": 2.719
    },
    {
        "text": "On the right hand side you have machines that\nreally don't have a basis for making a decision.",
        "start": 626.759,
        "duration": 4.87
    },
    {
        "text": "So that's an inherently human endeavor, not\nthat humans do particularly well at it.",
        "start": 631.629,
        "duration": 4.81
    },
    {
        "text": "In fact, most humans actually underperformed\nthe market, you know, Warren Buffet and a",
        "start": 636.439,
        "duration": 4.501
    },
    {
        "text": "few others being notable exceptions.",
        "start": 640.94,
        "duration": 1.639
    },
    {
        "text": "And in the middle you have sort of this intermediate\nspace where you have enough data and the machine",
        "start": 642.579,
        "duration": 5.641
    },
    {
        "text": "has a basis to learn and trade on its own.",
        "start": 648.22,
        "duration": 4.59
    },
    {
        "text": "My experience is that humans really aren't\ncapable of making too many decisions in a",
        "start": 652.81,
        "duration": 5.35
    },
    {
        "text": "day, right?",
        "start": 658.16,
        "duration": 1.76
    },
    {
        "text": "If you actually have enough data, then models\nof men tend to be better than man, right?",
        "start": 659.92,
        "duration": 5.459
    },
    {
        "text": "That's what the research generally tends to\nshow, you know, human emotions kind of get",
        "start": 665.379,
        "duration": 4.88
    },
    {
        "text": "in the way.",
        "start": 670.259,
        "duration": 2.2
    },
    {
        "text": "And so, you know, when we talk about augmented\nintelligence, you have to ask yourself who's",
        "start": 672.459,
        "duration": 4.85
    },
    {
        "text": "augmenting who, you know, is the machine augmenting\nhumans, which has been sort of the traditional",
        "start": 677.309,
        "duration": 7.041
    },
    {
        "text": "decision support model for 50 years.",
        "start": 684.35,
        "duration": 1.989
    },
    {
        "text": "And that makes a lot of sense because their\nproblems where you don't have enough data",
        "start": 686.339,
        "duration": 4.28
    },
    {
        "text": "for the machine to actually make the, to be\nmaking a decision.",
        "start": 690.619,
        "duration": 2.331
    },
    {
        "text": "And so that makes a lot of sense.",
        "start": 692.95,
        "duration": 2.11
    },
    {
        "text": "On the other hand, if it's machine augmenting\na, if it's man augmenting machine, then it,",
        "start": 695.06,
        "duration": 5.889
    },
    {
        "text": "then I feel that it's sort of a matter of\ntime before the machine does better because",
        "start": 700.949,
        "duration": 4.291
    },
    {
        "text": "you're training it to do better and then you\nshould expect it to do better over time.",
        "start": 705.24,
        "duration": 5.37
    },
    {
        "text": "So sort of to put this all together, the way\nI sort of look at the world is, you know,",
        "start": 710.61,
        "duration": 4.81
    },
    {
        "text": "if you can imagine sort of predictability\non the x axis and cost per error on the y",
        "start": 715.42,
        "duration": 3.64
    },
    {
        "text": "axis than problems that fall on the lower\nright are very amenable to automated decision",
        "start": 719.06,
        "duration": 5.739
    },
    {
        "text": "making.",
        "start": 724.799,
        "duration": 1.0
    },
    {
        "text": "You know, you have high predictability and\nlow cost per error and problems to the left",
        "start": 725.799,
        "duration": 5.15
    },
    {
        "text": "are difficult to automate because there's\nlow predictability relative to cost per error.",
        "start": 730.949,
        "duration": 5.39
    },
    {
        "text": "Now, interestingly, driverless cars are highly\npredictable until you might expect those to",
        "start": 736.339,
        "duration": 4.55
    },
    {
        "text": "be automated, but at the moment the cost of\nmistakes is very high.",
        "start": 740.889,
        "duration": 3.81
    },
    {
        "text": "So they're also very high on the y axis, which\nis why we're reluctant to cede control of",
        "start": 744.699,
        "duration": 7.16
    },
    {
        "text": "our transportation yet to the machine because\nwe're just not sure of the sort of edge cases",
        "start": 751.859,
        "duration": 6.511
    },
    {
        "text": "or when stuff goes wrong.",
        "start": 758.37,
        "duration": 1.189
    },
    {
        "text": "It could go badly wrong, so I suspect that\nthat will happen very gradually",
        "start": 759.559,
        "duration": 4.34
    },
    {
        "text": "And isn't there another kind of aspect here\nwhere there are categories of decisions.",
        "start": 763.899,
        "duration": 4.271
    },
    {
        "text": "I mean so much of this technology, which we\nused to call it data science, which is data",
        "start": 768.17,
        "duration": 4.719
    },
    {
        "text": "plus machine learning algorithms.",
        "start": 772.889,
        "duration": 1.721
    },
    {
        "text": "We now call AI, right?",
        "start": 774.61,
        "duration": 3.579
    },
    {
        "text": "Its principle use was increasing your odds\nof making a sale, you know, predictive product",
        "start": 778.189,
        "duration": 6.241
    },
    {
        "text": "predictions, targeted advertising, that sort\nof thing.",
        "start": 784.43,
        "duration": 7.459
    },
    {
        "text": "And that's fine for decisions were better\non average is great.",
        "start": 791.889,
        "duration": 4.091
    },
    {
        "text": "To me, one of my favorite data sciences woman\nnamed Claudia Perlich and her line on this,",
        "start": 795.98,
        "duration": 3.879
    },
    {
        "text": "she works, used to work for a Watson and now\nworks for ad targeting firming.",
        "start": 799.859,
        "duration": 4.92
    },
    {
        "text": "And her line is that, look, this is a great\ntime for experimentation in marketing because",
        "start": 804.779,
        "duration": 4.691
    },
    {
        "text": "what happens if my algorithm's wrong?",
        "start": 809.47,
        "duration": 1.579
    },
    {
        "text": "It's, you know, it's somebody sees the wrong\nad.",
        "start": 811.049,
        "duration": 2.451
    },
    {
        "text": "It's not a false positive for breast cancer,\nbut we're moving into these categories that",
        "start": 813.5,
        "duration": 3.85
    },
    {
        "text": "things were better on you.",
        "start": 817.35,
        "duration": 1.37
    },
    {
        "text": "You're affecting individuals' lives, medical\ndiagnosis, hiring decisions, and lending decisions",
        "start": 818.72,
        "duration": 7.289
    },
    {
        "text": "where, you know, individual, these are high\nstakes decisions for individual lives.",
        "start": 826.009,
        "duration": 4.971
    },
    {
        "text": "And that seems to me it's a different kind\nof category, isn't it?",
        "start": 830.98,
        "duration": 4.49
    },
    {
        "text": "Well, so for medical diagnosis, your trust\nthat falls sort of somewhere in the middle,",
        "start": 835.47,
        "duration": 5.88
    },
    {
        "text": "so let's say diabetes prediction than diagnosis\nfalls somewhere in the middle of the spectrum",
        "start": 841.35,
        "duration": 5.219
    },
    {
        "text": "and machines do reasonably well, but they\nstill make lots of errors but it.",
        "start": 846.569,
        "duration": 3.98
    },
    {
        "text": "So they still made this still significant\nnumbers of false positives and false negatives,",
        "start": 850.549,
        "duration": 3.931
    },
    {
        "text": "which can be particularly injurious if you\nsort of missed something.",
        "start": 854.48,
        "duration": 5.229
    },
    {
        "text": "And so for that reason, the way machines are\nreally used as sort of to make that first",
        "start": 859.709,
        "duration": 5.1
    },
    {
        "text": "cart and categorize people into various levels\nof risks that humans can then pursue in a",
        "start": 864.809,
        "duration": 6.811
    },
    {
        "text": "more structured kind of fashion.",
        "start": 871.62,
        "duration": 2.829
    },
    {
        "text": "But it sort of comes down to that the cost\nof errors there are still pretty high, so",
        "start": 874.449,
        "duration": 3.67
    },
    {
        "text": "you're not going to cede control of that to\nthe machine.",
        "start": 878.119,
        "duration": 2.241
    },
    {
        "text": "On the other hand, imagine that we now have\ngenomic data available, right?",
        "start": 880.36,
        "duration": 3.499
    },
    {
        "text": "The trouble with healthcare is that most healthy\npeople have very few points of contact with",
        "start": 883.859,
        "duration": 4.72
    },
    {
        "text": "the healthcare system.",
        "start": 888.579,
        "duration": 1.17
    },
    {
        "text": "So there isn't enough data about them.",
        "start": 889.749,
        "duration": 1.81
    },
    {
        "text": "Right.",
        "start": 891.559,
        "duration": 1.0
    },
    {
        "text": "Whereas the sick people, there's lots of data\nabout them, but it's usually too late to do",
        "start": 892.559,
        "duration": 3.08
    },
    {
        "text": "much about it, so you can imagine that in\nthe future as we get more data about people,",
        "start": 895.639,
        "duration": 6.79
    },
    {
        "text": "your physician could very well be a machine\nas well, or at least the machine group play",
        "start": 902.429,
        "duration": 4.041
    },
    {
        "text": "a much larger role in advising you on your\nhealth.",
        "start": 906.47,
        "duration": 4.96
    },
    {
        "text": "Kathryn mentioned earlier, putting chips in\nbrains.",
        "start": 911.43,
        "duration": 1.809
    },
    {
        "text": "Actually, this is an area of research that\nMatthew's done a lot on and it talks about",
        "start": 913.239,
        "duration": 6.32
    },
    {
        "text": "brain machine interfaces, some of primitive\nones we have now.",
        "start": 919.559,
        "duration": 2.82
    },
    {
        "text": "And he explores, kind of the future of this\nin terms of what you call the control problem.",
        "start": 922.379,
        "duration": 4.69
    },
    {
        "text": "I believe so.",
        "start": 927.069,
        "duration": 1.0
    },
    {
        "text": "Elaborate on that.",
        "start": 928.069,
        "duration": 1.0
    },
    {
        "text": "So I'm a philosopher and bioethicists.",
        "start": 929.069,
        "duration": 1.81
    },
    {
        "text": "So in the bioethics community, there's a talk\nof human cognitive enhancement.",
        "start": 930.879,
        "duration": 4.681
    },
    {
        "text": "So one way to amplify our intelligence, so\nis to sort of amplify biological intelligence",
        "start": 935.56,
        "duration": 7.019
    },
    {
        "text": "to get us to become smarter biologically speaking.",
        "start": 942.579,
        "duration": 3.78
    },
    {
        "text": "But there's another way which is to do some\nsort of symbiosis where we begin to use computer",
        "start": 946.359,
        "duration": 6.17
    },
    {
        "text": "parts and smartphones kinda like that.",
        "start": 952.529,
        "duration": 3.27
    },
    {
        "text": "You might think that your smartphone, it's\nkind of like an extended mind, an extension",
        "start": 955.799,
        "duration": 3.671
    },
    {
        "text": "of your mind.",
        "start": 959.47,
        "duration": 1.32
    },
    {
        "text": "But there's more now there's something called\nbrain machine interfaces where there's something",
        "start": 960.79,
        "duration": 4.799
    },
    {
        "text": "called transcranial stimulation.",
        "start": 965.589,
        "duration": 1.55
    },
    {
        "text": "So you sorta put something over your head.",
        "start": 967.139,
        "duration": 2.56
    },
    {
        "text": "So companies are marketing this to athletes\nso that they can sort of performed better.",
        "start": 969.699,
        "duration": 4.51
    },
    {
        "text": "They can learn better, learn quicker.",
        "start": 974.209,
        "duration": 1.67
    },
    {
        "text": "And there's actually evidence that it's not\nquite like the matrix style of being able",
        "start": 975.879,
        "duration": 5.04
    },
    {
        "text": "to learn a language right away.",
        "start": 980.919,
        "duration": 1.82
    },
    {
        "text": "But it turns out that you can learn things\nfaster, you remember things more using even",
        "start": 982.739,
        "duration": 4.32
    },
    {
        "text": "transcranial stimulation, which is actually\na very crude technology.",
        "start": 987.059,
        "duration": 3.94
    },
    {
        "text": "And there's something else called deep brain\nstimulation which is much more invasive.",
        "start": 990.999,
        "duration": 4.45
    },
    {
        "text": "And so where basically you're inserting a\ntheme the electrode into your brain and then",
        "start": 995.449,
        "duration": 5.19
    },
    {
        "text": "it's connected to a battery pack and then\nyou sort of, you can adjust the, the mode,",
        "start": 1000.639,
        "duration": 4.61
    },
    {
        "text": "the electrical currents, and it's said sense\nof electrical current to your brain.",
        "start": 1005.249,
        "duration": 3.921
    },
    {
        "text": "And about a hundred thousand people in the\nworld today have already a DBS and they use",
        "start": 1009.17,
        "duration": 6.24
    },
    {
        "text": "it for things like Parkinson's disease, epilepsy,\netc.",
        "start": 1015.41,
        "duration": 5.169
    },
    {
        "text": "Etc.",
        "start": 1020.579,
        "duration": 1.24
    },
    {
        "text": "Even depression.",
        "start": 1021.819,
        "duration": 2.471
    },
    {
        "text": "But the interesting about thing about DBS\nright now is that it's an open loop system.",
        "start": 1024.29,
        "duration": 5.4
    },
    {
        "text": "And what that means is user controlled, right?",
        "start": 1029.69,
        "duration": 2.54
    },
    {
        "text": "So you kinda manipulate, you sort of adjust\nthe level of electricity.",
        "start": 1032.23,
        "duration": 5.349
    },
    {
        "text": "But DARPA, the Defense Advanced Research Projects\nAgency, for example, it's quite interested",
        "start": 1037.579,
        "duration": 5.921
    },
    {
        "text": "in something called a closed loop system where\nthe implant itself will auto monitor your",
        "start": 1043.5,
        "duration": 7.08
    },
    {
        "text": "mood, your brain, state and your emotional\nstate.",
        "start": 1050.58,
        "duration": 2.48
    },
    {
        "text": "So say you're a soldier in the war.",
        "start": 1053.06,
        "duration": 2.729
    },
    {
        "text": "And all of a sudden you started to panic,\nit will send, what DARPA wants to do is sort",
        "start": 1055.789,
        "duration": 4.592
    },
    {
        "text": "of send some sort of automatic electrical\nsignal to calm you down, for example.",
        "start": 1060.381,
        "duration": 4.469
    },
    {
        "text": "Right.",
        "start": 1064.85,
        "duration": 1.0
    },
    {
        "text": "Um, and so we'll automatically monitor your\nemotions and then adjust them on your, on",
        "start": 1065.85,
        "duration": 5.579
    },
    {
        "text": "your behalf.",
        "start": 1071.429,
        "duration": 1.041
    },
    {
        "text": "And that raises all sorts of questions about\nwhether this is going to solve the control",
        "start": 1072.47,
        "duration": 3.85
    },
    {
        "text": "problem because, well, you know, if the machine's\ndeciding that for you, then who's really in",
        "start": 1076.32,
        "duration": 5.9
    },
    {
        "text": "control, right?",
        "start": 1082.22,
        "duration": 1.0
    },
    {
        "text": "Who's really augmenting, who?",
        "start": 1083.22,
        "duration": 1.5
    },
    {
        "text": "What Vassant is talking about.",
        "start": 1084.72,
        "duration": 1.74
    },
    {
        "text": "What worries you about, you know, at what\nlevel, because we're talking about cyborgs",
        "start": 1086.46,
        "duration": 5.579
    },
    {
        "text": "basically, right?",
        "start": 1092.039,
        "duration": 1.0
    },
    {
        "text": "The deeper philosophical question, one issue\nthat's going to come up is so say, so it's",
        "start": 1093.039,
        "duration": 5.921
    },
    {
        "text": "going beyond augmentation towards integration,\nright?",
        "start": 1098.96,
        "duration": 3.42
    },
    {
        "text": "And when you have this type of integration,\none issue is that is going to be, is this",
        "start": 1102.38,
        "duration": 4.12
    },
    {
        "text": "going to still be me?",
        "start": 1106.5,
        "duration": 2.19
    },
    {
        "text": "Right?",
        "start": 1108.69,
        "duration": 1.39
    },
    {
        "text": "So in this literature it gets a bit science\nfictiony, some people talk about uploading",
        "start": 1110.08,
        "duration": 5.3
    },
    {
        "text": "your mental contents, taking like copying\nall your mental content and uploading it to",
        "start": 1115.38,
        "duration": 3.799
    },
    {
        "text": "the cloud so you can kind of like “Her”\nor you know, if you've seen the movie “Her”",
        "start": 1119.179,
        "duration": 4.0
    },
    {
        "text": "and then sort of, and that's one issue.",
        "start": 1123.179,
        "duration": 5.071
    },
    {
        "text": "The thing about that is that when you upload\nthe mental contents into the cloud, it's not",
        "start": 1128.25,
        "duration": 4.49
    },
    {
        "text": "going to be you.",
        "start": 1132.74,
        "duration": 1.069
    },
    {
        "text": "And here's a way to think about why it's not\ngoing to be you.",
        "start": 1133.809,
        "duration": 2.791
    },
    {
        "text": "So imagine that you take, you make a thousand\ncopies of that, right?",
        "start": 1136.6,
        "duration": 3.679
    },
    {
        "text": "And just run it in thousand different locations.",
        "start": 1140.279,
        "duration": 2.64
    },
    {
        "text": "Now you're supposed to be only in one location,\nright?",
        "start": 1142.919,
        "duration": 4.61
    },
    {
        "text": "A so it seems like if it's running a thousand\ncopies all that, all those copies cannot be",
        "start": 1147.529,
        "duration": 6.661
    },
    {
        "text": "you.",
        "start": 1154.19,
        "duration": 1.0
    },
    {
        "text": "Right?",
        "start": 1155.19,
        "duration": 1.0
    },
    {
        "text": "But the integration part seems like, maybe\nyou can kind of preserve some sort of identity",
        "start": 1156.19,
        "duration": 5.08
    },
    {
        "text": "if its more much more integrated if some sort\nof.",
        "start": 1161.27,
        "duration": 3.499
    },
    {
        "text": "If our carbon-based cells can interact with\nan isomorphic non-carbon based cells sort",
        "start": 1164.769,
        "duration": 7.581
    },
    {
        "text": "of talk to each other if we can kind of get\nat that level.",
        "start": 1172.35,
        "duration": 2.39
    },
    {
        "text": "So a lot of people are working on this particular\nproblem, right?",
        "start": 1174.74,
        "duration": 3.92
    },
    {
        "text": "Getting biological cells to talk to digital\ncells.",
        "start": 1178.66,
        "duration": 4.399
    },
    {
        "text": "If that can happen, then we can accomplish\nsome form of integration and still be you.",
        "start": 1183.059,
        "duration": 7.511
    },
    {
        "text": "John, let's bring this back a little back.",
        "start": 1190.57,
        "duration": 4.359
    },
    {
        "text": "What is IBM working on?",
        "start": 1194.929,
        "duration": 1.38
    },
    {
        "text": "Healthcare or something that's an example\nof sort of augmented intelligence that you",
        "start": 1196.309,
        "duration": 4.48
    },
    {
        "text": "might.",
        "start": 1200.789,
        "duration": 1.0
    },
    {
        "text": "That is either in the marketplace or in the\nlabs, demonstrated, right?",
        "start": 1201.789,
        "duration": 6.11
    },
    {
        "text": "That can be done now that you wouldn't have\nthought could have been done five years ago.",
        "start": 1207.899,
        "duration": 6.0
    },
    {
        "text": "So, you know, there are many really good examples.",
        "start": 1213.899,
        "duration": 2.041
    },
    {
        "text": "I'll talk about one, you know, one is in healthcare.",
        "start": 1215.94,
        "duration": 3.17
    },
    {
        "text": "So, you know, today, if we think about a problem,\nI'm like skin cancer, actually millions of",
        "start": 1219.11,
        "duration": 5.949
    },
    {
        "text": "people around the world every year are affected\nby skin cancer.",
        "start": 1225.059,
        "duration": 4.96
    },
    {
        "text": "And if we look at melanoma in particular,\nit's actually a very deadly form of skin cancer",
        "start": 1230.019,
        "duration": 6.74
    },
    {
        "text": "where in the U.S. 10,000 people die each year.",
        "start": 1236.759,
        "duration": 4.991
    },
    {
        "text": "The computer can work together with the clinician,\nyou know, sort of addressing the fact that",
        "start": 1241.75,
        "duration": 7.679
    },
    {
        "text": "people don't always make good decisions.",
        "start": 1249.429,
        "duration": 2.651
    },
    {
        "text": "They have their own biases, they get tired,\nthere's subjectivity, you know, there's, you",
        "start": 1252.08,
        "duration": 5.5
    },
    {
        "text": "know, there's a lot there.",
        "start": 1257.58,
        "duration": 1.0
    },
    {
        "text": "The computer is objective and the computer,\nyou know, that's, you know, that's a strong",
        "start": 1258.58,
        "duration": 4.27
    },
    {
        "text": "capability that it can bring to the clinician\nand point things out.",
        "start": 1262.85,
        "duration": 5.98
    },
    {
        "text": "So maybe, you know, maybe there's, maybe there's\nsomething that they haven't seen before, but",
        "start": 1268.83,
        "duration": 4.8
    },
    {
        "text": "the computer has an infinite capacity to,\nyou know, to see thousands or tens of thousands",
        "start": 1273.63,
        "duration": 5.75
    },
    {
        "text": "of cases of melanoma and make connections,\nyou know, the clinician, you know, may, may",
        "start": 1279.38,
        "duration": 6.581
    },
    {
        "text": "miss.",
        "start": 1285.961,
        "duration": 1.419
    },
    {
        "text": "So It's, you know, it's really problems like\nthat where we look at the strengths of the",
        "start": 1287.38,
        "duration": 4.39
    },
    {
        "text": "computer, you know, the ability to look at\nmassive amounts of data, the ability to continuously",
        "start": 1291.77,
        "duration": 5.619
    },
    {
        "text": "learn, the ability to be there without any\ndelay, you know, the ability to sort of interject",
        "start": 1297.389,
        "duration": 8.091
    },
    {
        "text": "the right moment., B really ultimately it's\naugmentation and scaling that, that human",
        "start": 1305.48,
        "duration": 6.411
    },
    {
        "text": "expertise, it's not replacing that doctor,\nfor example, in the end.",
        "start": 1311.891,
        "duration": 7.008
    },
    {
        "text": "Yeah, this is the other come back and automation\nis destroying jobs…",
        "start": 1318.899,
        "duration": 2.321
    },
    {
        "text": "Can l just add to that because I just want\nto pick up on that, so one of the reasons",
        "start": 1321.22,
        "duration": 5.699
    },
    {
        "text": "there's all of this sort of excitement about\nAI is that we've made a big dent in solving",
        "start": 1326.919,
        "duration": 5.681
    },
    {
        "text": "perception and the reason that's profound\nis because previous generations of AI required",
        "start": 1332.6,
        "duration": 7.49
    },
    {
        "text": "you to curate the input into a representation\nthat the machine could understand and then",
        "start": 1340.09,
        "duration": 5.069
    },
    {
        "text": "we'll run with that.",
        "start": 1345.159,
        "duration": 1.0
    },
    {
        "text": "Right?",
        "start": 1346.159,
        "duration": 1.0
    },
    {
        "text": "So game playing in the sixties and seventies\nfor example, you give them a representation",
        "start": 1347.159,
        "duration": 3.831
    },
    {
        "text": "of the problem of the of the chess board or\nthe backgammon game or whatever, and then",
        "start": 1350.99,
        "duration": 4.59
    },
    {
        "text": "within the precepts of that they did their\nthing and did search and all of that sort",
        "start": 1355.58,
        "duration": 4.15
    },
    {
        "text": "of cool stuff, and did quite well, but you\nstill have to tell the machine what it was",
        "start": 1359.73,
        "duration": 5.809
    },
    {
        "text": "working on.",
        "start": 1365.539,
        "duration": 1.281
    },
    {
        "text": "The difference now is that machines just take\ninput directly from the environment.",
        "start": 1366.82,
        "duration": 4.92
    },
    {
        "text": "Images like vision, they can dig and see,\nthey can hear, they can read and that makes",
        "start": 1371.74,
        "duration": 4.809
    },
    {
        "text": "a big difference because you know, you just\nkind of sidestep that laborious process of",
        "start": 1376.549,
        "duration": 7.391
    },
    {
        "text": "curating the inputs for the machine and then\nhaving the machine do kind of the rest of",
        "start": 1383.94,
        "duration": 4.609
    },
    {
        "text": "it, right?",
        "start": 1388.549,
        "duration": 1.0
    },
    {
        "text": "Whereas now it's doing the heavy lifting right\nfrom the get go right from the source and",
        "start": 1389.549,
        "duration": 6.771
    },
    {
        "text": "sort of doing it all the way.",
        "start": 1396.32,
        "duration": 1.559
    },
    {
        "text": "Now I am a little less optimistic about the\nfuture when I think of the world that way",
        "start": 1397.879,
        "duration": 6.821
    },
    {
        "text": "because one of the basic fortes of human beings\nis our ability to deal with unstructured data.",
        "start": 1404.7,
        "duration": 7.02
    },
    {
        "text": "A lot of the basis of human employment is\nthe ability to look at images, whichever way",
        "start": 1411.72,
        "duration": 6.43
    },
    {
        "text": "they come, look at handwriting, whichever\nthe way it comes, and then do some simple",
        "start": 1418.15,
        "duration": 3.84
    },
    {
        "text": "sort of logical things on top of that.",
        "start": 1421.99,
        "duration": 2.659
    },
    {
        "text": "Right, and it does, and it doesn't matter.",
        "start": 1424.649,
        "duration": 1.731
    },
    {
        "text": "By the way.",
        "start": 1426.38,
        "duration": 1.0
    },
    {
        "text": "This is blue-collar workers or white-collar\nworkers.",
        "start": 1427.38,
        "duration": 2.139
    },
    {
        "text": "The machines don't really care.",
        "start": 1429.519,
        "duration": 1.48
    },
    {
        "text": "The only thing that matters is that sufficient\namounts of data available.",
        "start": 1430.999,
        "duration": 6.4
    },
    {
        "text": "And I think this is what the excitement is\nabout and the and the shifts that are going",
        "start": 1437.399,
        "duration": 5.28
    },
    {
        "text": "to happen.",
        "start": 1442.679,
        "duration": 1.0
    },
    {
        "text": "You know, I was in Toronto airport the other\nday.",
        "start": 1443.679,
        "duration": 2.161
    },
    {
        "text": "I was on a United airlines flight that happened\nto be a code share with Air Canada, so we",
        "start": 1445.84,
        "duration": 4.679
    },
    {
        "text": "went to the kiosk, tried my passport, no go\ncredit card no go, global entry didn't work",
        "start": 1450.519,
        "duration": 6.25
    },
    {
        "text": "and so I need a human.",
        "start": 1456.769,
        "duration": 2.68
    },
    {
        "text": "So I go into a line that's full of humans.",
        "start": 1459.449,
        "duration": 3.72
    },
    {
        "text": "The lines look humans and I was thinking this\nis silly, right?",
        "start": 1463.169,
        "duration": 3.911
    },
    {
        "text": "All you need is a machine just watching everything,\nright?",
        "start": 1467.08,
        "duration": 2.169
    },
    {
        "text": "Image recognition, technology is good enough\nand it can just tell Air Canada how many people",
        "start": 1469.249,
        "duration": 5.05
    },
    {
        "text": "didn't need, when to sort of keep things flowing\nmore freely and sort of sort of doing things",
        "start": 1474.299,
        "duration": 4.74
    },
    {
        "text": "the old way where you know, we're a scientist\nis making Poisson assumptions about arrivals",
        "start": 1479.039,
        "duration": 5.651
    },
    {
        "text": "and doing this heavy duty modeling and the\nstuff has gotten a broken at the end of the",
        "start": 1484.69,
        "duration": 6.2
    },
    {
        "text": "day as far as I'm concerned.",
        "start": 1490.89,
        "duration": 1.71
    },
    {
        "text": "So that's sort of, where a lot of the productivity\ngains I feel will accrue is from this ability",
        "start": 1492.6,
        "duration": 7.189
    },
    {
        "text": "to just kind of ingest the raw data and to\nbe able to make intelligent decisions with",
        "start": 1499.789,
        "duration": 4.911
    },
    {
        "text": "it automatically it.",
        "start": 1504.7,
        "duration": 1.569
    },
    {
        "text": "So that's going to have a pretty profound\nimpact.",
        "start": 1506.269,
        "duration": 2.721
    },
    {
        "text": "Yeah, I agree with that.",
        "start": 1508.99,
        "duration": 1.419
    },
    {
        "text": "Like with the so the data science community,\nwe call it feature engineering.",
        "start": 1510.409,
        "duration": 3.37
    },
    {
        "text": "So the sort of standard practice in data science\nup to the past couple of years have been to",
        "start": 1513.779,
        "duration": 5.88
    },
    {
        "text": "have a human come in and curate which aspects\nof a data set are going to be most highly",
        "start": 1519.659,
        "duration": 5.88
    },
    {
        "text": "with the outputs that you're looking for.",
        "start": 1525.539,
        "duration": 1.661
    },
    {
        "text": "So extended example I'll give is if you're,\nyou've got a simple model where you're trying",
        "start": 1527.2,
        "duration": 3.689
    },
    {
        "text": "to predict the prices of houses in a given\njurisdiction.",
        "start": 1530.889,
        "duration": 2.02
    },
    {
        "text": "You go through and you say, well is it going\nto be the square footage?",
        "start": 1532.909,
        "duration": 3.23
    },
    {
        "text": "Is it the location?",
        "start": 1536.139,
        "duration": 1.191
    },
    {
        "text": "Is it some sort of amenity?",
        "start": 1537.33,
        "duration": 1.36
    },
    {
        "text": "And you might note that it's the square footage\nthat seems to be the most highly correlated",
        "start": 1538.69,
        "duration": 4.439
    },
    {
        "text": "what you're looking for, so you focus on that.",
        "start": 1543.129,
        "duration": 2.581
    },
    {
        "text": "And in these new deep learning neural oriented\nsystems, we that sometimes there are so many",
        "start": 1545.71,
        "duration": 6.4
    },
    {
        "text": "possible features that could be relevant to\npredict what we're looking for, that we sort",
        "start": 1552.11,
        "duration": 3.449
    },
    {
        "text": "of remove that part from the equation and\nfocus the engineer's activity on selecting",
        "start": 1555.559,
        "duration": 4.261
    },
    {
        "text": "how many layers in a network might be useful\nselecting, which type of architecture because",
        "start": 1559.82,
        "duration": 5.65
    },
    {
        "text": "the connections can be oriented in different\nways, will be most effective in, in deriving",
        "start": 1565.47,
        "duration": 5.199
    },
    {
        "text": "the output that we're looking for, which has\nlead to these breakthroughs and things like",
        "start": 1570.669,
        "duration": 3.941
    },
    {
        "text": "perception.",
        "start": 1574.61,
        "duration": 1.09
    },
    {
        "text": "I'm on Jeopardy is a type of problem as John\nmentioned earlier on is one that's a little",
        "start": 1575.7,
        "duration": 4.199
    },
    {
        "text": "bit like entity extraction or sort of basic\nequations, right?",
        "start": 1579.899,
        "duration": 2.89
    },
    {
        "text": "So Einstein is who's the most famous scientists\nof 21st century.",
        "start": 1582.789,
        "duration": 3.671
    },
    {
        "text": "It says Einstein, right?",
        "start": 1586.46,
        "duration": 1.0
    },
    {
        "text": "So it goes through Wikipedia and can pull\nthat out, which is different from truly interpretive",
        "start": 1587.46,
        "duration": 4.93
    },
    {
        "text": "semantic understanding of text, which is harder\nto encode and a set of steadfast rules or",
        "start": 1592.39,
        "duration": 5.899
    },
    {
        "text": "humans selected features and a is leading\nto some relatively significant breakthroughs",
        "start": 1598.289,
        "duration": 4.821
    },
    {
        "text": "in applications like automated text summarization\nwhere we can build systems that make our representation",
        "start": 1603.11,
        "duration": 5.909
    },
    {
        "text": "of a very long piece of text as well as a\nmathematical representation of each sentence",
        "start": 1609.019,
        "duration": 5.04
    },
    {
        "text": "and then basically pick out those sentences\nthat are most closely related to the model",
        "start": 1614.059,
        "duration": 4.33
    },
    {
        "text": "of the whole, which is a thing that has struggled,\nhas been a struggle for the research community",
        "start": 1618.389,
        "duration": 4.471
    },
    {
        "text": "for a long time.",
        "start": 1622.86,
        "duration": 1.5
    },
    {
        "text": "One thing though, he mentioned that I want\nto disagree with his with the medical example",
        "start": 1624.36,
        "duration": 3.83
    },
    {
        "text": "and considering these computer systems more\nobjective than humans.",
        "start": 1628.19,
        "duration": 3.4
    },
    {
        "text": "I don't think machine-learning systems are\nobjective, in part because of the way that",
        "start": 1631.59,
        "duration": 4.579
    },
    {
        "text": "they're trained.",
        "start": 1636.169,
        "duration": 1.0
    },
    {
        "text": "so I'm in the, there's two sort of camps and\nmachine learning, supervised learning and",
        "start": 1637.169,
        "duration": 5.84
    },
    {
        "text": "unsupervised learning.",
        "start": 1643.009,
        "duration": 1.711
    },
    {
        "text": "So unsupervised learning is the style that\nwe know when, when, when we normally think",
        "start": 1644.72,
        "duration": 3.48
    },
    {
        "text": "about machine learning and from a public perception,\nit's the machines magical ability to discern",
        "start": 1648.2,
        "duration": 4.75
    },
    {
        "text": "patterns in data.",
        "start": 1652.95,
        "duration": 1.89
    },
    {
        "text": "So that exists and it's hard and it's often\nused for exploratory analysis of a data set",
        "start": 1654.84,
        "duration": 5.39
    },
    {
        "text": "to get a feel for clusters of information\nthat have something to do with one another",
        "start": 1660.23,
        "duration": 4.05
    },
    {
        "text": "so that you can then build a system.",
        "start": 1664.28,
        "duration": 2.71
    },
    {
        "text": "A lot of the big breakthroughs in deep learning\ntoday, most systems are supervised, which",
        "start": 1666.99,
        "duration": 5.65
    },
    {
        "text": "means they require a human to come in and\nlabel a set of data so they give it the right",
        "start": 1672.64,
        "duration": 4.759
    },
    {
        "text": "answer.",
        "start": 1677.399,
        "duration": 1.0
    },
    {
        "text": "And then the learning is optimizing the pathways\nso that when it sees something that it doesn't",
        "start": 1678.399,
        "duration": 4.15
    },
    {
        "text": "know yet it's been trained, the model has\nbeen trained well enough that it can make",
        "start": 1682.549,
        "duration": 3.24
    },
    {
        "text": "an accurate prediction.",
        "start": 1685.789,
        "duration": 1.0
    },
    {
        "text": "So that means humans are training them, which\nmeans there's a lot of subjectivity baked",
        "start": 1686.789,
        "duration": 5.651
    },
    {
        "text": "into the systems, right?",
        "start": 1692.44,
        "duration": 1.51
    },
    {
        "text": "So I’ll give you example of one where this\ncan have ethical consequences.",
        "start": 1693.95,
        "duration": 3.74
    },
    {
        "text": "So a good friend of mine just published a\npost on Medium about, a set of research that",
        "start": 1697.69,
        "duration": 6.189
    },
    {
        "text": "was used to detect and assume criminality\nfrom just from someone's photo.",
        "start": 1703.879,
        "duration": 5.561
    },
    {
        "text": "So these series of photos, this was done in\nChina have of men and you had sort of the",
        "start": 1709.44,
        "duration": 4.969
    },
    {
        "text": "top row when they every had on their white\ncollar and they looked like nice kind people",
        "start": 1714.409,
        "duration": 4.15
    },
    {
        "text": "in the bottom row are these sort of smug faces\nwith furrowed brows.",
        "start": 1718.559,
        "duration": 3.911
    },
    {
        "text": "And you look at that and you say, imagine\nthat weren't a machine learning system.",
        "start": 1722.47,
        "duration": 2.689
    },
    {
        "text": "It's just you as a human who's the good guy\nand who's the bad guy?",
        "start": 1725.159,
        "duration": 3.211
    },
    {
        "text": "And lo and behold, you kinda, you know, it's\nlike at first glance you have this intuition.",
        "start": 1728.37,
        "duration": 5.61
    },
    {
        "text": "So, the researchers of the paper claimed isn't\nthis amazing!",
        "start": 1733.98,
        "duration": 5.09
    },
    {
        "text": "These systems can go out and automatically\nidentify criminals just from their faces when",
        "start": 1739.07,
        "duration": 4.13
    },
    {
        "text": "in fact, you know, basically what the AI has\ndone is it's revealed to us, our prejudices,",
        "start": 1743.2,
        "duration": 6.17
    },
    {
        "text": "right?",
        "start": 1749.37,
        "duration": 1.0
    },
    {
        "text": "Our tendencies to look at somebody and be\nlike, yeah, that guy's scary and that guy's",
        "start": 1750.37,
        "duration": 2.789
    },
    {
        "text": "not.",
        "start": 1753.159,
        "duration": 1.0
    },
    {
        "text": "And we do this every day when we're walking\ndown the streets, right?",
        "start": 1754.159,
        "duration": 2.411
    },
    {
        "text": "So basically it is, if we view AI there as,\nas a magnifying glass to illuminate our own",
        "start": 1756.57,
        "duration": 8.319
    },
    {
        "text": "human biases, I think that there's a powerful\nethical discussion to have, but it means that",
        "start": 1764.889,
        "duration": 4.77
    },
    {
        "text": "if the systems, we have to assume that you\nhave to recognize the systems actually aren't",
        "start": 1769.659,
        "duration": 3.441
    },
    {
        "text": "objective because they, they're concatenating\nour own human behavior.",
        "start": 1773.1,
        "duration": 5.38
    },
    {
        "text": "So I think that indeed, is a risk and certainly\nit's something we have to take a, you know,",
        "start": 1778.48,
        "duration": 4.27
    },
    {
        "text": "a lot of care.",
        "start": 1782.75,
        "duration": 3.119
    },
    {
        "text": "In that particular case, what was the ground\ntruth?",
        "start": 1785.869,
        "duration": 3.81
    },
    {
        "text": "I think that, you know, that's what it comes\ndown to, you know, with a lot of this training",
        "start": 1789.679,
        "duration": 5.85
    },
    {
        "text": "if you're going to be teaching the computer\nthan is the information that your teaching",
        "start": 1795.529,
        "duration": 4.941
    },
    {
        "text": "in with correct?",
        "start": 1800.47,
        "duration": 1.26
    },
    {
        "text": "And you know, in the case of skin cancer,\nyou know, well, what can you do?",
        "start": 1801.73,
        "duration": 4.169
    },
    {
        "text": "You can have a gold standard around, you know,\nthe pathology reports or you know, they're",
        "start": 1805.899,
        "duration": 7.02
    },
    {
        "text": "there.",
        "start": 1812.919,
        "duration": 1.0
    },
    {
        "text": "Can, you can work hard to get information\nthat is correct as possible when you're training",
        "start": 1813.919,
        "duration": 7.021
    },
    {
        "text": "the computer.",
        "start": 1820.94,
        "duration": 1.0
    },
    {
        "text": "I think these are things that we have to strive\nfor.",
        "start": 1821.94,
        "duration": 2.079
    },
    {
        "text": "I mean, I fully agree there was always this\nnotion and machine learning, you know, prior",
        "start": 1824.019,
        "duration": 5.931
    },
    {
        "text": "to this resurgence, which was garbage in,\ngarbage out and I think that still applies",
        "start": 1829.95,
        "duration": 7.04
    },
    {
        "text": "today with deep learning and so on.",
        "start": 1836.99,
        "duration": 1.899
    },
    {
        "text": "You know, you have to take a lot of care and\nhow you train these systems.",
        "start": 1838.889,
        "duration": 2.75
    },
    {
        "text": "Is there, you know, the next five years, is\nthere something you think is going to be achievable",
        "start": 1841.639,
        "duration": 5.311
    },
    {
        "text": "that you see as you know, are potentially,\nit's striking and I'm thinking positive here",
        "start": 1846.95,
        "duration": 6.199
    },
    {
        "text": "right",
        "start": 1853.149,
        "duration": 1.0
    },
    {
        "text": "So I see more and more sort of decisions getting\nautomated and humans will do something else.",
        "start": 1854.149,
        "duration": 5.561
    },
    {
        "text": "What they do, I don't know.",
        "start": 1859.71,
        "duration": 1.13
    },
    {
        "text": "Right?",
        "start": 1860.84,
        "duration": 1.0
    },
    {
        "text": "Because there's a lot of talk about, well,\nthey won't replace us, they'll augment us.",
        "start": 1861.84,
        "duration": 5.089
    },
    {
        "text": "I'm just not seeing yet what that will be.",
        "start": 1866.929,
        "duration": 3.301
    },
    {
        "text": "I mean, I accept the fact that people will\ndo something different, right?",
        "start": 1870.23,
        "duration": 3.24
    },
    {
        "text": "If they're dangerous jobs that humans have\nbeen doing well better than machines do them",
        "start": 1873.47,
        "duration": 4.189
    },
    {
        "text": "and the human operator does something else.",
        "start": 1877.659,
        "duration": 3.88
    },
    {
        "text": "But I don't see exactly how that's going to\nsort of liberate us to, do, you know, more",
        "start": 1881.539,
        "duration": 8.2
    },
    {
        "text": "productive things as has been the case in\nthe past.",
        "start": 1889.739,
        "duration": 3.651
    },
    {
        "text": "So I'm sort of agnostic on this whole view\nof, you know, whether, you know, like previous",
        "start": 1893.39,
        "duration": 8.09
    },
    {
        "text": "waves of technology, AI is no different, you\nknow, it'll just make us more productive.",
        "start": 1901.48,
        "duration": 7.42
    },
    {
        "text": "But I fear that it'll worsen inequality that\nit will actually, you know, will still require",
        "start": 1908.9,
        "duration": 8.769
    },
    {
        "text": "humans, but the kinds of things that we value\nabout humans like empathy and all of that,",
        "start": 1917.669,
        "duration": 5.281
    },
    {
        "text": "I'm not in short supply , so they're not going\nto be sort of well compensated kinds of jobs.",
        "start": 1922.95,
        "duration": 7.719
    },
    {
        "text": "So I worried that the balance is shifting\nheavily in terms of capital, you know, as",
        "start": 1930.669,
        "duration": 6.031
    },
    {
        "text": "opposed to labor.",
        "start": 1936.7,
        "duration": 1.0
    },
    {
        "text": "Anyway, take a shot at the five-year thing?",
        "start": 1937.7,
        "duration": 2.25
    },
    {
        "text": "One of the other reasons why AI is taking\noff right now or one of the core reasons is",
        "start": 1939.95,
        "duration": 4.38
    },
    {
        "text": "actually from hardware.",
        "start": 1944.33,
        "duration": 1.469
    },
    {
        "text": "So graphical processing units that were historically\nused for video games.",
        "start": 1945.799,
        "duration": 3.691
    },
    {
        "text": "They do a good job moving electrons and basically\nin these parallel matrices as opposed to just",
        "start": 1949.49,
        "duration": 5.09
    },
    {
        "text": "in a straight line like in a central processing\nunit.",
        "start": 1954.58,
        "duration": 1.939
    },
    {
        "text": "That was great for processing images and building\nvideo games, the popularity of video games,",
        "start": 1956.519,
        "duration": 4.79
    },
    {
        "text": "and it just so happens that the architecture\nis also great for the type of mathematics",
        "start": 1961.309,
        "duration": 3.93
    },
    {
        "text": "that's underlying the types of systems that\nVasant was just describing.",
        "start": 1965.239,
        "duration": 3.621
    },
    {
        "text": "It’s really that combined with an immense\namount of data and just faster processing",
        "start": 1968.86,
        "duration": 3.77
    },
    {
        "text": "power is really led to the quantum, no pun\nintended, sort of leap in the revolution recently.",
        "start": 1972.63,
        "duration": 7.0
    },
    {
        "text": "And there's other types of hardware advances\nthat are occurring right now.",
        "start": 1979.63,
        "duration": 2.529
    },
    {
        "text": "So in those, this quantum computing world\nwith the, you know, and we could have a session,",
        "start": 1982.159,
        "duration": 4.14
    },
    {
        "text": "they just did a session on itself to describe\nthis, you can given, given this sort of entanglement",
        "start": 1986.299,
        "duration": 5.12
    },
    {
        "text": "properties that exist at the atomic level,\nyou can super, super impose various states",
        "start": 1991.419,
        "duration": 5.691
    },
    {
        "text": "of a bit so that it's not just the ones and\nzeros that we think of in standard deterministic,",
        "start": 1997.11,
        "duration": 4.069
    },
    {
        "text": "linear processing power.",
        "start": 2001.179,
        "duration": 1.291
    },
    {
        "text": "But from a probabilistic perspective and machine\nlearning is all about statistics and probability,",
        "start": 2002.47,
        "duration": 5.11
    },
    {
        "text": "you can use one operation to basically like\nsample across what could be for states if",
        "start": 2007.58,
        "duration": 6.979
    },
    {
        "text": "you've just got to bits and up to many, many,\nmany, many, many to, to the N levels of states.",
        "start": 2014.559,
        "duration": 4.84
    },
    {
        "text": "Which is significant, I think for the types\nof operations and the types of hierarchical",
        "start": 2019.399,
        "duration": 5.74
    },
    {
        "text": "and complex patterns that we look for in machine\nlearning, which could lead to potentially",
        "start": 2025.139,
        "duration": 4.62
    },
    {
        "text": "like even more cool perception or perception\noriented activities.",
        "start": 2029.759,
        "duration": 4.221
    },
    {
        "text": "The second is most of the time today, it's\nvery computationally intensive to train these",
        "start": 2033.98,
        "duration": 4.75
    },
    {
        "text": "algorithms.",
        "start": 2038.73,
        "duration": 1.0
    },
    {
        "text": "So you make the system smart, you bake up\nthe smarts, lets say I'm in a very large cloud",
        "start": 2039.73,
        "duration": 4.99
    },
    {
        "text": "computing architecture.",
        "start": 2044.72,
        "duration": 1.699
    },
    {
        "text": "So Google and Facebook, et cetera, they're\ndoing most of this work today centrally, but",
        "start": 2046.419,
        "duration": 4.161
    },
    {
        "text": "all of the big companies, Google, Apple, I'd\nassume Facebook in some way because of Google",
        "start": 2050.58,
        "duration": 4.53
    },
    {
        "text": "and Apple is, Facebook is as well.",
        "start": 2055.11,
        "duration": 1.02
    },
    {
        "text": "They're spending a lot of energy right now\nto push the training of the algorithms out",
        "start": 2056.13,
        "duration": 4.789
    },
    {
        "text": "onto mobile devices, which means your device\nwill really start to know you.",
        "start": 2060.919,
        "duration": 5.561
    },
    {
        "text": "It will track your data and it will be personalized\nto how you write messages, what you like,",
        "start": 2066.48,
        "duration": 5.26
    },
    {
        "text": "what pictures you're interested in, etc.",
        "start": 2071.74,
        "duration": 2.51
    },
    {
        "text": "And the caveat here is we go, as we think\nabout privacy, that could be super creepy",
        "start": 2074.25,
        "duration": 5.369
    },
    {
        "text": "if these large companies then get access to\nall of that data.",
        "start": 2079.619,
        "duration": 3.21
    },
    {
        "text": "But from what I know, they actually are making\nattempts to do this right where they're using",
        "start": 2082.829,
        "duration": 4.751
    },
    {
        "text": "some new, uh, privacy techniques called differential\nprivacy encryption techniques, homomorphic",
        "start": 2087.58,
        "duration": 5.089
    },
    {
        "text": "encryption to make sure that Google never\nactually gets access to this fundamental personal",
        "start": 2092.669,
        "duration": 5.281
    },
    {
        "text": "data.",
        "start": 2097.95,
        "duration": 1.01
    },
    {
        "text": "And if we think about edge computing, so all\nof our little toasters and shower heads and",
        "start": 2098.96,
        "duration": 4.5
    },
    {
        "text": "everything connected to the internet today,\nall that information has to come back to a",
        "start": 2103.46,
        "duration": 3.659
    },
    {
        "text": "centralized server to then make it back to\nyour fridge to tell you what to cook next.",
        "start": 2107.119,
        "duration": 3.881
    },
    {
        "text": "But if that processing exists out on the edge,\nI think it could lead to some startling new",
        "start": 2111.0,
        "duration": 6.21
    },
    {
        "text": "applications.",
        "start": 2117.21,
        "duration": 1.0
    },
    {
        "text": "So that's for me, that's the sort of cool,\nsuper exciting area.",
        "start": 2118.21,
        "duration": 2.68
    },
    {
        "text": "I just want to add one thing.",
        "start": 2120.89,
        "duration": 1.449
    },
    {
        "text": "I think that the area of augmented reality\nis very exciting, right?",
        "start": 2122.339,
        "duration": 4.071
    },
    {
        "text": "So that's kind of the machine learning coming\ntogether with some of the processing power",
        "start": 2126.41,
        "duration": 4.59
    },
    {
        "text": "that Catherine was talking about.",
        "start": 2131.0,
        "duration": 2.72
    },
    {
        "text": "I think that's a world that we're augmentation\nwill be really cool, sort of, you know, the",
        "start": 2133.72,
        "duration": 6.66
    },
    {
        "text": "world seems to be heading that way because\nmachine learning has become good enough to",
        "start": 2140.38,
        "duration": 3.81
    },
    {
        "text": "facilitate that kind of stuff.",
        "start": 2144.19,
        "duration": 2.69
    },
    {
        "text": "Hardware is kind of, you know, so the algorithms,\nthe AGI that we're talking about, good enough,",
        "start": 2146.88,
        "duration": 4.77
    },
    {
        "text": "the hardware power is there, the speed is\nthere.",
        "start": 2151.65,
        "duration": 2.05
    },
    {
        "text": "So it sort of, that's what I would expect\nto see a lot of augmentation happening.",
        "start": 2153.7,
        "duration": 5.19
    },
    {
        "text": "Yeah, imagine kids taking a field trip to\nthe Great Barrier Reef and swimming around",
        "start": 2158.89,
        "duration": 4.59
    },
    {
        "text": "presuming that we don't kill the earth but\nglobal warming and it still exists soon, there's",
        "start": 2163.48,
        "duration": 3.589
    },
    {
        "text": "another problem that we're not talking about,\nbut like, you know, and they could, they could",
        "start": 2167.069,
        "duration": 2.751
    },
    {
        "text": "snorkel around and have their little glasses\non and have the taxonomy of the fish be identified",
        "start": 2169.82,
        "duration": 5.67
    },
    {
        "text": "in real time and.",
        "start": 2175.49,
        "duration": 1.23
    },
    {
        "text": "Right.",
        "start": 2176.72,
        "duration": 1.0
    },
    {
        "text": "So you could like, education could be awesome\nwith, with augmented reality, you could take",
        "start": 2177.72,
        "duration": 3.879
    },
    {
        "text": "a walk through the park and have your botany\nglasses on, you know?",
        "start": 2181.599,
        "duration": 3.52
    },
    {
        "text": "Yeah.",
        "start": 2185.119,
        "duration": 1.0
    },
    {
        "text": "Some people actually creating sort of doing\nscience labs where you, sort of, use sort",
        "start": 2186.119,
        "duration": 4.331
    },
    {
        "text": "of augmented reality or virtual reality where\nyou go in and you can kind of do sort of experiments",
        "start": 2190.45,
        "duration": 5.75
    },
    {
        "text": "in virtual labs and things like that.",
        "start": 2196.2,
        "duration": 2.72
    },
    {
        "text": "But just the comment on a sort of this your\nquestion.",
        "start": 2198.92,
        "duration": 4.8
    },
    {
        "text": "While I already mentioned the brain machine\ninterfaces and it's already been used.",
        "start": 2203.72,
        "duration": 4.73
    },
    {
        "text": "I mean, so they have people, sort of like\none person sort of like people who are paralyzed",
        "start": 2208.45,
        "duration": 5.369
    },
    {
        "text": "now for example, there being computer, there'll\nbe wired to computers and they can now or",
        "start": 2213.819,
        "duration": 5.131
    },
    {
        "text": "they're training them to be able to move different\nthings using their mind to type, you know,",
        "start": 2218.95,
        "duration": 4.48
    },
    {
        "text": "sort of things on computers, etc. etc.",
        "start": 2223.43,
        "duration": 2.05
    },
    {
        "text": "There are also people implanting things into\ntheir body so that they can use it to open",
        "start": 2225.48,
        "duration": 5.349
    },
    {
        "text": "doors to, you know, pay at checkout counters\nand you can see that sort of.",
        "start": 2230.829,
        "duration": 5.501
    },
    {
        "text": "I mean there was this guy with an antenna\non the head, so all that, oh that's actually",
        "start": 2236.33,
        "duration": 6.62
    },
    {
        "text": "been done.",
        "start": 2242.95,
        "duration": 1.0
    },
    {
        "text": "And there's a lot more integration.",
        "start": 2243.95,
        "duration": 1.69
    },
    {
        "text": "And again, and you know, at DARPA is really\nat the forefront of a lot of these technologies",
        "start": 2245.64,
        "duration": 6.87
    },
    {
        "text": "and they're trying to get people to, there's\nsomething called the silent top program where",
        "start": 2252.51,
        "duration": 5.13
    },
    {
        "text": "they're trying to get soldiers to be able\nto talk to each other using their mind.",
        "start": 2257.64,
        "duration": 3.16
    },
    {
        "text": "They're really, they're trying to do that\nwithin the next five years.",
        "start": 2260.8,
        "duration": 2.98
    },
    {
        "text": "That was what near mandate.",
        "start": 2263.78,
        "duration": 1.15
    },
    {
        "text": "Within five years we want to close loop system\nwhere the machine can automatically monitor",
        "start": 2264.93,
        "duration": 5.3
    },
    {
        "text": "what's going on out there and be able to put\nthat into the user.",
        "start": 2270.23,
        "duration": 4.839
    },
    {
        "text": "Right",
        "start": 2275.069,
        "duration": 1.0
    },
    {
        "text": "Intelligent, autonomous nervous system, the\noutside world, the augmented reality stuff",
        "start": 2276.069,
        "duration": 4.941
    },
    {
        "text": "is basically Her as a guide to the outside\nworld",
        "start": 2281.01,
        "duration": 3.66
    },
    {
        "text": "That's exactly right.",
        "start": 2284.67,
        "duration": 1.0
    },
    {
        "text": "So yeah, so I think Kathryn described many\nof these, what I would call technology enablers.",
        "start": 2285.67,
        "duration": 5.42
    },
    {
        "text": "I think quantum has definitely, you know,\nit has enormous potential IBM is so huge.",
        "start": 2291.09,
        "duration": 6.259
    },
    {
        "text": "It's a huge direction for IBM and its impact\nwill be enormous.",
        "start": 2297.349,
        "duration": 4.831
    },
    {
        "text": "I mean just in terms of computation and computation\nis important.",
        "start": 2302.18,
        "duration": 4.11
    },
    {
        "text": "I mean it's actually one of the primary things\nthat's driving our ability to learn more complex",
        "start": 2306.29,
        "duration": 5.68
    },
    {
        "text": "models and more sophisticated, sophisticated\nknowledge and, and so on.",
        "start": 2311.97,
        "duration": 5.73
    },
    {
        "text": "But what are the areas that I'm very interested\nin, is its application of AI is to creativity",
        "start": 2317.7,
        "duration": 5.95
    },
    {
        "text": "and if you think about it, you know, the sort\nof the spectrum of artificial intelligence.",
        "start": 2323.65,
        "duration": 4.26
    },
    {
        "text": "We talked a lot about perception, the ability\nto see and hear and speak and, and, and, and",
        "start": 2327.91,
        "duration": 6.871
    },
    {
        "text": "so on.",
        "start": 2334.781,
        "duration": 1.0
    },
    {
        "text": "Then at the middle maybe we have more about\nknowledge and reasoning, but then where, where,",
        "start": 2335.781,
        "duration": 5.089
    },
    {
        "text": "where's creativity?",
        "start": 2340.87,
        "duration": 1.0
    },
    {
        "text": "I think creativity is even, you know, at,\nat the further end of the spectrum.",
        "start": 2341.87,
        "duration": 2.87
    },
    {
        "text": "And I think it's even harder to answer the\nquestion, “what is creativity?” then it",
        "start": 2344.74,
        "duration": 6.4
    },
    {
        "text": "may be to answer “what is intelligence?”",
        "start": 2351.14,
        "duration": 3.439
    },
    {
        "text": "We can sort of describe a few attributes of\ncreativity.",
        "start": 2354.579,
        "duration": 6.091
    },
    {
        "text": "But it's hard to really know what is, what\nis happening and it's, it's really entirely",
        "start": 2360.67,
        "duration": 5.48
    },
    {
        "text": "a human endeavor today.",
        "start": 2366.15,
        "duration": 2.459
    },
    {
        "text": "So I like to think of myself as an engineer.",
        "start": 2368.609,
        "duration": 2.581
    },
    {
        "text": "It's about, it's all about method, but what\ncreative people do, to me, it still seems",
        "start": 2371.19,
        "duration": 5.4
    },
    {
        "text": "to be magic somehow.",
        "start": 2376.59,
        "duration": 2.21
    },
    {
        "text": "We did a project at IBM in this last year\naround horror movies.",
        "start": 2378.8,
        "duration": 5.18
    },
    {
        "text": "We actually got Watson to watch hundreds of\nhorror movies.",
        "start": 2383.98,
        "duration": 4.42
    },
    {
        "text": "So I like to think we sent it to film school.",
        "start": 2388.4,
        "duration": 3.23
    },
    {
        "text": "I also like to think I went from teaching\nWatson to see, to teaching Watson to feel,",
        "start": 2391.63,
        "duration": 5.53
    },
    {
        "text": "because really what we were able to encode\na Watson to do around these horror movies",
        "start": 2397.16,
        "duration": 4.909
    },
    {
        "text": "was, you know, not only, you know, not just\nsee a objects and scenes and people and transcribed",
        "start": 2402.069,
        "duration": 8.231
    },
    {
        "text": "speech, but characterize the content in terms\nof emotion.",
        "start": 2410.3,
        "duration": 4.83
    },
    {
        "text": "So it was a scene that it sounds scary?",
        "start": 2415.13,
        "duration": 2.709
    },
    {
        "text": "Did you know, did a scene look happy?",
        "start": 2417.839,
        "duration": 3.921
    },
    {
        "text": "Or did know, did it look, did it look sad?",
        "start": 2421.76,
        "duration": 2.91
    },
    {
        "text": "You know, something like that.",
        "start": 2424.67,
        "duration": 2.0
    },
    {
        "text": "And through these algorithms we were able\nto get Watson, you know, able to make a fairly",
        "start": 2426.67,
        "duration": 6.08
    },
    {
        "text": "good assessment of horror movies, but also\na horror movie trailers.",
        "start": 2432.75,
        "duration": 5.079
    },
    {
        "text": "We learned the patterns for making a horror\ntrailer.",
        "start": 2437.829,
        "duration": 4.01
    },
    {
        "text": "Essentially it came down to three things.",
        "start": 2441.839,
        "duration": 2.131
    },
    {
        "text": "The scenes at a horror movie, a movie trailer\nare either suspenseful, scary or tender.",
        "start": 2443.97,
        "duration": 7.109
    },
    {
        "text": "That's it, but you need, you need all three.",
        "start": 2451.079,
        "duration": 2.79
    },
    {
        "text": "I mean, you know, the, contrast is there and\nwe were able to take that simple recipe, apply",
        "start": 2453.869,
        "duration": 6.641
    },
    {
        "text": "it to a brand new horror movie and have Watson\ndo a significant part of making the trailer",
        "start": 2460.51,
        "duration": 8.21
    },
    {
        "text": "for that movie.",
        "start": 2468.72,
        "duration": 1.29
    },
    {
        "text": "We just needed a film editor to come in and\nwithin one day, you know, create an entire",
        "start": 2470.01,
        "duration": 4.48
    },
    {
        "text": "trailer for the movie.",
        "start": 2474.49,
        "duration": 1.54
    },
    {
        "text": "So it's a good example of taking something\nwhich is, you know, might be a three month",
        "start": 2476.03,
        "duration": 3.75
    },
    {
        "text": "effort for a production team, you know, down\nto, you know, computer assisted task which",
        "start": 2479.78,
        "duration": 5.85
    },
    {
        "text": "happened in a day.",
        "start": 2485.63,
        "duration": 2.75
    },
    {
        "text": "But I think this just scratches the surface.",
        "start": 2488.38,
        "duration": 1.78
    },
    {
        "text": "I think it points to a lot of potential for\nthe computer to be an assistant to augment",
        "start": 2490.16,
        "duration": 6.43
    },
    {
        "text": "the creative process, to do some of the mundane\nwork.",
        "start": 2496.59,
        "duration": 4.59
    },
    {
        "text": "The computer has no problem watching every\nmovie that was ever made.",
        "start": 2501.18,
        "duration": 3.1
    },
    {
        "text": "If it comes down to it and can extract insights\nand you know, it can really be an aid to the",
        "start": 2504.28,
        "duration": 5.27
    },
    {
        "text": "creative person.",
        "start": 2509.55,
        "duration": 1.569
    },
    {
        "text": "Certainly in filmmaking, but it goes beyond,\ncertainly goes beyond making movies.",
        "start": 2511.119,
        "duration": 5.131
    },
    {
        "text": "There's a cool a trend in the computer vision\nworld they call it style transfer.",
        "start": 2516.25,
        "duration": 4.96
    },
    {
        "text": "And this was a neat; I find this a neat accidental\nbyproduct of the research process.",
        "start": 2521.21,
        "duration": 5.45
    },
    {
        "text": "So as people were trying to hone the algorithms\nto do the type of work that john mentioned,",
        "start": 2526.66,
        "duration": 6.27
    },
    {
        "text": "so come vision perceptions, a computer vision\nand perception.",
        "start": 2532.93,
        "duration": 3.1
    },
    {
        "text": "So being able to accurately label a picture\naccording to its content.",
        "start": 2536.03,
        "duration": 4.029
    },
    {
        "text": "To do that, they have to pass it through this\nnetwork and it twists and turns and transforms",
        "start": 2540.059,
        "duration": 5.581
    },
    {
        "text": "the input image and gradually gets rid of\nall the noise so that it can focus on the",
        "start": 2545.64,
        "duration": 4.709
    },
    {
        "text": "general representation that can be affiliated\nwith a linguistic term.",
        "start": 2550.349,
        "duration": 3.651
    },
    {
        "text": "Cat, dog, glass of wine is I've been using\nduring the, during the presentation.",
        "start": 2554.0,
        "duration": 3.839
    },
    {
        "text": "So as there was a group of researchers who\nnoticed that that noise that got removed just",
        "start": 2557.839,
        "duration": 5.261
    },
    {
        "text": "so happened to be what we call artistic style\nwhen they put in painting.",
        "start": 2563.1,
        "duration": 4.16
    },
    {
        "text": "So if you put in Van Gogh's, Starry Night\nand you pass it through these algorithms,",
        "start": 2567.26,
        "duration": 4.41
    },
    {
        "text": "it will pull out the Starry Nightness.",
        "start": 2571.67,
        "duration": 3.14
    },
    {
        "text": "And then you can impose that on your, your\nfavorite selfie on your Facebook page.",
        "start": 2574.81,
        "duration": 4.039
    },
    {
        "text": "Right?",
        "start": 2578.849,
        "duration": 1.0
    },
    {
        "text": "So this, I think this actually there's the\nart critical community has different views",
        "start": 2579.849,
        "duration": 3.51
    },
    {
        "text": "on this.",
        "start": 2583.359,
        "duration": 1.0
    },
    {
        "text": "Some people say is kitsch, right?",
        "start": 2584.359,
        "duration": 2.23
    },
    {
        "text": "It's ridiculous that, you know, are selfies,\ncan become a Rembrandt.",
        "start": 2586.589,
        "duration": 3.441
    },
    {
        "text": "On the flip side, it actually is a really,\nit's sort of democratizes the skillset around",
        "start": 2590.03,
        "duration": 4.09
    },
    {
        "text": "art.",
        "start": 2594.12,
        "duration": 1.0
    },
    {
        "text": "So there's an app called Picazzo and I've\nhad some conversations with the CEO of the",
        "start": 2595.12,
        "duration": 3.59
    },
    {
        "text": "app who said, well, the critics panned it.",
        "start": 2598.71,
        "duration": 2.349
    },
    {
        "text": "He had this influx of emails from people just\nlike you and I who were like, oh my god, I",
        "start": 2601.059,
        "duration": 6.161
    },
    {
        "text": "always wanted to paint, but I just don't have\ntime to learn it and now I feel like I have",
        "start": 2607.22,
        "duration": 3.21
    },
    {
        "text": "this like I have this agency and I can go\nand I can make a Kandinsky and I can make",
        "start": 2610.43,
        "duration": 4.53
    },
    {
        "text": "a you know, and I can make my own Mondrian\nor whatever, and the commercial applications",
        "start": 2614.96,
        "duration": 6.03
    },
    {
        "text": "or that, you know, you can be.",
        "start": 2620.99,
        "duration": 1.14
    },
    {
        "text": "I've done a lot of work in startups and we've\ngot no budget so we can't afford $50,000 branding",
        "start": 2622.13,
        "duration": 4.82
    },
    {
        "text": "agencies.",
        "start": 2626.95,
        "duration": 1.18
    },
    {
        "text": "But it's really cool when you don't have to\nhire that that, you can pull up this app and",
        "start": 2628.13,
        "duration": 4.09
    },
    {
        "text": "you can for five cents, make a really professional\nneeds, stylistic website.",
        "start": 2632.22,
        "duration": 5.97
    },
    {
        "text": "So, so it's not, you know, it's not quite\ncreatively like we think of it, but there",
        "start": 2638.19,
        "duration": 4.72
    },
    {
        "text": "is the sacrosanct newness of, of the, you\nknow, of genius and art gets, it forces us",
        "start": 2642.91,
        "duration": 7.47
    },
    {
        "text": "to ask these big philosophical questions about\nwhat we value in society when we see that",
        "start": 2650.38,
        "duration": 4.46
    },
    {
        "text": "this happens and it also leads to this whole\nfrom an epistemological and cognitive perspective,",
        "start": 2654.84,
        "duration": 6.59
    },
    {
        "text": "it's teaching us and it's inspired some research\non the correlations between how we see and",
        "start": 2661.43,
        "duration": 5.1
    },
    {
        "text": "align language with the world that we process\nand then how we make art and what's and what",
        "start": 2666.53,
        "duration": 4.91
    },
    {
        "text": "qualifies as style.",
        "start": 2671.44,
        "duration": 1.23
    },
    {
        "text": "So I think that's just also super cool.",
        "start": 2672.67,
        "duration": 2.85
    },
    {
        "text": "You know, consequences of this, of this moment.",
        "start": 2675.52,
        "duration": 2.339
    },
    {
        "text": "Well, let me just ask John on the creativity\nside, because you guys had done stuff with",
        "start": 2677.859,
        "duration": 4.01
    },
    {
        "text": "a cooking and other things.",
        "start": 2681.869,
        "duration": 2.771
    },
    {
        "text": "Where do you kind of come out on this, anybody's\ndoing any kind of real reporting, a research",
        "start": 2684.64,
        "duration": 10.36
    },
    {
        "text": "about artificial intelligence.",
        "start": 2695.0,
        "duration": 1.0
    },
    {
        "text": "I mean, you kind of come away with a credible\nappreciation for what we call general human",
        "start": 2696.0,
        "duration": 4.65
    },
    {
        "text": "intelligence, right?",
        "start": 2700.65,
        "duration": 1.0
    },
    {
        "text": "And only 20 watts, you know, low power, you\nknow, it just, and it feeds into this the",
        "start": 2701.65,
        "duration": 5.899
    },
    {
        "text": "AI debate I was in particularly the brain.",
        "start": 2707.549,
        "duration": 2.951
    },
    {
        "text": "I mean, is it good?",
        "start": 2710.5,
        "duration": 1.0
    },
    {
        "text": "Is it an inspirational metaphor or is it a\nroadmap?",
        "start": 2711.5,
        "duration": 3.33
    },
    {
        "text": "Computers do not work like the human brain,\nyou know, they are not 20 watts and you know,",
        "start": 2714.83,
        "duration": 6.32
    },
    {
        "text": "and they are very fast, but they're not massively\nparallel, It's a very different ability which",
        "start": 2721.15,
        "duration": 9.689
    },
    {
        "text": "can have great impact, uh, certainly for data\nprocessing and making, you know, finding patterns",
        "start": 2730.839,
        "duration": 6.49
    },
    {
        "text": "and making predictions, that's really, it's\nstrength, but in terms of replacing that 20",
        "start": 2737.329,
        "duration": 5.321
    },
    {
        "text": "watts of, of, of human ability that they bring,\num, you know, I think we have a ways to go.",
        "start": 2742.65,
        "duration": 6.24
    },
    {
        "text": "Yeah.",
        "start": 2748.89,
        "duration": 1.0
    },
    {
        "text": "It reminds me that famous line by, one of\nthe pioneers in voice recognition who worked",
        "start": 2749.89,
        "duration": 5.04
    },
    {
        "text": "for IBM for Fred Jelenik is he explained it,\nyou know, airplanes don't flap their wings.",
        "start": 2754.93,
        "duration": 5.62
    },
    {
        "text": "You can, they do it differently.",
        "start": 2760.55,
        "duration": 1.74
    },
    {
        "text": "Yeah, that's right.",
        "start": 2762.29,
        "duration": 1.0
    },
    {
        "text": "And I think there is some, you said, is it\na metaphor?",
        "start": 2763.29,
        "duration": 3.48
    },
    {
        "text": "Yeah, certainly there's a lot there because\nwhatever biological systems, you know, human",
        "start": 2766.77,
        "duration": 8.25
    },
    {
        "text": "cognition perception, it's the best system\nwe know.",
        "start": 2775.02,
        "duration": 4.38
    },
    {
        "text": "So we can learn.",
        "start": 2779.4,
        "duration": 1.72
    },
    {
        "text": "We can certainly learn a lot by knowing, you\nknow, knowing it better, you know, knowing",
        "start": 2781.12,
        "duration": 4.77
    },
    {
        "text": "how it works, it doesn't necessarily mean\nthat's how we should build our computers.",
        "start": 2785.89,
        "duration": 4.63
    },
    {
        "text": "So I just want to comment on the creativity.",
        "start": 2790.52,
        "duration": 2.079
    },
    {
        "text": "I'm not sure if it's true that machines can\nbe more creative than we are.",
        "start": 2792.599,
        "duration": 5.401
    },
    {
        "text": "Just give one example: take like AlphaGo,\nright.",
        "start": 2798.0,
        "duration": 3.16
    },
    {
        "text": "So, uh, when he was playing Lee Sedol, and\nhe made this move is like the 34th movie.",
        "start": 2801.16,
        "duration": 5.649
    },
    {
        "text": "It was like a move that nobody had ever made.",
        "start": 2806.809,
        "duration": 3.371
    },
    {
        "text": "Uh you might think creativity, just in terms\nof being able to come up with a come up with",
        "start": 2810.18,
        "duration": 5.439
    },
    {
        "text": "solutions or sort of conceptual space that\nhasn't been thought of before.",
        "start": 2815.619,
        "duration": 4.341
    },
    {
        "text": "Right?",
        "start": 2819.96,
        "duration": 1.0
    },
    {
        "text": "And to that extent it does satisfy that criteria\nof creativity came up with ideas that haven't",
        "start": 2820.96,
        "duration": 5.139
    },
    {
        "text": "been thought of before and I think machines\nare going to be able to do that.",
        "start": 2826.099,
        "duration": 3.391
    },
    {
        "text": "They're going to be able to locate spaces\nwhere we haven't been to before.",
        "start": 2829.49,
        "duration": 4.76
    },
    {
        "text": "So, I don't know what you think about that?",
        "start": 2834.25,
        "duration": 2.66
    },
    {
        "text": "I even when Kasparov played against Deep Blue\nand in chess, he reached the point where he,",
        "start": 2836.91,
        "duration": 6.57
    },
    {
        "text": "you know, he felt that the computer was not\nplaying fair, right.",
        "start": 2843.48,
        "duration": 4.03
    },
    {
        "text": "Or there was really a person behind it, right?",
        "start": 2847.51,
        "duration": 2.51
    },
    {
        "text": "Because of whatever move Deep Blue had made,\nit just didn't seem logical to him.",
        "start": 2850.02,
        "duration": 5.26
    },
    {
        "text": "Right.",
        "start": 2855.28,
        "duration": 1.0
    },
    {
        "text": "So, you know, I think there is, but in the\nend, what was the Deep Blue?",
        "start": 2856.28,
        "duration": 3.15
    },
    {
        "text": "Deep Blue was a massive search system.",
        "start": 2859.43,
        "duration": 3.12
    },
    {
        "text": "There was no intelligence there, right?",
        "start": 2862.55,
        "duration": 1.97
    },
    {
        "text": "You know, in, in the way we think, you know,\nabout a lot of the problems in AI.",
        "start": 2864.52,
        "duration": 5.64
    },
    {
        "text": "It just was a brute force search problem.",
        "start": 2870.16,
        "duration": 3.429
    },
    {
        "text": "So sometimes we might ascribe some of these\nqualities to it, but certainly knowing what",
        "start": 2873.589,
        "duration": 5.891
    },
    {
        "text": "was behind the curtain, you wouldn't say,\nyou know, Deep Blue was creative.",
        "start": 2879.48,
        "duration": 4.21
    },
    {
        "text": "I see.",
        "start": 2883.69,
        "duration": 1.0
    },
    {
        "text": "I think we, we're talking about like two types\nof creativity here.",
        "start": 2884.69,
        "duration": 4.42
    },
    {
        "text": "I think what Matthew alluded to was sort of\nmore in the realm of reinforcement learning",
        "start": 2889.11,
        "duration": 6.18
    },
    {
        "text": "are we Kathryn mentioned, supervised or unsupervised.",
        "start": 2895.29,
        "duration": 2.62
    },
    {
        "text": "There's reinforcement where the reward is\ndelayed, right?",
        "start": 2897.91,
        "duration": 3.629
    },
    {
        "text": "And so, what Deep Mind has been really masterful\nthat is just sort of pushing the limits in",
        "start": 2901.539,
        "duration": 7.76
    },
    {
        "text": "terms of reinforcement learning, which in\nsimple terms boils down to, you know, you",
        "start": 2909.299,
        "duration": 5.23
    },
    {
        "text": "have an evaluation function, you're here,\nyou can evaluate sort of what got you there,",
        "start": 2914.529,
        "duration": 4.891
    },
    {
        "text": "but then what's the remaining thing to the\nend of the game?",
        "start": 2919.42,
        "duration": 2.939
    },
    {
        "text": "And that's kind of a recursive kind of problem\nand they become really good at solving that",
        "start": 2922.359,
        "duration": 6.581
    },
    {
        "text": "problem.",
        "start": 2928.94,
        "duration": 1.0
    },
    {
        "text": "And so a machine may make a move and you said,\nwow, that's never happened before, that's",
        "start": 2929.94,
        "duration": 3.01
    },
    {
        "text": "creative.",
        "start": 2932.95,
        "duration": 1.0
    },
    {
        "text": "But there's another aspect of creativity that\nsort of, it seems to be outside the realm",
        "start": 2933.95,
        "duration": 4.24
    },
    {
        "text": "of these kinds of algorithms, which is we\njust find ways to do stuff and we gone quite",
        "start": 2938.19,
        "duration": 5.29
    },
    {
        "text": "describe it, such as even dealing with each\nother.",
        "start": 2943.48,
        "duration": 3.92
    },
    {
        "text": "Right?",
        "start": 2947.4,
        "duration": 1.0
    },
    {
        "text": "And machines are not good at dealing with\npeople at the moment.",
        "start": 2948.4,
        "duration": 2.81
    },
    {
        "text": "Right?",
        "start": 2951.21,
        "duration": 1.0
    },
    {
        "text": "That human machine interface is actually quite\npoor.",
        "start": 2952.21,
        "duration": 2.06
    },
    {
        "text": "They're quite stunted in that sense and a\nlot of the research efforts and creativity,",
        "start": 2954.27,
        "duration": 6.46
    },
    {
        "text": "I think will make a dent in that arena and\njust getting machines to be more empathic",
        "start": 2960.73,
        "duration": 7.379
    },
    {
        "text": "or sort of have the kinds of qualities that\nwe so seamlessly seem to exhibit.",
        "start": 2968.109,
        "duration": 3.72
    },
    {
        "text": "On the flip side, so there's a film called\nTim’s Vermeer and I think it's fantastic.",
        "start": 2971.829,
        "duration": 5.96
    },
    {
        "text": "I think it's fantastic because it, for two\nreasons.",
        "start": 2977.789,
        "duration": 4.591
    },
    {
        "text": "One is it actually forces us to question our\nassumptions around human artistic creativity.",
        "start": 2982.38,
        "duration": 5.86
    },
    {
        "text": "So this is a movie about some guy, Tim.",
        "start": 2988.24,
        "duration": 1.99
    },
    {
        "text": "Uh, he was a designer at Pixar who has a theory\nabout the 17th century Dutch painter Vermeer",
        "start": 2990.23,
        "duration": 7.46
    },
    {
        "text": "and wants to test his theory and he assumes\nthat Vermeer used an optic system that had",
        "start": 2997.69,
        "duration": 5.99
    },
    {
        "text": "two mirrors, one that sort of just reflected\nthe, the world that he was trying to depict.",
        "start": 3003.68,
        "duration": 5.94
    },
    {
        "text": "And then the other one that's sort of shot\nthat reflection down onto a canvas and then,",
        "start": 3009.62,
        "duration": 5.07
    },
    {
        "text": "Tim hypothesizes that he used something like\na paint by number type system to basically",
        "start": 3014.69,
        "duration": 4.98
    },
    {
        "text": "use pigment until there was a color gradient\nbetween what was reflected in what he was",
        "start": 3019.67,
        "duration": 3.74
    },
    {
        "text": "painting.",
        "start": 3023.41,
        "duration": 1.0
    },
    {
        "text": "And the minute it got there he shifted on\nand he just sort of goes through and in a",
        "start": 3024.41,
        "duration": 3.12
    },
    {
        "text": "seemingly extraordinarily uncreative way,\nit made what were the most realistic.",
        "start": 3027.53,
        "duration": 5.29
    },
    {
        "text": "And I, I'm a huge fan.",
        "start": 3032.82,
        "duration": 1.56
    },
    {
        "text": "I mean just tantalizing paintings from the\n17th century that looked radically different",
        "start": 3034.38,
        "duration": 3.38
    },
    {
        "text": "from those of his contemporaries.",
        "start": 3037.76,
        "duration": 2.76
    },
    {
        "text": "So I think what I like about that is it also\nforces us to.",
        "start": 3040.52,
        "duration": 4.069
    },
    {
        "text": "It's this is less about machine creativity\nand more about our assumptions of what qualifies",
        "start": 3044.589,
        "duration": 3.921
    },
    {
        "text": "as artistic creativity.",
        "start": 3048.51,
        "duration": 1.0
    },
    {
        "text": "That has a lot of ramifications also further\nscientific research community.",
        "start": 3049.51,
        "duration": 4.13
    },
    {
        "text": "So, you know, I believe that the myth of the\nsolitary genius who sits there and solves",
        "start": 3053.64,
        "duration": 4.84
    },
    {
        "text": "Fermat’s last theorem, you know, is not\nnecessarily the way that the innovation technology",
        "start": 3058.48,
        "duration": 4.45
    },
    {
        "text": "progresses.",
        "start": 3062.93,
        "duration": 1.0
    },
    {
        "text": "This is very much a back to Her and artificial\ngeneral intelligence, right?",
        "start": 3063.93,
        "duration": 3.36
    },
    {
        "text": "There's, there's stuff going on collectively\nthat we from our, trapped in our bodies.",
        "start": 3067.29,
        "duration": 6.039
    },
    {
        "text": "Subjective viewpoints don't often perceive.",
        "start": 3073.329,
        "duration": 2.061
    },
    {
        "text": "But if we could perceive like who knows what\nmight happen.",
        "start": 3075.39,
        "duration": 2.689
    },
    {
        "text": "The second cool thing about that film is that\nto make this happen, Tim had to reverse engineer",
        "start": 3078.079,
        "duration": 6.151
    },
    {
        "text": "he thought would have been the original scene.",
        "start": 3084.23,
        "duration": 1.68
    },
    {
        "text": "So to do it he has to learn about 17th century\nglasswork and textiles and woodworking.",
        "start": 3085.91,
        "duration": 5.8
    },
    {
        "text": "And it's kind of this engineer's paradise,\nright?",
        "start": 3091.71,
        "duration": 3.409
    },
    {
        "text": "Because within this one single project lies\nof the world is he has to do all, you have",
        "start": 3095.119,
        "duration": 4.335
    },
    {
        "text": "to learn all these things in order to solve\nhis problem.",
        "start": 3099.454,
        "duration": 1.986
    },
    {
        "text": "So I like it as something that also forces\nus to question or are inherited assumptions",
        "start": 3101.44,
        "duration": 5.3
    },
    {
        "text": "of what qualifies as human creativity in the\nfirst place, which can be often very scientific",
        "start": 3106.74,
        "duration": 4.19
    },
    {
        "text": "and constraint oriented.",
        "start": 3110.93,
        "duration": 1.22
    },
    {
        "text": "Are you guys are really worried about what\nyou're doing is, you know, gonna make the",
        "start": 3112.15,
        "duration": 7.429
    },
    {
        "text": "world a rougher place for more people?",
        "start": 3119.579,
        "duration": 2.331
    },
    {
        "text": "I think.",
        "start": 3121.91,
        "duration": 1.0
    },
    {
        "text": "I think IBM is very clear on this.",
        "start": 3122.91,
        "duration": 1.32
    },
    {
        "text": "Um, you know, we've outlined the principles\nhere for AI around three dimensions and we",
        "start": 3124.23,
        "duration": 5.69
    },
    {
        "text": "call it a purpose.",
        "start": 3129.92,
        "duration": 3.48
    },
    {
        "text": "So you know that the role is about augmentation\nof you know, working together with humans",
        "start": 3133.4,
        "duration": 7.58
    },
    {
        "text": "for important industry problems.",
        "start": 3140.98,
        "duration": 3.5
    },
    {
        "text": "Trust that, you know, when we build these\nAI systems will make it very clear how those",
        "start": 3144.48,
        "duration": 5.2
    },
    {
        "text": "models were, were learned when AI is being\nused, what data is behind it, you know, and",
        "start": 3149.68,
        "duration": 8.56
    },
    {
        "text": "so on.",
        "start": 3158.24,
        "duration": 1.0
    },
    {
        "text": "And then the, and then the third is skill.",
        "start": 3159.24,
        "duration": 1.26
    },
    {
        "text": "It actually comes back to how these systems\nare trained that they are, that they will",
        "start": 3160.5,
        "duration": 4.65
    },
    {
        "text": "learn from the human experts, you know, that,\nit is about taking all of that human expertise",
        "start": 3165.15,
        "duration": 8.439
    },
    {
        "text": "and trying to make a joint computer human\ncapability that's even better.",
        "start": 3173.589,
        "duration": 6.581
    },
    {
        "text": "That can help scale expertise, you know, can\nhelp, solve difficult industry problems.",
        "start": 3180.17,
        "duration": 6.06
    },
    {
        "text": "So I think we're very optimistic in, you know,\nin the, in the potential if we follow these",
        "start": 3186.23,
        "duration": 5.609
    },
    {
        "text": "three things,",
        "start": 3191.839,
        "duration": 1.591
    },
    {
        "text": "Don’t feel compelled if you don't, but if\nyou, if you got to put a strong point of view,",
        "start": 3193.43,
        "duration": 5.11
    },
    {
        "text": "I'd like to hear.",
        "start": 3198.54,
        "duration": 1.18
    },
    {
        "text": "Yeah, I worry, I don't have that optimistic\nprognosis on employment.",
        "start": 3199.72,
        "duration": 5.94
    },
    {
        "text": "I think the worldview of a cool place, they'll,\nit'll be amazing machines, augmented reality,",
        "start": 3205.66,
        "duration": 5.159
    },
    {
        "text": "all kinds of stuff.",
        "start": 3210.819,
        "duration": 1.0
    },
    {
        "text": "You know, my wife yesterday showed me a Groupon\ncoupon for data scientists.",
        "start": 3211.819,
        "duration": 5.121
    },
    {
        "text": "So did you expect to see this?",
        "start": 3216.94,
        "duration": 1.919
    },
    {
        "text": "I was like, no, that's really interesting.",
        "start": 3218.859,
        "duration": 2.601
    },
    {
        "text": "Um, and that kind of tells you were sort of\npeople are focusing on, but that's, you know,",
        "start": 3221.46,
        "duration": 6.849
    },
    {
        "text": "everyone can be a data scientist, and if machines\nare making of these decisions better than",
        "start": 3228.309,
        "duration": 5.351
    },
    {
        "text": "us, that we'll be doing something else.",
        "start": 3233.66,
        "duration": 1.24
    },
    {
        "text": "I don't know what that is.",
        "start": 3234.9,
        "duration": 1.28
    },
    {
        "text": "Hard to say, what it's going to do for employment,\nbut like I said, I worry about inequality.",
        "start": 3236.18,
        "duration": 5.52
    },
    {
        "text": "Okay.",
        "start": 3241.7,
        "duration": 1.0
    },
    {
        "text": "I kind of side with the economists here.",
        "start": 3242.7,
        "duration": 1.329
    },
    {
        "text": "I think there's been multiple technology revolutions\nhistorically and that jobs haven't disappeared.",
        "start": 3244.029,
        "duration": 5.721
    },
    {
        "text": "And if you look through the history, I may\ncome from a sort of history philosophy background.",
        "start": 3249.75,
        "duration": 4.67
    },
    {
        "text": "People have worried about the same things\ntime and time again.",
        "start": 3254.42,
        "duration": 2.04
    },
    {
        "text": "We talked about it with, there's this film\nand from 1957 “Desk Set” where I'm Katharine",
        "start": 3256.46,
        "duration": 4.451
    },
    {
        "text": "Hepburn and Spencer Tracy screwball comedy,\nabsolutely fantastic.",
        "start": 3260.911,
        "duration": 2.989
    },
    {
        "text": "They were all worried they're gonna lose their\njobs in the sixties.",
        "start": 3263.9,
        "duration": 2.23
    },
    {
        "text": "And it didn't happen because the computer.",
        "start": 3266.13,
        "duration": 4.96
    },
    {
        "text": "I also do think though that the fact that\nwhite collar jobs, subtasks of white collar",
        "start": 3271.09,
        "duration": 6.11
    },
    {
        "text": "jobs like investment banking, wiring, accounting,\ndoctors, etc. pushes a sensitive button in",
        "start": 3277.2,
        "duration": 5.579
    },
    {
        "text": "today's contemporary society.",
        "start": 3282.779,
        "duration": 1.361
    },
    {
        "text": "So there's a lot of people in the world today\nwho have horrible jobs, they’re jobs they",
        "start": 3284.14,
        "duration": 2.479
    },
    {
        "text": "don't really want and we don't think about\nthem, were worried about the fancy things.",
        "start": 3286.619,
        "duration": 3.681
    },
    {
        "text": "And I think it tells us, actually some people\nare worried about sort of, self driving cars",
        "start": 3290.3,
        "duration": 4.6
    },
    {
        "text": "and what that's gonna do the trucking industry\nas well.",
        "start": 3294.9,
        "duration": 2.65
    },
    {
        "text": "And obviously with the manufacturing industry.",
        "start": 3297.55,
        "duration": 2.9
    },
    {
        "text": "But, I think that I, the fact that, you know,\ncognitive tasks are often hyper specialized,",
        "start": 3300.45,
        "duration": 7.45
    },
    {
        "text": "which is a great candidate for narrow, narrow\nintelligence leads to some discomfort with",
        "start": 3307.9,
        "duration": 6.429
    },
    {
        "text": "the way in which our society is currently\nconstructed that people are reacting to.",
        "start": 3314.329,
        "duration": 4.091
    },
    {
        "text": "So I think that there is going to be some\nsort of a, it's going to transform our society,",
        "start": 3318.42,
        "duration": 5.159
    },
    {
        "text": "there's going to be transitioned costs, so\npeople are gonna lose their jobs and it's",
        "start": 3323.579,
        "duration": 4.571
    },
    {
        "text": "not so easy to retrain people, you know, especially\nif you're in your fifties, etc. etc. to try",
        "start": 3328.15,
        "duration": 5.409
    },
    {
        "text": "to retrain, to say, oh, you can take a course\non data mining as you know, it's very hard.",
        "start": 3333.559,
        "duration": 6.24
    },
    {
        "text": "Right?",
        "start": 3339.799,
        "duration": 1.0
    },
    {
        "text": "And so that's going to, it's going to hurt\na lot of people and so I do think that we",
        "start": 3340.799,
        "duration": 3.201
    },
    {
        "text": "need a discussion in our society about the\nunique qualities that are going to result,",
        "start": 3344.0,
        "duration": 4.339
    },
    {
        "text": "you know, so in the long run, maybe so just\nlike, when we transition from horse buggies",
        "start": 3348.339,
        "duration": 5.681
    },
    {
        "text": "to cars, right, people lost jobs, etc. etc.",
        "start": 3354.02,
        "duration": 3.349
    },
    {
        "text": "We need to be able to do this this time, it's\ngoing to happen even faster.",
        "start": 3357.369,
        "duration": 4.561
    },
    {
        "text": "Right?",
        "start": 3361.93,
        "duration": 1.0
    },
    {
        "text": "And so we as a society need to be able to\ndeal with that transition and how do we help",
        "start": 3362.93,
        "duration": 4.839
    },
    {
        "text": "these people?",
        "start": 3367.769,
        "duration": 1.0
    },
    {
        "text": "Do we do something like universal basic income,\netc. etc.",
        "start": 3368.769,
        "duration": 3.54
    },
    {
        "text": "But we do need to have that conversation.",
        "start": 3372.309,
        "duration": 2.141
    },
    {
        "text": "Otherwise the inequality is going to be hugely\nexacerbate it and that's going to be really",
        "start": 3374.45,
        "duration": 5.589
    },
    {
        "text": "bad.",
        "start": 3380.039,
        "duration": 1.29
    },
    {
        "text": "Technologists should be part of that debate\nas opposed to just the public policy people",
        "start": 3381.329,
        "duration": 3.911
    },
    {
        "text": "to kind of.",
        "start": 3385.24,
        "duration": 1.0
    },
    {
        "text": "So we have time for some questions if there\nare, I think there people with microphones.",
        "start": 3386.24,
        "duration": 5.75
    },
    {
        "text": "My main concern is how we should educate the\ngeneration, like my son who is 12, which type",
        "start": 3391.99,
        "duration": 9.369
    },
    {
        "text": "of profession, how we should encourage that,\nknowing that it's going to be harder in the",
        "start": 3401.359,
        "duration": 6.821
    },
    {
        "text": "future?",
        "start": 3408.18,
        "duration": 1.0
    },
    {
        "text": "I've written a lot about this topic in education\nin this age, so I think, you know, as we've",
        "start": 3409.18,
        "duration": 7.22
    },
    {
        "text": "been talking about this whole debate between\nartificial general and narrow intelligence,",
        "start": 3416.4,
        "duration": 3.98
    },
    {
        "text": "the, this general as a model or something\nthat it really is not achieved yet and there's",
        "start": 3420.38,
        "duration": 6.28
    },
    {
        "text": "a lot of value in our being able to do multiple\nthings, right?",
        "start": 3426.66,
        "duration": 3.699
    },
    {
        "text": "So not just focusing on one single thing,\nbut really the value of a classical liberal",
        "start": 3430.359,
        "duration": 5.66
    },
    {
        "text": "art, liberal, a liberal arts education, right?",
        "start": 3436.019,
        "duration": 2.29
    },
    {
        "text": "So really sort of learning not only one thing\nbut, but many things will be valuable in the",
        "start": 3438.309,
        "duration": 5.54
    },
    {
        "text": "future.",
        "start": 3443.849,
        "duration": 1.0
    },
    {
        "text": "And then the other thing, as Matthew just\nmentioned, skills transfer.",
        "start": 3444.849,
        "duration": 2.51
    },
    {
        "text": "So, the, most valuable skillset that one can\nhave today is the ability to learn, learn",
        "start": 3447.359,
        "duration": 5.221
    },
    {
        "text": "new things because as the technology keeps\nchanging, you don't want to get stuck in a",
        "start": 3452.58,
        "duration": 4.039
    },
    {
        "text": "thing where you know, you kind of have this\none skill and if you can't perform that skill",
        "start": 3456.619,
        "duration": 3.49
    },
    {
        "text": "then you're out of a job.",
        "start": 3460.109,
        "duration": 1.021
    },
    {
        "text": "If you can go on a MOOC right, so a massive\nonline open course and learn a new skill when",
        "start": 3461.13,
        "duration": 4.909
    },
    {
        "text": "you're 25, when you're 30, when you're 35,\nthat's going to be, these are going to be",
        "start": 3466.039,
        "duration": 4.411
    },
    {
        "text": "the Darwinian fits for the new economy.",
        "start": 3470.45,
        "duration": 2.76
    },
    {
        "text": "And I don't know, there's no, the education\nsystem hasn't solved this at all.",
        "start": 3473.21,
        "duration": 4.53
    },
    {
        "text": "You know, there is, and I hope that the technologists\nwill be in dialogue with the education policymakers",
        "start": 3477.74,
        "duration": 3.91
    },
    {
        "text": "to make sure that both general education as\nwell as skills transfer will be will be focused",
        "start": 3481.65,
        "duration": 6.53
    },
    {
        "text": "on in the future.",
        "start": 3488.18,
        "duration": 1.0
    },
    {
        "text": "Another Question",
        "start": 3489.18,
        "duration": 1.0
    },
    {
        "text": "The thing that's really looming on the horizon\nthat I see as the self-driving car, I think",
        "start": 3490.18,
        "duration": 4.23
    },
    {
        "text": "there's a lot of money going there and they\nreally want to make it happen very quickly.",
        "start": 3494.41,
        "duration": 4.78
    },
    {
        "text": "One of the things I keep hearing is going\nto happen within five years.",
        "start": 3499.19,
        "duration": 3.21
    },
    {
        "text": "So, you know, obviously how does this, I feel\nlike it's going to be shoved down our throats",
        "start": 3502.4,
        "duration": 5.29
    },
    {
        "text": "rather than we're going to be allowed to arrive\nat some sort of organic a solution.",
        "start": 3507.69,
        "duration": 5.11
    },
    {
        "text": "So where do you guys see as, how is this going\nto be implemented?",
        "start": 3512.8,
        "duration": 5.069
    },
    {
        "text": "So maybe I can go.",
        "start": 3517.869,
        "duration": 1.321
    },
    {
        "text": "So one of the things that we haven't really\ntalked about is sort of how do we build ethics",
        "start": 3519.19,
        "duration": 3.53
    },
    {
        "text": "into AI and that's sort of a very prominent\nin the case of self-driving car.",
        "start": 3522.72,
        "duration": 4.549
    },
    {
        "text": "So as a philosopher we talk about the trolley\nproblems.",
        "start": 3527.269,
        "duration": 2.941
    },
    {
        "text": "So what happens when a trolley goes towards\nfive people, you know?",
        "start": 3530.21,
        "duration": 3.319
    },
    {
        "text": "Well now lets deal with the self-driving car.",
        "start": 3533.529,
        "duration": 1.981
    },
    {
        "text": "Imagine now the car's driving, it's an.",
        "start": 3535.51,
        "duration": 2.819
    },
    {
        "text": "It could kill five people.",
        "start": 3538.329,
        "duration": 1.601
    },
    {
        "text": "Oh, could kill you, right?",
        "start": 3539.93,
        "duration": 1.0
    },
    {
        "text": "You could sort of turn off to the side of\nthe world killing you, right?",
        "start": 3540.93,
        "duration": 3.7
    },
    {
        "text": "What should the car do and how should we,\nhow should the program or a program that into",
        "start": 3544.63,
        "duration": 4.44
    },
    {
        "text": "the car and which you buy a car that will\nkill you.",
        "start": 3549.07,
        "duration": 3.44
    },
    {
        "text": "Right?",
        "start": 3552.51,
        "duration": 1.0
    },
    {
        "text": "Even though maybe that's the right thing to\ndo.",
        "start": 3553.51,
        "duration": 2.27
    },
    {
        "text": "Right?",
        "start": 3555.78,
        "duration": 1.0
    },
    {
        "text": "And so, and who gets to decide that?",
        "start": 3556.78,
        "duration": 1.2
    },
    {
        "text": "So there's a sort of, there's a who's going\nto build in these sort of ethics into the",
        "start": 3557.98,
        "duration": 5.13
    },
    {
        "text": "AI.",
        "start": 3563.11,
        "duration": 1.0
    },
    {
        "text": "So that's sort of a huge area that hasn't\nreally been discussed well that people are",
        "start": 3564.11,
        "duration": 4.63
    },
    {
        "text": "starting to discuss now.",
        "start": 3568.74,
        "duration": 1.589
    },
    {
        "text": "My take on that has to do with sort of like\ndifferent geographical locations are a better",
        "start": 3570.329,
        "duration": 4.611
    },
    {
        "text": "fit for self-driving cars.",
        "start": 3574.94,
        "duration": 1.46
    },
    {
        "text": "So Singapore it would be great, right?",
        "start": 3576.4,
        "duration": 1.73
    },
    {
        "text": "So self-driving cars work the best.",
        "start": 3578.13,
        "duration": 1.38
    },
    {
        "text": "If it's, if we go from human to all cars,\nall self drivers, all human today also driving",
        "start": 3579.51,
        "duration": 5.14
    },
    {
        "text": "tomorrow because once you've got all the cars\nthat are talking to one another with their",
        "start": 3584.65,
        "duration": 3.1
    },
    {
        "text": "sensors, it becomes a very static system.",
        "start": 3587.75,
        "duration": 1.609
    },
    {
        "text": "It loses a lot of complexity.",
        "start": 3589.359,
        "duration": 1.93
    },
    {
        "text": "Bangalore is the worst place for self-driving\ncars because if you ever been to Bangalore,",
        "start": 3591.289,
        "duration": 3.901
    },
    {
        "text": "it's like people are honking and driving all\nover the place.",
        "start": 3595.19,
        "duration": 2.37
    },
    {
        "text": "There's traffic lights, right?",
        "start": 3597.56,
        "duration": 1.0
    },
    {
        "text": "So it would be super hard.",
        "start": 3598.56,
        "duration": 1.12
    },
    {
        "text": "It goes back to the, as was saying with the\nquickness with which you have to make a decision",
        "start": 3599.68,
        "duration": 5.04
    },
    {
        "text": "in the level of chaos in your system.",
        "start": 3604.72,
        "duration": 2.639
    },
    {
        "text": "So I do think like, this is going to be the\ntechnology's there, you know, and it's going",
        "start": 3607.359,
        "duration": 5.811
    },
    {
        "text": "to be a policy decision where certain who\nknows in the States, it'll be Uber that starts",
        "start": 3613.17,
        "duration": 4.07
    },
    {
        "text": "because there is aggressive as they are and\nthey're just going to put the fleet out and",
        "start": 3617.24,
        "duration": 4.369
    },
    {
        "text": "god knows what will happen and you know, and\nthen they'll get sued and they'll pay it off.",
        "start": 3621.609,
        "duration": 3.611
    },
    {
        "text": "And the next thing you know, everybody will\nhave self-driving cars.",
        "start": 3625.22,
        "duration": 1.899
    },
    {
        "text": "Right?",
        "start": 3627.119,
        "duration": 1.0
    },
    {
        "text": "But um, you know, I think that it'll be a\ngeographically specific area, there'll be",
        "start": 3628.119,
        "duration": 3.551
    },
    {
        "text": "somewhere that's more of a Singaporean like\nstate that will probably be like at the early",
        "start": 3631.67,
        "duration": 3.689
    },
    {
        "text": "adopter, and then it'll gradually shift to,\nI can't imagine when it'll make it this place",
        "start": 3635.359,
        "duration": 5.081
    },
    {
        "text": "like India just because of the, but I think\nthe, so the, so the sort of that.",
        "start": 3640.44,
        "duration": 4.29
    },
    {
        "text": "But the interesting point is going to be this,\nthis middle threshold where, you know, you've",
        "start": 3644.73,
        "duration": 4.31
    },
    {
        "text": "got some human drivers and some self driving\ncars and you've got these, I can't remember",
        "start": 3649.04,
        "duration": 3.87
    },
    {
        "text": "what they call it, but it's sort of, there's\nlike four levels of self driving cars from,",
        "start": 3652.91,
        "duration": 3.76
    },
    {
        "text": "you know, cruise control to full automation\nand right now there's a lot of work on the",
        "start": 3656.67,
        "duration": 4.32
    },
    {
        "text": "like when does the human intervene, who's\nliable when the human intervenes and it goes",
        "start": 3660.99,
        "duration": 5.57
    },
    {
        "text": "into the ethics and IP, right?",
        "start": 3666.56,
        "duration": 1.279
    },
    {
        "text": "So it's like, is it the carmaker?",
        "start": 3667.839,
        "duration": 1.171
    },
    {
        "text": "How do we do we model this like a software\nliability problems.",
        "start": 3669.01,
        "duration": 3.109
    },
    {
        "text": "So I think right now the issue is really one\nof policy and ethics.",
        "start": 3672.119,
        "duration": 4.311
    },
    {
        "text": "But there was another point earlier on that\nis also relevant for self-driving cars.",
        "start": 3676.43,
        "duration": 2.98
    },
    {
        "text": "We hold computers often to higher standards\nand human behavior.",
        "start": 3679.41,
        "duration": 3.5
    },
    {
        "text": "And in the self driving car world, there's\nso many accidents per day that it's kind of",
        "start": 3682.91,
        "duration": 3.78
    },
    {
        "text": "a no brainer that we should go to the autonomous\nvehicle paradigm, even if there will be accidents,",
        "start": 3686.69,
        "duration": 5.3
    },
    {
        "text": "there will be fewer than there are with human\ndrivers.",
        "start": 3691.99,
        "duration": 2.96
    },
    {
        "text": "But it's so hard to get people to appreciate\nthat.",
        "start": 3694.95,
        "duration": 2.599
    },
    {
        "text": "Right?",
        "start": 3697.549,
        "duration": 1.0
    },
    {
        "text": "So for me, this is the sort of like the messy\ndebate in the, in the space right now.",
        "start": 3698.549,
        "duration": 4.671
    },
    {
        "text": "And it's not all math.",
        "start": 3703.22,
        "duration": 1.379
    },
    {
        "text": "Um, well, I think we're a little past time\nhere I want to thank the panelists and all",
        "start": 3704.599,
        "duration": 4.521
    },
    {
        "text": "of you for coming.",
        "start": 3709.12,
        "duration": 0.45
    }
]