[
    {
        "text": "more than a half a century before he",
        "start": 0.03,
        "duration": 4.44
    },
    {
        "text": "Steven Hawkings and Elon Musk felt",
        "start": 2.07,
        "duration": 4.14
    },
    {
        "text": "compelled to warn the world of",
        "start": 4.47,
        "duration": 4.23
    },
    {
        "text": "artificial intelligence back in 1942",
        "start": 6.21,
        "duration": 4.559
    },
    {
        "text": "before the term was even coined the",
        "start": 8.7,
        "duration": 4.29
    },
    {
        "text": "science fiction writer Isaac Asimov",
        "start": 10.769,
        "duration": 5.551
    },
    {
        "text": "wrote the Three Laws of Robotics a moral",
        "start": 12.99,
        "duration": 6.18
    },
    {
        "text": "code to keep our machines in check and",
        "start": 16.32,
        "duration": 6.209
    },
    {
        "text": "the Three Laws of Robotics are a robot",
        "start": 19.17,
        "duration": 6.39
    },
    {
        "text": "may not injure a human being or through",
        "start": 22.529,
        "duration": 5.58
    },
    {
        "text": "inaction allow a human being to come to",
        "start": 25.56,
        "duration": 6.27
    },
    {
        "text": "harm the second law a robot must obey",
        "start": 28.109,
        "duration": 6.36
    },
    {
        "text": "orders given by human beings except",
        "start": 31.83,
        "duration": 4.02
    },
    {
        "text": "where such orders would conflict with",
        "start": 34.469,
        "duration": 5.641
    },
    {
        "text": "the first law and the third a robot must",
        "start": 35.85,
        "duration": 6.75
    },
    {
        "text": "protect its own existence as long as",
        "start": 40.11,
        "duration": 4.17
    },
    {
        "text": "such protection does not conflict with",
        "start": 42.6,
        "duration": 5.31
    },
    {
        "text": "the first and the second law that sounds",
        "start": 44.28,
        "duration": 6.81
    },
    {
        "text": "logical do these three laws provide a",
        "start": 47.91,
        "duration": 5.7
    },
    {
        "text": "basis to work from to develop moral",
        "start": 51.09,
        "duration": 8.489
    },
    {
        "text": "robots Marcus what do you think there",
        "start": 53.61,
        "duration": 8.4
    },
    {
        "text": "are lots of plots that you know can turn",
        "start": 59.579,
        "duration": 4.291
    },
    {
        "text": "around having these kinds of laws but",
        "start": 62.01,
        "duration": 3.179
    },
    {
        "text": "the first problem if you've ever",
        "start": 63.87,
        "duration": 3.06
    },
    {
        "text": "programmed anything is a concept like",
        "start": 65.189,
        "duration": 4.051
    },
    {
        "text": "harm is really hard to program into a",
        "start": 66.93,
        "duration": 4.14
    },
    {
        "text": "machine so it's one thing to program in",
        "start": 69.24,
        "duration": 3.72
    },
    {
        "text": "geometry or compound interest or",
        "start": 71.07,
        "duration": 2.729
    },
    {
        "text": "something like that where we have",
        "start": 72.96,
        "duration": 2.699
    },
    {
        "text": "precise necessary and sufficient",
        "start": 73.799,
        "duration": 4.71
    },
    {
        "text": "conditions nobody has any idea how to in",
        "start": 75.659,
        "duration": 4.411
    },
    {
        "text": "a generalized way get a machine to",
        "start": 78.509,
        "duration": 3.301
    },
    {
        "text": "recognize something like harm or justice",
        "start": 80.07,
        "duration": 3.659
    },
    {
        "text": "so there's a very serious programming",
        "start": 81.81,
        "duration": 3.239
    },
    {
        "text": "problem and then there are a couple",
        "start": 83.729,
        "duration": 3.241
    },
    {
        "text": "other problems too one is that not",
        "start": 85.049,
        "duration": 3.78
    },
    {
        "text": "everybody would agree that the robot",
        "start": 86.97,
        "duration": 3.27
    },
    {
        "text": "should never allow a human to come to",
        "start": 88.829,
        "duration": 2.671
    },
    {
        "text": "harm and would it what if for example",
        "start": 90.24,
        "duration": 3.48
    },
    {
        "text": "we're talking about a terrorist or a",
        "start": 91.5,
        "duration": 3.72
    },
    {
        "text": "sniper or something like that I mean",
        "start": 93.72,
        "duration": 3.18
    },
    {
        "text": "some people not everybody but some",
        "start": 95.22,
        "duration": 3.41
    },
    {
        "text": "people might actually want to allow that",
        "start": 96.9,
        "duration": 4.5
    },
    {
        "text": "into what they would let robots do and",
        "start": 98.63,
        "duration": 4.51
    },
    {
        "text": "then the third issue if you really think",
        "start": 101.4,
        "duration": 4.289
    },
    {
        "text": "through the third one of those laws is",
        "start": 103.14,
        "duration": 4.14
    },
    {
        "text": "it sets up robots to be second-class",
        "start": 105.689,
        "duration": 3.661
    },
    {
        "text": "citizens and ultimately to be slaves and",
        "start": 107.28,
        "duration": 3.839
    },
    {
        "text": "right now that might seem okay because",
        "start": 109.35,
        "duration": 3.42
    },
    {
        "text": "robots don't seem very clever but as",
        "start": 111.119,
        "duration": 3.0
    },
    {
        "text": "they get smarter and smarter they might",
        "start": 112.77,
        "duration": 3.12
    },
    {
        "text": "resent that or it might not feel like",
        "start": 114.119,
        "duration": 3.36
    },
    {
        "text": "the appropriate thing to do I mean those",
        "start": 115.89,
        "duration": 3.869
    },
    {
        "text": "laws might not be fair to robots they",
        "start": 117.479,
        "duration": 3.96
    },
    {
        "text": "might not be fair to robots exactly what",
        "start": 119.759,
        "duration": 2.0
    },
    {
        "text": "I'm saying",
        "start": 121.439,
        "duration": 3.54
    },
    {
        "text": "but the problem is not just with the",
        "start": 121.759,
        "duration": 5.021
    },
    {
        "text": "machines but our ethical code itself",
        "start": 124.979,
        "duration": 4.111
    },
    {
        "text": "surely do we know what fair is if that",
        "start": 126.78,
        "duration": 3.75
    },
    {
        "text": "is if we agree we should be fair to",
        "start": 129.09,
        "duration": 2.21
    },
    {
        "text": "robots",
        "start": 130.53,
        "duration": 2.24
    },
    {
        "text": "that's part of the problem is we don't",
        "start": 131.3,
        "duration": 3.84
    },
    {
        "text": "know what code we should program in so",
        "start": 132.77,
        "duration": 4.47
    },
    {
        "text": "asthma's laws are a nice starting point",
        "start": 135.14,
        "duration": 4.56
    },
    {
        "text": "at least for for a novel but for example",
        "start": 137.24,
        "duration": 4.17
    },
    {
        "text": "imagine that we programmed in our laws",
        "start": 139.7,
        "duration": 3.87
    },
    {
        "text": "from the 17th century than we would have",
        "start": 141.41,
        "duration": 3.99
    },
    {
        "text": "thought slavery was okay so we maybe",
        "start": 143.57,
        "duration": 3.78
    },
    {
        "text": "don't want to program in the fixed laws",
        "start": 145.4,
        "duration": 3.78
    },
    {
        "text": "that we have right now to shackle the",
        "start": 147.35,
        "duration": 3.66
    },
    {
        "text": "robots forever we don't know burn them",
        "start": 149.18,
        "duration": 3.87
    },
    {
        "text": "into the ROM chips of the robots but we",
        "start": 151.01,
        "duration": 4.74
    },
    {
        "text": "also don't know how we want the morals",
        "start": 153.05,
        "duration": 5.19
    },
    {
        "text": "to grow over time and so it's a very",
        "start": 155.75,
        "duration": 5.33
    },
    {
        "text": "complicated issue",
        "start": 158.24,
        "duration": 2.84
    }
]