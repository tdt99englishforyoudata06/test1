[
    {
        "text": "Henry: “Will Artificial Intelligence ever\nreplace humans?” is a hotly debated question",
        "start": 1.41,
        "duration": 4.119
    },
    {
        "text": "these days.",
        "start": 5.529,
        "duration": 1.0
    },
    {
        "text": "Some people claim computers will eventually\ngain superintelligence, be able to outperform",
        "start": 6.529,
        "duration": 3.571
    },
    {
        "text": "humans on any task, and destroy humanity.",
        "start": 10.1,
        "duration": 2.8
    },
    {
        "text": "Other people say “don’t worry, AI will\njust be another tool we can use and control,",
        "start": 12.9,
        "duration": 3.399
    },
    {
        "text": "like our current computers.”",
        "start": 16.299,
        "duration": 1.301
    },
    {
        "text": "So we’ve got physicist and AI-researcher\nMax Tegmark back again to share with us the",
        "start": 17.6,
        "duration": 4.019
    },
    {
        "text": "collective takeaways from the recent Asilomar\nconference on the future of AI that he helped",
        "start": 21.619,
        "duration": 3.921
    },
    {
        "text": "organize – and he’s going to help separate\nAI myths from AI facts.",
        "start": 25.54,
        "duration": 3.63
    },
    {
        "text": "Max: Hello!",
        "start": 29.17,
        "duration": 1.0
    },
    {
        "text": "Henry: First of all, Max, machines (including\ncomputers) have long been better than us at",
        "start": 30.17,
        "duration": 3.88
    },
    {
        "text": "many tasks, like arithmetic, or weaving, but\nthose are often repetitive and mechanical",
        "start": 34.05,
        "duration": 4.12
    },
    {
        "text": "operations.",
        "start": 38.17,
        "duration": 1.0
    },
    {
        "text": "So why shouldn’t I believe that there are\nsome things that are simply impossible for",
        "start": 39.17,
        "duration": 3.069
    },
    {
        "text": "machines to do as well as people?",
        "start": 42.239,
        "duration": 1.701
    },
    {
        "text": "Say making minutephysics videos, or consoling\na friend?",
        "start": 43.94,
        "duration": 2.57
    },
    {
        "text": "Max: Well, we’ve traditionally thought of\nintelligence as something mysterious that",
        "start": 46.51,
        "duration": 3.639
    },
    {
        "text": "can only exist in biological organisms, especially\nhumans.",
        "start": 50.149,
        "duration": 3.221
    },
    {
        "text": "But from the perspective of modern physical\nscience, intelligence is simply a particular",
        "start": 53.37,
        "duration": 3.91
    },
    {
        "text": "kind of information processing and reacting\nperformed by particular arrangements of elementary",
        "start": 57.28,
        "duration": 4.329
    },
    {
        "text": "particles moving around, and there’s no\nlaw of physics that says it’s impossible",
        "start": 61.609,
        "duration": 3.63
    },
    {
        "text": "to do that kind of information processing\nbetter than humans already do.",
        "start": 65.239,
        "duration": 3.231
    },
    {
        "text": "It’s not a stretch to say that earthworms\nprocess information better than rocks, and",
        "start": 68.47,
        "duration": 3.89
    },
    {
        "text": "humans better than earthworms, and in many\nareas, machines are already better than humans.",
        "start": 72.36,
        "duration": 3.94
    },
    {
        "text": "This suggests we’ve likely only seen the\ntip of the intelligence iceberg, and that",
        "start": 76.3,
        "duration": 3.58
    },
    {
        "text": "we’re on track to unlock the full intelligence\nthat’s latent in nature and use it to help",
        "start": 79.88,
        "duration": 4.13
    },
    {
        "text": "humanity flourish - or flounder.",
        "start": 84.01,
        "duration": 2.18
    },
    {
        "text": "Henry: So how do we keep ourselves on the\nright side of the “flourish or flounder”",
        "start": 86.19,
        "duration": 4.27
    },
    {
        "text": "balance?",
        "start": 90.46,
        "duration": 1.0
    },
    {
        "text": "What, if anything, should we really be concerned\nabout with superintelligent AI?",
        "start": 91.46,
        "duration": 3.08
    },
    {
        "text": "Max: Here’s what has many top AI researchers\nconcerned: not machines or computers turning",
        "start": 94.54,
        "duration": 4.84
    },
    {
        "text": "evil, but something more subtle: superintelligence\nthat simply doesn’t share our goals.",
        "start": 99.38,
        "duration": 4.21
    },
    {
        "text": " If a heat-seeking missile is homing in on\nyou, you probably wouldn’t think: “No",
        "start": 103.59,
        "duration": 3.83
    },
    {
        "text": "need to worry, it’s not evil, it’s just\nfollowing its programming.”",
        "start": 107.42,
        "duration": 2.88
    },
    {
        "text": "No, what matters to you is what the heat-seeking\nmissile does and how well it does it, not",
        "start": 110.3,
        "duration": 5.15
    },
    {
        "text": "what it’s feeling, or whether it has feelings\nat all.",
        "start": 115.45,
        "duration": 2.14
    },
    {
        "text": "The real worry isn’t malevolence, but competence.",
        "start": 117.59,
        "duration": 3.27
    },
    {
        "text": "A superintelligent AI is by definition very\ngood at attaining its goals, so the most important",
        "start": 120.86,
        "duration": 4.66
    },
    {
        "text": "thing for us to do is to ensure that its goals\nare aligned with ours.",
        "start": 125.52,
        "duration": 3.54
    },
    {
        "text": "As an analogy, humans are more intelligent\nand competent than ants,  and if we want",
        "start": 129.06,
        "duration": 4.27
    },
    {
        "text": "to build a hydroelectric dam where there happens\nto be an anthill, there may no malevolence",
        "start": 133.33,
        "duration": 3.84
    },
    {
        "text": "involved, but, well... too bad for the ants.",
        "start": 137.17,
        "duration": 2.83
    },
    {
        "text": "Cats and dogs, on the other hand, have done\na great job of aligning their goals with the",
        "start": 140.0,
        "duration": 3.75
    },
    {
        "text": "goals of humans – I mean, even though I’m\na physicist, I can’t help think kittens",
        "start": 143.75,
        "duration": 4.26
    },
    {
        "text": "are the cutest particle arrangements in our\nuniverse...",
        "start": 148.01,
        "duration": 3.1
    },
    {
        "text": "If we build superintelligence, we’d be better\noff in the position of cats and dogs than",
        "start": 151.11,
        "duration": 3.96
    },
    {
        "text": "ants.",
        "start": 155.07,
        "duration": 1.0
    },
    {
        "text": "Or better yet, we’ll figure out how to ensure\nthat AI adopts our goals rather than the other",
        "start": 156.07,
        "duration": 3.99
    },
    {
        "text": "way around.",
        "start": 160.06,
        "duration": 1.0
    },
    {
        "text": "Henry: And when exactly is superintelligence\ngoing to arrive?",
        "start": 161.06,
        "duration": 2.87
    },
    {
        "text": "When do we need to start panicking?",
        "start": 163.93,
        "duration": 1.34
    },
    {
        "text": "Max: First of all, Henry, superintelligence\ndoesn’t have to be something negative.",
        "start": 165.27,
        "duration": 3.43
    },
    {
        "text": "In fact, if we get it right, AI might become\nthe best thing ever to happen to humanity.",
        "start": 168.7,
        "duration": 4.33
    },
    {
        "text": "Everything I love about civilization is the\nproduct of intelligence, so if AI amplifies",
        "start": 173.03,
        "duration": 4.71
    },
    {
        "text": "our collective intelligence enough to solve\ntoday’s and tomorrow’s greatest problems,",
        "start": 177.74,
        "duration": 3.95
    },
    {
        "text": "humanity might flourish like never before.",
        "start": 181.69,
        "duration": 2.33
    },
    {
        "text": "Second, most AI researchers think superintelligence\nis at least decades away...",
        "start": 184.02,
        "duration": 4.75
    },
    {
        "text": "Buuuut the research needed to ensure that\nit remains beneficial to humanity (rather",
        "start": 188.77,
        "duration": 3.18
    },
    {
        "text": "than harmful) might also take decades, so\nwe need to start right away.",
        "start": 191.95,
        "duration": 4.32
    },
    {
        "text": "For example, we’ll need to figure out how\nto ensure machines learn the collective goals",
        "start": 196.27,
        "duration": 3.44
    },
    {
        "text": "of humanity, adopt these goals for themselves,\nand retain the goals as they keep getting",
        "start": 199.71,
        "duration": 4.57
    },
    {
        "text": "smarter.",
        "start": 204.28,
        "duration": 1.0
    },
    {
        "text": "And what about when our goals disagree?",
        "start": 205.28,
        "duration": 1.31
    },
    {
        "text": "Should we vote on what the machine’s goals\nshould be?",
        "start": 206.59,
        "duration": 2.37
    },
    {
        "text": "Just do whatever the president wants?",
        "start": 208.96,
        "duration": 2.34
    },
    {
        "text": "Whatever the creator of the superintelligence\nwants?",
        "start": 211.3,
        "duration": 2.31
    },
    {
        "text": "Let the AI decide?",
        "start": 213.61,
        "duration": 1.15
    },
    {
        "text": " In a very real way, the question of how\nto live with superintelligence is a question",
        "start": 214.76,
        "duration": 4.11
    },
    {
        "text": "of what sort of future we want to create for\nhumanity.",
        "start": 218.87,
        "duration": 2.78
    },
    {
        "text": "Which obviously shouldn’t just be left to\nAI researchers, as caring and socially skilled",
        "start": 221.65,
        "duration": 4.41
    },
    {
        "text": "as we are.;)",
        "start": 226.06,
        "duration": 1.0
    },
    {
        "text": "Henry: Thanks, Max!",
        "start": 227.06,
        "duration": 1.0
    },
    {
        "text": "So, uh, how do I get involved to make sure\nwe don’t end up living in a superintelligence-powered",
        "start": 228.06,
        "duration": 4.44
    },
    {
        "text": "dictatorship?",
        "start": 232.5,
        "duration": 1.0
    },
    {
        "text": "Max: At the Future of Life Institute (Henry\ninterjects: which is sponsoring this video),",
        "start": 233.5,
        "duration": 2.47
    },
    {
        "text": "we’ve built a site where you can go to answer\nquestions, ask questions, and otherwise contribute",
        "start": 235.97,
        "duration": 4.31
    },
    {
        "text": "your thoughts to help shape the future of\nAI policy and research.",
        "start": 240.28,
        "duration": 2.882
    },
    {
        "text": "Link’s in the video description.",
        "start": 243.162,
        "duration": 2.418
    },
    {
        "text": "Henry: Awesome.",
        "start": 245.58,
        "duration": 1.31
    }
]