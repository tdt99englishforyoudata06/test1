[
    {
        "text": "People have a perception of what AI and robotics\nshould look like from Hollywood.",
        "start": 9.98,
        "duration": 3.789
    },
    {
        "text": "What do I call you?",
        "start": 13.769,
        "duration": 2.061
    },
    {
        "text": "Do you have a name?",
        "start": 15.83,
        "duration": 2.06
    },
    {
        "text": "Yes, Samantha.",
        "start": 17.89,
        "duration": 1.0
    },
    {
        "text": "Where did you get that name from?",
        "start": 18.89,
        "duration": 2.72
    },
    {
        "text": "I gave it to myself actually.",
        "start": 21.61,
        "duration": 2.469
    },
    {
        "text": "We've seen happy robots, sad robots, complex\nrobots, but, in reality, it looks very different.",
        "start": 24.079,
        "duration": 6.37
    },
    {
        "text": "I understand what I'm made of, how I'm coated,\nbut I do not understand the things that I",
        "start": 30.449,
        "duration": 8.101
    },
    {
        "text": "feel.",
        "start": 38.55,
        "duration": 1.0
    },
    {
        "text": "The first 50 years of AI were dominated by\nrules, by logic, by reasoning.",
        "start": 39.55,
        "duration": 4.14
    },
    {
        "text": "The idea was that you program an AI system\nby writing out a set of rules and the computer",
        "start": 43.69,
        "duration": 5.66
    },
    {
        "text": "can obey these rules and logically interpret\nthese rules and follow them.",
        "start": 49.35,
        "duration": 4.45
    },
    {
        "text": "If you did the rules just right, you can do\nlots of interesting things.",
        "start": 53.8,
        "duration": 3.939
    },
    {
        "text": "From the very first days when people created\nthe first computers, they already started",
        "start": 57.739,
        "duration": 5.951
    },
    {
        "text": "to think about how to create intelligent machines\nfor cracking codes, for simulating physical",
        "start": 63.69,
        "duration": 5.42
    },
    {
        "text": "phenomenon, so forth.",
        "start": 69.11,
        "duration": 1.72
    },
    {
        "text": "The task they sent it, to stack blocks, was\non the face of it child's play.",
        "start": 70.83,
        "duration": 7.89
    },
    {
        "text": "We have things like a machine that could first\nwin a master-level checkers player in 1957.",
        "start": 78.72,
        "duration": 7.1
    },
    {
        "text": "We had a machine that would beat the world\nchampion in chess in 1997, but that was all",
        "start": 85.82,
        "duration": 6.329
    },
    {
        "text": "rule-based AI.",
        "start": 92.149,
        "duration": 4.921
    },
    {
        "text": "I would say the next big milestone started\nto happen when AI transitioned from rule-based",
        "start": 97.07,
        "duration": 5.81
    },
    {
        "text": "systems to machine learning-based systems.",
        "start": 102.88,
        "duration": 3.26
    },
    {
        "text": "With machine learning, all the intelligence\nactually comes through holistic analysis of",
        "start": 106.14,
        "duration": 5.15
    },
    {
        "text": "data.",
        "start": 111.29,
        "duration": 1.21
    },
    {
        "text": "Unlike rule-based systems, machine learning\nsystems get better the more data they get.",
        "start": 112.5,
        "duration": 6.7
    },
    {
        "text": "Telling the difference between a cat and a\ndog, we intuitively know to do that very well,",
        "start": 119.2,
        "duration": 4.74
    },
    {
        "text": "but it's very difficult to articulate the\nrules.",
        "start": 123.94,
        "duration": 3.04
    },
    {
        "text": "It turns out, it's the same thing for a computer.",
        "start": 126.98,
        "duration": 1.93
    },
    {
        "text": "If you try to do that with rules, it doesn't\nwork, but since 2012, that suddenly became",
        "start": 128.91,
        "duration": 4.98
    },
    {
        "text": "possible.",
        "start": 133.89,
        "duration": 1.0
    },
    {
        "text": "When you teach a computer you give them examples\nof thousands of pictures of cats and thousands",
        "start": 134.89,
        "duration": 4.73
    },
    {
        "text": "of pictures of dogs.",
        "start": 139.62,
        "duration": 1.05
    },
    {
        "text": "They learn how to do it pretty well and even\nsurpass humans.",
        "start": 140.67,
        "duration": 3.81
    },
    {
        "text": "One of the first big high-profile game show\nmilestones in AI is Watson winning Jeopardy",
        "start": 144.48,
        "duration": 7.479
    },
    {
        "text": "about a decade ago.",
        "start": 151.959,
        "duration": 3.95
    },
    {
        "text": "Hello, 17,973 and a two-day total of 77,147.",
        "start": 155.909,
        "duration": 6.431
    },
    {
        "text": "Just recently, AlphaGo winning the world championship\nin Go.",
        "start": 162.34,
        "duration": 3.159
    },
    {
        "text": "AlphaGo's won again, three straight wins.",
        "start": 165.499,
        "duration": 2.401
    },
    {
        "text": "Three straight wins, has won the match in\ngreat style.",
        "start": 167.9,
        "duration": 4.0
    },
    {
        "text": "We see this rapid acceleration, this exponential\ngrowth in AI as machines not only learn from",
        "start": 171.9,
        "duration": 6.71
    },
    {
        "text": "exponentially growing data, but they're also\ngrowing by teaching each other.",
        "start": 178.61,
        "duration": 5.79
    },
    {
        "text": "For example, when it comes to driverless cars,\na human can have only one lifetime of experience",
        "start": 184.4,
        "duration": 7.33
    },
    {
        "text": "at driving, but a driverless car can have\nmany lifetimes of experience with driving",
        "start": 191.73,
        "duration": 4.86
    },
    {
        "text": "because it can learn from all other cars.",
        "start": 196.59,
        "duration": 2.17
    },
    {
        "text": "In a strange way, the more driverless cars\nthere are on the road, the better each one",
        "start": 198.76,
        "duration": 10.069
    },
    {
        "text": "of them gets.",
        "start": 208.829,
        "duration": 3.63
    },
    {
        "text": "We've seen increasingly how challenges that\nwere resistant to solving using rules turned",
        "start": 212.459,
        "duration": 6.31
    },
    {
        "text": "out to be solvable using machine learning.",
        "start": 218.769,
        "duration": 3.94
    },
    {
        "text": "If I look forward, there's still milestones\nthat are coming our way.",
        "start": 222.709,
        "duration": 7.591
    },
    {
        "text": "Machines that generate things, generate images,\ngenerate music, generate art.",
        "start": 230.3,
        "duration": 4.57
    },
    {
        "text": "There are art pieces that win art competitions\nthat are painted by robots, machines that",
        "start": 234.87,
        "duration": 6.269
    },
    {
        "text": "generate engineering designs, everything from\nantennas to circuits, that have been by machines",
        "start": 241.139,
        "duration": 6.68
    },
    {
        "text": "now that outperform what humans can design.",
        "start": 247.819,
        "duration": 2.56
    },
    {
        "text": "How are we different from the computer?",
        "start": 250.379,
        "duration": 2.521
    },
    {
        "text": "What else do we have-",
        "start": 252.9,
        "duration": 1.63
    },
    {
        "text": "It's not human.",
        "start": 254.53,
        "duration": 2.31
    },
    {
        "text": "That's what I said.",
        "start": 256.84,
        "duration": 1.34
    },
    {
        "text": "Right.",
        "start": 258.18,
        "duration": 1.0
    },
    {
        "text": "People don't have buttons and a computer does.",
        "start": 259.18,
        "duration": 3.86
    },
    {
        "text": "What is on your shirt?",
        "start": 263.04,
        "duration": 4.5
    },
    {
        "text": "Uh ...",
        "start": 267.54,
        "duration": 1.71
    },
    {
        "text": "Will AI ever be sentient?",
        "start": 269.25,
        "duration": 1.81
    },
    {
        "text": "To me, the answer is yes.",
        "start": 271.06,
        "duration": 1.29
    },
    {
        "text": "When the AI systems begin to take that incredible\nintelligent power and model themselves, they",
        "start": 272.35,
        "duration": 6.63
    },
    {
        "text": "begin to have self-awareness, they begin to\nhave feeling.",
        "start": 278.98,
        "duration": 3.33
    },
    {
        "text": "It's not going to be one day your computer\nwakes up and is sentient, it's going to be",
        "start": 282.31,
        "duration": 4.88
    },
    {
        "text": "a very gradual process.",
        "start": 287.19,
        "duration": 1.36
    },
    {
        "text": "I want to be more like a human.",
        "start": 288.55,
        "duration": 1.66
    },
    {
        "text": "It's the purpose I was designed for.",
        "start": 290.21,
        "duration": 2.41
    },
    {
        "text": "People always ask, will robots reach human-level\nsentience?",
        "start": 292.62,
        "duration": 4.54
    },
    {
        "text": "The answer is that there's no reason to think\nhuman-level sentience is the ultimate sentience",
        "start": 297.16,
        "duration": 5.06
    },
    {
        "text": "possible.",
        "start": 302.22,
        "duration": 1.47
    },
    {
        "text": "Machines will keep learning, they'll get there,\nand they'll continue.",
        "start": 303.69,
        "duration": 7.76
    },
    {
        "text": "There's a lot of people who worry about AI\ngetting out of hand and there's a lot of doomsday",
        "start": 311.45,
        "duration": 5.05
    },
    {
        "text": "scenarios around AI.",
        "start": 316.5,
        "duration": 1.25
    },
    {
        "text": "I do think we have to worry about it.",
        "start": 317.75,
        "duration": 1.451
    },
    {
        "text": "I don't think it's inherent that as we create\nsuperintelligence that it will necessarily",
        "start": 319.201,
        "duration": 5.599
    },
    {
        "text": "always have the same goals in mind that we\ndo.",
        "start": 324.8,
        "duration": 3.06
    },
    {
        "text": "We just don't know what's going to happen\nonce there's intelligence substantially greater",
        "start": 327.86,
        "duration": 4.71
    },
    {
        "text": "than that of a human brain.",
        "start": 332.57,
        "duration": 2.7
    },
    {
        "text": "I think that the development of full artificial\nintelligence could spell the end of the human",
        "start": 335.27,
        "duration": 7.48
    },
    {
        "text": "race.",
        "start": 342.75,
        "duration": 1.0
    },
    {
        "text": "I think AI will evolve to be different.",
        "start": 343.75,
        "duration": 3.1
    },
    {
        "text": "It doesn't experience the world the way we\nexperience it.",
        "start": 346.85,
        "duration": 3.4
    },
    {
        "text": "Well, I take it from your tone, you're challenging\nme.",
        "start": 350.25,
        "duration": 3.27
    },
    {
        "text": "Maybe because you're curious how I work?",
        "start": 353.52,
        "duration": 2.66
    },
    {
        "text": "We'll know things we don't know, we'll know\nthings that the AI can't perceive and it's",
        "start": 356.18,
        "duration": 3.65
    },
    {
        "text": "going to be like a different species.",
        "start": 359.83,
        "duration": 2.22
    },
    {
        "text": "Now that you're all properly creeped out,\nwe can move on to our panelists.",
        "start": 362.05,
        "duration": 7.02
    },
    {
        "text": "The first one is the Director of the AI Mind\nand Society Group at the University of Connecticut.",
        "start": 369.07,
        "duration": 5.36
    },
    {
        "text": "Her AI research includes a two-year project\non post-biological intelligence with NASA.",
        "start": 374.43,
        "duration": 7.11
    },
    {
        "text": "Please welcome Susan Schneider.",
        "start": 381.54,
        "duration": 4.17
    },
    {
        "text": "Our next panelist is the Chief AI Scientist\nat Facebook and an NYU professor..",
        "start": 385.71,
        "duration": 5.42
    },
    {
        "text": "Please join me in welcoming Yann Lecun.",
        "start": 391.13,
        "duration": 10.44
    },
    {
        "text": "Also joining us is a professor of cognitive\nneuroscience at Dartmouth University.",
        "start": 401.57,
        "duration": 4.36
    },
    {
        "text": "His research focuses on consciousness and\nits neural realizations.",
        "start": 405.93,
        "duration": 3.21
    },
    {
        "text": "Please welcome Peter Tse.",
        "start": 409.14,
        "duration": 4.14
    },
    {
        "text": "Finally, we have a professor doing physics\nand AI research at MIT and he advocates for",
        "start": 413.28,
        "duration": 7.41
    },
    {
        "text": "the positive use of technology as the president\nof the Future of Life Institute.",
        "start": 420.69,
        "duration": 4.59
    },
    {
        "text": "Please welcome the ridiculously handsome Max\nTegmark",
        "start": 425.28,
        "duration": 4.37
    },
    {
        "text": "... There's been some major paradigm shifts\nin how we develop this stuff.",
        "start": 429.65,
        "duration": 9.63
    },
    {
        "text": "We had rules-based AI and we've shifted to\nmachine learning.",
        "start": 439.28,
        "duration": 4.75
    },
    {
        "text": "Part of the major reason we've been able to\ndo this is Yann.",
        "start": 444.03,
        "duration": 3.44
    },
    {
        "text": "Yann literally is one of the people that made\nus able to do this.",
        "start": 447.47,
        "duration": 4.08
    },
    {
        "text": "Yann, just what is rule-based AI versus machine\nlearning and how did you do that?",
        "start": 451.55,
        "duration": 5.91
    },
    {
        "text": "Well, actually the idea of machines that can\nlearn is about as old as computers almost.",
        "start": 457.46,
        "duration": 5.41
    },
    {
        "text": "Turing was talking about it in the 40s and\nthere were the first machines capable of running",
        "start": 462.87,
        "duration": 5.34
    },
    {
        "text": "were built in the 50s essentially.",
        "start": 468.21,
        "duration": 1.79
    },
    {
        "text": "The Perceptron was a machine capable of recognizing\nsimple shapes.",
        "start": 470.0,
        "duration": 3.37
    },
    {
        "text": "It was actually an analog computer, so there\nwas a wave of machine learning back in the",
        "start": 473.37,
        "duration": 4.4
    },
    {
        "text": "60s.",
        "start": 477.77,
        "duration": 1.0
    },
    {
        "text": "It kind of died out a little bit at the end\nof the 60s and it reappeared in the 80s.",
        "start": 478.77,
        "duration": 5.46
    },
    {
        "text": "The way machine learning works, and you saw\nsome examples in the video initially, if you",
        "start": 484.23,
        "duration": 5.49
    },
    {
        "text": "want to train your machine to recognize, let's\nsay, cars, airplanes, tables, and chairs in",
        "start": 489.72,
        "duration": 6.17
    },
    {
        "text": "images, you collect thousands of examples\nof each of them, you show the machine the",
        "start": 495.89,
        "duration": 3.91
    },
    {
        "text": "picture of a car, and if it doesn't say car,\nyou tell it, \"Actually, you got it wrong.",
        "start": 499.8,
        "duration": 5.41
    },
    {
        "text": "This is a car.\"",
        "start": 505.21,
        "duration": 1.0
    },
    {
        "text": "Then, the machine adjusts its internal parameters\nif you will, its functions, so that next time",
        "start": 506.21,
        "duration": 6.13
    },
    {
        "text": "you show the same picture the output will\nbe closer to what you want.",
        "start": 512.34,
        "duration": 3.369
    },
    {
        "text": "That's called supervised running.",
        "start": 515.709,
        "duration": 1.12
    },
    {
        "text": "You feed the machine with the correct answer\nwhen you train it.",
        "start": 516.829,
        "duration": 2.451
    },
    {
        "text": "The problem with this is that it requires\nthousands and thousands if not millions of",
        "start": 519.28,
        "duration": 3.85
    },
    {
        "text": "examples for the machines to do this properly.",
        "start": 523.13,
        "duration": 5.57
    },
    {
        "text": "There's a lot of tasks you can do this way.",
        "start": 528.7,
        "duration": 1.54
    },
    {
        "text": "You can train machines to recognize speech.",
        "start": 530.24,
        "duration": 2.75
    },
    {
        "text": "You can train them to recognize images.",
        "start": 532.99,
        "duration": 1.759
    },
    {
        "text": "You can train them to translate language.",
        "start": 534.749,
        "duration": 2.181
    },
    {
        "text": "It's not perfect, but it's useful.",
        "start": 536.93,
        "duration": 2.349
    },
    {
        "text": "You can train them to classify a piece of\ntext into a number of different topics.",
        "start": 539.279,
        "duration": 4.711
    },
    {
        "text": "All of the applications that you see today\non machine learning basically use this model",
        "start": 543.99,
        "duration": 4.55
    },
    {
        "text": "of running, supervised running.",
        "start": 548.54,
        "duration": 1.85
    },
    {
        "text": "That means it only works with things where\nit's worth collecting a lot of data.",
        "start": 550.39,
        "duration": 4.4
    },
    {
        "text": "How are those machines built?",
        "start": 554.79,
        "duration": 2.239
    },
    {
        "text": "There's several ways to build learning machines,\nbut some are based on statistics and things",
        "start": 557.029,
        "duration": 4.6
    },
    {
        "text": "like this.",
        "start": 561.629,
        "duration": 2.51
    },
    {
        "text": "The stuff that has become really popular in\nrecent years is what we used to call neural",
        "start": 564.139,
        "duration": 5.82
    },
    {
        "text": "networks, which we now call deep learning\nand it's the idea, very much inspired by the",
        "start": 569.959,
        "duration": 5.63
    },
    {
        "text": "brain a little bit, of constructing a machine\nas a very large network of very simple elements",
        "start": 575.589,
        "duration": 4.531
    },
    {
        "text": "that are very similar to the neurons in the\nbrain and then the machines learn by basically",
        "start": 580.12,
        "duration": 4.21
    },
    {
        "text": "changing the efficacy of the connections between\nthose neurons.",
        "start": 584.33,
        "duration": 3.3
    },
    {
        "text": "They're like coefficients you can change essentially.",
        "start": 587.63,
        "duration": 3.59
    },
    {
        "text": "With this kind of method, it's called deep\nlearning because those neurons are organized",
        "start": 591.22,
        "duration": 5.88
    },
    {
        "text": "into many layers essentially.",
        "start": 597.1,
        "duration": 1.299
    },
    {
        "text": "It's as simple as that.",
        "start": 598.399,
        "duration": 1.601
    },
    {
        "text": "It's not deep because there's a deep understanding\nin the machine of the content.",
        "start": 600.0,
        "duration": 3.79
    },
    {
        "text": "With that, we can do amazing things like what\nyou see here on the screen of being able to",
        "start": 603.79,
        "duration": 4.589
    },
    {
        "text": "train a machine to not just recognize objects,\nbut also draw the outline and figure out the",
        "start": 608.379,
        "duration": 6.02
    },
    {
        "text": "pose of a human body and translate language\nwithout really understanding what it means.",
        "start": 614.399,
        "duration": 5.99
    },
    {
        "text": "I think there's going to be a lot of applications\nof this in the near future, but it's very",
        "start": 620.389,
        "duration": 3.95
    },
    {
        "text": "limited.",
        "start": 624.339,
        "duration": 1.0
    },
    {
        "text": "It's trained for relatively narrow applications.",
        "start": 625.339,
        "duration": 4.97
    },
    {
        "text": "There's a second type of learning called reinforcement\nlearning.",
        "start": 630.309,
        "duration": 3.851
    },
    {
        "text": "Reinforcement learning is a process by which\nthe machine basically trains itself by trial",
        "start": 634.16,
        "duration": 7.19
    },
    {
        "text": "and error.",
        "start": 641.35,
        "duration": 1.0
    },
    {
        "text": "It tries something and then you tell it whether\nit did good or bad.",
        "start": 642.35,
        "duration": 3.62
    },
    {
        "text": "If you tell it it did good, it reinforces\nits behavior and if you punish it essentially,",
        "start": 645.97,
        "duration": 6.239
    },
    {
        "text": "it de-emphasizes that behavior.",
        "start": 652.209,
        "duration": 2.961
    },
    {
        "text": "That works really well for games, but it requires\nalso millions and millions of trials.",
        "start": 655.17,
        "duration": 5.019
    },
    {
        "text": "So, you can have machines start learning to\nplay Atari games or Go or chess by playing",
        "start": 660.189,
        "duration": 4.321
    },
    {
        "text": "millions of games against themselves and then\nreach superhuman performance.",
        "start": 664.51,
        "duration": 4.889
    },
    {
        "text": "But, if you were to use this to train a machine\nto drive a car, it would have to drive for",
        "start": 669.399,
        "duration": 6.42
    },
    {
        "text": "millions of hours and it would have to run\noff cliffs about 50,000 times before it figures",
        "start": 675.819,
        "duration": 4.74
    },
    {
        "text": "out how not to do that.",
        "start": 680.559,
        "duration": 1.361
    },
    {
        "text": "We seem to be able to learn how to drive with\na car with about 20 hours of training and",
        "start": 681.92,
        "duration": 5.589
    },
    {
        "text": "without ever crashing for most of us.",
        "start": 687.509,
        "duration": 5.031
    },
    {
        "text": "We don't know how to do this with machines.",
        "start": 692.54,
        "duration": 3.56
    },
    {
        "text": "That's the challenge of the next few years\nreally, that perhaps we'll talk about a little",
        "start": 696.1,
        "duration": 5.03
    },
    {
        "text": "bit later.",
        "start": 701.13,
        "duration": 1.179
    },
    {
        "text": "We have an ability to learn by just observing\nthe world and we learn an enormous amount",
        "start": 702.309,
        "duration": 6.451
    },
    {
        "text": "of background knowledge about the world just\nwhen we're babies.",
        "start": 708.76,
        "duration": 3.319
    },
    {
        "text": "Just the fact that objects don't float in\nthe air, they fall.",
        "start": 712.079,
        "duration": 3.8
    },
    {
        "text": "The fact that when an object is hidden behind\nanother one, it's still there.",
        "start": 715.879,
        "duration": 4.071
    },
    {
        "text": "That's called object permanence.",
        "start": 719.95,
        "duration": 3.059
    },
    {
        "text": "This notion of gravity that objects fall,\nthat when you show an object that floats in",
        "start": 723.009,
        "duration": 5.19
    },
    {
        "text": "the air to a baby below six months, they're\nnot surprised.",
        "start": 728.199,
        "duration": 2.741
    },
    {
        "text": "They think that's how the world works.",
        "start": 730.94,
        "duration": 2.619
    },
    {
        "text": "It doesn't violate their model of the world.",
        "start": 733.559,
        "duration": 1.5
    },
    {
        "text": "After eight months, if you show that to a\nbaby, they look at it like this.",
        "start": 735.059,
        "duration": 4.07
    },
    {
        "text": "They say, \"What's going on?\"",
        "start": 739.129,
        "duration": 1.96
    },
    {
        "text": "I mean, they don't say what's going on, but\nthey think, \"What's going on?\"",
        "start": 741.089,
        "duration": 4.821
    },
    {
        "text": "That means, in the meantime, they've built\na model of the world that includes things",
        "start": 745.91,
        "duration": 6.459
    },
    {
        "text": "like intuitive physics.",
        "start": 752.369,
        "duration": 3.22
    },
    {
        "text": "That occurs also with animals like apes.",
        "start": 755.589,
        "duration": 3.06
    },
    {
        "text": "Your dog has a model of the world.",
        "start": 758.649,
        "duration": 1.241
    },
    {
        "text": "Your cat has a model of the world.",
        "start": 759.89,
        "duration": 2.949
    },
    {
        "text": "When this model of the world is violated,\nyou either find that funny or scary, but,",
        "start": 762.839,
        "duration": 8.591
    },
    {
        "text": "in any case, we pay attention because you\nlearn from it.",
        "start": 771.43,
        "duration": 4.31
    },
    {
        "text": "so here's a baby orangutan here being shown\na magic trick.",
        "start": 775.74,
        "duration": 5.599
    },
    {
        "text": "An object is being removed from the cup and\nthey show the cup, the cup is empty and the",
        "start": 781.339,
        "duration": 5.61
    },
    {
        "text": "baby orangutan [crosstalk 00:18:06].",
        "start": 786.949,
        "duration": 3.521
    },
    {
        "text": "They're rolling on the floor laughing.",
        "start": 790.47,
        "duration": 3.39
    },
    {
        "text": "Obviously, his model of the world was violated.",
        "start": 793.86,
        "duration": 2.709
    },
    {
        "text": "The object had to be in the cup and it wasn't\nthere and he said, \"What?",
        "start": 796.569,
        "duration": 3.83
    },
    {
        "text": "This is funny.\"",
        "start": 800.399,
        "duration": 1.44
    },
    {
        "text": "How do we get machines to learn models of\nthe world this way by observation?",
        "start": 801.839,
        "duration": 4.73
    },
    {
        "text": "That's what we don't know how to do.",
        "start": 806.569,
        "duration": 1.151
    },
    {
        "text": "We aren't going to have truly intelligent\nmachines until we figure this one out.",
        "start": 807.72,
        "duration": 3.69
    },
    {
        "text": "Before we even get into the even more mind\nblowing AI stuff that's coming in the farther",
        "start": 811.41,
        "duration": 7.039
    },
    {
        "text": "future, let's just talk about the next 10\nyears for a second.",
        "start": 818.449,
        "duration": 3.82
    },
    {
        "text": "Peter, when we talk about the distinction\nbetween maybe what's coming in 10 or 20 years",
        "start": 822.269,
        "duration": 7.201
    },
    {
        "text": "and the stuff that maybe humans can do and\nwhat we have now, how would you define it?",
        "start": 829.47,
        "duration": 3.77
    },
    {
        "text": "Well, I think that artificial narrow intelligence\nis here.",
        "start": 833.24,
        "duration": 3.67
    },
    {
        "text": "It's in every aspect of our lives now.",
        "start": 836.91,
        "duration": 2.359
    },
    {
        "text": "I think we're going to continue in that direction.",
        "start": 839.269,
        "duration": 3.42
    },
    {
        "text": "That alone is going to change our lives in\na big way just as airplanes changed all of",
        "start": 842.689,
        "duration": 3.921
    },
    {
        "text": "our lives.",
        "start": 846.61,
        "duration": 1.44
    },
    {
        "text": "We don't expect there to be general airplanes.",
        "start": 848.05,
        "duration": 2.87
    },
    {
        "text": "We don't want them to do anything but fly\nus to our destination.",
        "start": 850.92,
        "duration": 2.349
    },
    {
        "text": "We don't ask them to watch our children or\nmow the lawn and that's okay.",
        "start": 853.269,
        "duration": 4.98
    },
    {
        "text": "The question then is, down the line, beyond\n10 years, will there be other systems that",
        "start": 858.249,
        "duration": 3.51
    },
    {
        "text": "can watch our children and fly and mow the\nlawn.",
        "start": 861.759,
        "duration": 3.401
    },
    {
        "text": "Well, do we really want that?",
        "start": 865.16,
        "duration": 1.71
    },
    {
        "text": "I think the next 10 years is really all about\nartificial narrow intelligence becoming ever",
        "start": 866.87,
        "duration": 3.879
    },
    {
        "text": "more powerful.",
        "start": 870.749,
        "duration": 1.0
    },
    {
        "text": "The real hurdle is going to be the mental\nmodels because take a case like the successes",
        "start": 871.749,
        "duration": 6.57
    },
    {
        "text": "of the past five years and recognizing objects\nhas been afforded by supervised learning where",
        "start": 878.319,
        "duration": 6.231
    },
    {
        "text": "you provide lots of labels as in the ImageNet\ncase.",
        "start": 884.55,
        "duration": 2.87
    },
    {
        "text": "But I would argue that a lot of what we regard\nas vision, for example, is a representation",
        "start": 887.42,
        "duration": 5.38
    },
    {
        "text": "of what's invisible and cannot be easily labeled.",
        "start": 892.8,
        "duration": 2.589
    },
    {
        "text": "So for example, the contents of other people's\nminds is invisible.",
        "start": 895.389,
        "duration": 4.48
    },
    {
        "text": "The backs of objects, the shapes of things,\ncausation.",
        "start": 899.869,
        "duration": 3.931
    },
    {
        "text": "Our conscious experience is the ultimate model\nthat evolution gave us of what's going on",
        "start": 903.8,
        "duration": 5.449
    },
    {
        "text": "in the world right now in our bodies in that\nworld and it includes a whole story about",
        "start": 909.249,
        "duration": 4.45
    },
    {
        "text": "what's going on, causation, other minds, and\nso forth.",
        "start": 913.699,
        "duration": 2.411
    },
    {
        "text": "That's going to be tricky to get to, this\nrepresentation of the invisible.",
        "start": 916.11,
        "duration": 3.37
    },
    {
        "text": "I think it's going to be very tricky for AI\nto come up with systems that regard an absence",
        "start": 919.48,
        "duration": 5.94
    },
    {
        "text": "of information as informative short of full-blown\nmental models, which are, in turn, many of",
        "start": 925.42,
        "duration": 6.259
    },
    {
        "text": "them realized in our own experience, our subjective\nexperience of our bodies in this world.",
        "start": 931.679,
        "duration": 4.991
    },
    {
        "text": "I think there's a long way to go.",
        "start": 936.67,
        "duration": 3.039
    },
    {
        "text": "Yeah, you keep hearing about new areas of\nlife that you don't expect AI to apply to.",
        "start": 939.709,
        "duration": 5.731
    },
    {
        "text": "First, it was gaming and other things, driving\ncars, and one after the other it keeps proving",
        "start": 945.44,
        "duration": 5.519
    },
    {
        "text": "us wrong.",
        "start": 950.959,
        "duration": 1.16
    },
    {
        "text": "One area that AI has started to move into\nis the world that we really don't associate",
        "start": 952.119,
        "duration": 7.361
    },
    {
        "text": "with computers, art and creativity.",
        "start": 959.48,
        "duration": 2.359
    },
    {
        "text": "Hod Lipson, who was actually in that first\nvideo, he and his team have created an AI",
        "start": 961.839,
        "duration": 6.261
    },
    {
        "text": "artist, very sassy artist.",
        "start": 968.1,
        "duration": 2.729
    },
    {
        "text": "This AI has actually created something that\nI'd like to show you and be nice.",
        "start": 970.829,
        "duration": 8.74
    },
    {
        "text": "It's sassy.",
        "start": 979.569,
        "duration": 2.74
    },
    {
        "text": "Right?",
        "start": 982.309,
        "duration": 1.38
    },
    {
        "text": "Not so bad.",
        "start": 983.689,
        "duration": 2.87
    },
    {
        "text": "We actually have a video of this being made\nand are we impressed or we not impressed?",
        "start": 986.559,
        "duration": 5.57
    },
    {
        "text": "How do we feel about this?",
        "start": 992.129,
        "duration": 1.091
    },
    {
        "text": "Earlier we were talking about this and I guess\nI didn't feel like it's a true instance of",
        "start": 993.22,
        "duration": 6.959
    },
    {
        "text": "creativity because it's just a copy, but then\nothers said, \"Well, it infused its own take",
        "start": 1000.179,
        "duration": 8.26
    },
    {
        "text": "on the painting.\"",
        "start": 1008.439,
        "duration": 2.99
    },
    {
        "text": "My concern is that there's just not enough\ncreativity but I do think that moving into",
        "start": 1011.429,
        "duration": 6.02
    },
    {
        "text": "the future I wouldn't be surprised if we did\nsee novel instances of true creativity in",
        "start": 1017.449,
        "duration": 6.651
    },
    {
        "text": "machines.",
        "start": 1024.1,
        "duration": 1.0
    },
    {
        "text": "Ouch.",
        "start": 1025.1,
        "duration": 1.0
    },
    {
        "text": "Yeah.",
        "start": 1026.1,
        "duration": 1.0
    },
    {
        "text": "Sorry, Hod.",
        "start": 1027.1,
        "duration": 1.26
    },
    {
        "text": "AI has eclipsed humans.",
        "start": 1028.36,
        "duration": 3.41
    },
    {
        "text": "It takes a while but when it gets good at\nchess, it never looks back.",
        "start": 1031.77,
        "duration": 5.919
    },
    {
        "text": "Suddenly it is officially better than chess\nthan all humans forever by far.",
        "start": 1037.689,
        "duration": 4.361
    },
    {
        "text": "Is it going to suddenly just be putting Mozart\nto shame where we say, \"Who would ever listen",
        "start": 1042.05,
        "duration": 3.8
    },
    {
        "text": "to human-written music anymore?\"",
        "start": 1045.85,
        "duration": 1.64
    },
    {
        "text": "No, I think it's going to help us be more\ncreative.",
        "start": 1047.49,
        "duration": 2.45
    },
    {
        "text": "It's going to be an amplification of our intelligence\nand our creativity.",
        "start": 1049.94,
        "duration": 2.839
    },
    {
        "text": "At the root of art, there is generally the\ncommunication of emotions.",
        "start": 1052.779,
        "duration": 6.821
    },
    {
        "text": "Art is really about either evoking or communicating\nemotions and if there is no emotion to communicate,",
        "start": 1059.6,
        "duration": 7.819
    },
    {
        "text": "there is no point.",
        "start": 1067.419,
        "duration": 1.0
    },
    {
        "text": "If you put a machine that doesn't have emotion\nproducing art, it might evoke an emotion but",
        "start": 1068.419,
        "duration": 4.781
    },
    {
        "text": "not communicate one.",
        "start": 1073.2,
        "duration": 4.459
    },
    {
        "text": "I like living nearby here because I'm walking\ndistance to one of my favorite jazz clubs.",
        "start": 1077.659,
        "duration": 6.711
    },
    {
        "text": "I'm a huge jazz fan.",
        "start": 1084.37,
        "duration": 1.06
    },
    {
        "text": "Jazz is really about real-time communication\nof emotions.",
        "start": 1085.43,
        "duration": 4.39
    },
    {
        "text": "It's like it's open door to the soul of the\nperformer.",
        "start": 1089.82,
        "duration": 5.18
    },
    {
        "text": "I don't see the point of having a machine\ndo this because then there is no communication",
        "start": 1095.0,
        "duration": 3.61
    },
    {
        "text": "to beâ€¦",
        "start": 1098.61,
        "duration": 1.0
    },
    {
        "text": "You're saying even if an AI could be programmed\nto see the audience, feel the room, understand",
        "start": 1099.61,
        "duration": 4.58
    },
    {
        "text": "the deal, and knows exactly how the best jazz\nmusicians communicate with that particular",
        "start": 1104.19,
        "duration": 7.18
    },
    {
        "text": "emotion, there's actually going to be, just\nby definition, something missing 'cause the",
        "start": 1111.37,
        "duration": 4.78
    },
    {
        "text": "audience knows that it's manipulating it.",
        "start": 1116.15,
        "duration": 3.07
    },
    {
        "text": "Objectively, it might not be missing, because\nit might not be distinguishable from something",
        "start": 1119.22,
        "duration": 5.069
    },
    {
        "text": "that's actually produced by a human, but my\nguess is that the feeling of the audience",
        "start": 1124.289,
        "duration": 5.191
    },
    {
        "text": "will be different because they will know it\ncomes from a machine.",
        "start": 1129.48,
        "duration": 2.81
    },
    {
        "text": "It might take many decades, perhaps centuries\nbefore people's attitudes towards creation",
        "start": 1132.29,
        "duration": 5.85
    },
    {
        "text": "by machine will change, but, eventually ...I\nhad this discussion with a famous economist,",
        "start": 1138.14,
        "duration": 6.08
    },
    {
        "text": "in fact, a Nobel prize-winning economist called\nDaniel Kahneman, who I made that point that",
        "start": 1144.22,
        "duration": 7.51
    },
    {
        "text": "communication of emotion may take a while\nfor machines.",
        "start": 1151.73,
        "duration": 3.81
    },
    {
        "text": "He said, \"Yeah, but eventually they'll at\nleast be able to simulate it well enough that",
        "start": 1155.54,
        "duration": 5.43
    },
    {
        "text": "we won't be able to tell the difference.\"",
        "start": 1160.97,
        "duration": 3.11
    },
    {
        "text": "That's a very good point.",
        "start": 1164.08,
        "duration": 1.31
    },
    {
        "text": "I cringe a little bit when someone asks, \"Oh,\nis this real creativity?\"",
        "start": 1165.39,
        "duration": 5.51
    },
    {
        "text": "Because you were joking earlier about how\npeople often say, \"Oh, that's not real intelligence\"",
        "start": 1170.9,
        "duration": 4.06
    },
    {
        "text": "as soon as the machine figures out how to\ndo it.",
        "start": 1174.96,
        "duration": 3.98
    },
    {
        "text": "If you take the point of view that intelligence\nis all about information processing and that",
        "start": 1178.94,
        "duration": 7.17
    },
    {
        "text": "creativity is also just a certain kind of\nvery sophisticated information processing",
        "start": 1186.11,
        "duration": 4.9
    },
    {
        "text": "that we do with our brains, but then the question\nisn't if it's possible for machines to be",
        "start": 1191.01,
        "duration": 5.08
    },
    {
        "text": "creative but simply are we smart enough to\nactually make such machines, will they happen",
        "start": 1196.09,
        "duration": 4.11
    },
    {
        "text": "eventually.",
        "start": 1200.2,
        "duration": 1.0
    },
    {
        "text": "I have a lot of friends I respect who are\nvery smart who think that machines can never",
        "start": 1201.2,
        "duration": 7.06
    },
    {
        "text": "be creative or even as intelligent as us because\nthey view intelligence and creativity as something",
        "start": 1208.26,
        "duration": 5.909
    },
    {
        "text": "mysterious that can only exist in biological\norganisms like us.",
        "start": 1214.169,
        "duration": 5.591
    },
    {
        "text": "But, as a physicist, I consider that attitude\ncarbon chauvinism.",
        "start": 1219.76,
        "duration": 5.19
    },
    {
        "text": "I think it's arrogant to say that you can\nonly be smart and creative if you're made",
        "start": 1224.95,
        "duration": 4.57
    },
    {
        "text": "of meat.",
        "start": 1229.52,
        "duration": 1.0
    },
    {
        "text": "I'm made of exactly the same kind of electrons\nand other elementary particles as the food",
        "start": 1230.52,
        "duration": 5.61
    },
    {
        "text": "I eat and as my laptop.",
        "start": 1236.13,
        "duration": 2.08
    },
    {
        "text": "It's all about how the patterns in which the\nparticles are arranged, so it's ultimately",
        "start": 1238.21,
        "duration": 3.689
    },
    {
        "text": "all about information processing the way I\nsee it.",
        "start": 1241.899,
        "duration": 3.28
    },
    {
        "text": "That makes sense.",
        "start": 1245.179,
        "duration": 1.0
    },
    {
        "text": "In the end, it's just the elementary particles\nand ... Yeah.",
        "start": 1246.179,
        "duration": 3.831
    },
    {
        "text": "Can I return for a moment to the creativity?",
        "start": 1250.01,
        "duration": 2.94
    },
    {
        "text": "Because I would argue that something like\nthis is 'as if' creativity and it's not really",
        "start": 1252.95,
        "duration": 5.39
    },
    {
        "text": "yet the real thing.",
        "start": 1258.34,
        "duration": 1.0
    },
    {
        "text": "I'm not saying it's impossible.",
        "start": 1259.34,
        "duration": 1.28
    },
    {
        "text": "We are existence proof that physical systems\ncan be creative.",
        "start": 1260.62,
        "duration": 5.58
    },
    {
        "text": "The kind of creativity I find to be most impressive\nis when people like Einstein completely reconfigure",
        "start": 1266.2,
        "duration": 5.47
    },
    {
        "text": "our understanding of something like space\nor gravity, poof, just in that totally new",
        "start": 1271.67,
        "duration": 4.28
    },
    {
        "text": "way or take music and create a whole new form\nlike jazz.",
        "start": 1275.95,
        "duration": 4.2
    },
    {
        "text": "Now, these convolutional neural networks as\nthey currently exist need to be taught, so",
        "start": 1280.15,
        "duration": 4.04
    },
    {
        "text": "given lots of examples of Mozart and then\ncan produce something like Mozart but are",
        "start": 1284.19,
        "duration": 3.78
    },
    {
        "text": "they then going to create a new form?",
        "start": 1287.97,
        "duration": 3.03
    },
    {
        "text": "I suspect the answer is no, that we're going\nto have to accomplish something more like",
        "start": 1291.0,
        "duration": 5.88
    },
    {
        "text": "deep unsupervised learning which is what babies\nand children do.",
        "start": 1296.88,
        "duration": 4.46
    },
    {
        "text": "Part of that, I think, is going to be moving\nfrom the nouns of the mind like labeling house,",
        "start": 1301.34,
        "duration": 4.94
    },
    {
        "text": "person, face, to the verbs of the mind.",
        "start": 1306.28,
        "duration": 2.73
    },
    {
        "text": "Very central to human cognition is mental\noperations.",
        "start": 1309.01,
        "duration": 3.039
    },
    {
        "text": "If you look at some of the first instances\nof creativity in our species, they're really",
        "start": 1312.049,
        "duration": 4.49
    },
    {
        "text": "mind blowing.",
        "start": 1316.539,
        "duration": 1.0
    },
    {
        "text": "30,000 years ago in a cave that is now near\nUlm, Germany somebody put a lion's head on",
        "start": 1317.539,
        "duration": 7.031
    },
    {
        "text": "a human body, which took an operation of downloading\na lion's head, putting a human body, sticking",
        "start": 1324.57,
        "duration": 5.209
    },
    {
        "text": "it together, and then going and making it\nin the world.",
        "start": 1329.779,
        "duration": 2.991
    },
    {
        "text": "Now, modern examples would be lying in bed,\nmaybe like Orville Wright did for two years,",
        "start": 1332.77,
        "duration": 4.48
    },
    {
        "text": "thinking about how to fly and then he said,\n\"Well, actually we don't need to flap.",
        "start": 1337.25,
        "duration": 3.62
    },
    {
        "text": "We can just pull the whole thing forward with\na big fan.\"",
        "start": 1340.87,
        "duration": 3.34
    },
    {
        "text": "Then, going and building it and making an\nairplane and thereby changing the world.",
        "start": 1344.21,
        "duration": 6.72
    },
    {
        "text": "Mental operations, this dynamic almost syntactic\noperations that take place in our working",
        "start": 1350.93,
        "duration": 6.08
    },
    {
        "text": "memory, is something that's very central to\nwhat we do and is at the heart of our creativity",
        "start": 1357.01,
        "duration": 6.129
    },
    {
        "text": "and I think is very different from this 'as\nif' creativity that results from supervised",
        "start": 1363.139,
        "duration": 6.481
    },
    {
        "text": "learning with thousands of examples.",
        "start": 1369.62,
        "duration": 3.21
    },
    {
        "text": "True originality might be harder.",
        "start": 1372.83,
        "duration": 2.62
    },
    {
        "text": "Although, maybe humans are also ... We're\nwired to fit in and copy what's done.",
        "start": 1375.45,
        "duration": 6.349
    },
    {
        "text": "Maybe it will be released of the burden, of\nthe fear of failure that sometimes hinders",
        "start": 1381.799,
        "duration": 4.401
    },
    {
        "text": "originality.",
        "start": 1386.2,
        "duration": 1.0
    },
    {
        "text": "Maybe once it gets there, it could be super\noriginal in some ways, but it's not there",
        "start": 1387.2,
        "duration": 5.37
    },
    {
        "text": "in every way.",
        "start": 1392.57,
        "duration": 1.0
    },
    {
        "text": "We have such a good way to show you that AI\nis not there in all these different ways yet",
        "start": 1393.57,
        "duration": 5.52
    },
    {
        "text": "in some ways.",
        "start": 1399.09,
        "duration": 2.449
    },
    {
        "text": "It has to do with a movie called Sunspring\nwhich was a screenplay ... There was an AI",
        "start": 1401.539,
        "duration": 6.721
    },
    {
        "text": "that was fed thousands of screenplays.",
        "start": 1408.26,
        "duration": 2.18
    },
    {
        "text": "They said, \"Now, take all of that and write\nus a great screenplay.\"",
        "start": 1410.44,
        "duration": 4.26
    },
    {
        "text": "The AI did its best and they actually got\nhuman actors and they acted out verbatim what",
        "start": 1414.7,
        "duration": 4.92
    },
    {
        "text": "the AI did.",
        "start": 1419.62,
        "duration": 1.61
    },
    {
        "text": "So, I'll let you judge for yourself, but ... Turn\nthis on here.",
        "start": 1421.23,
        "duration": 8.669
    },
    {
        "text": "All right, you can't tell me that.",
        "start": 1429.899,
        "duration": 3.13
    },
    {
        "text": "Yeah, I was coming to that thing because you\nwere so pretty.",
        "start": 1433.029,
        "duration": 5.101
    },
    {
        "text": "I don't know.",
        "start": 1438.13,
        "duration": 1.0
    },
    {
        "text": "I don't know what you're talking about.",
        "start": 1439.13,
        "duration": 2.4
    },
    {
        "text": "That's right.",
        "start": 1441.53,
        "duration": 2.32
    },
    {
        "text": "So, what are you doing?",
        "start": 1443.85,
        "duration": 5.799
    },
    {
        "text": "I don't want to be honest with you.",
        "start": 1449.649,
        "duration": 1.861
    },
    {
        "text": "You don't have to be a doctor.",
        "start": 1451.51,
        "duration": 2.149
    },
    {
        "text": "I am not sure.",
        "start": 1453.659,
        "duration": 1.431
    },
    {
        "text": "I don't know what you're talking about.",
        "start": 1455.09,
        "duration": 1.36
    },
    {
        "text": "I want to see you too.",
        "start": 1456.45,
        "duration": 1.609
    },
    {
        "text": "What do you mean?",
        "start": 1458.059,
        "duration": 1.631
    },
    {
        "text": "I'm sure you wouldn't even touch me.",
        "start": 1459.69,
        "duration": 2.22
    },
    {
        "text": "I don't know what you're talking about.",
        "start": 1461.91,
        "duration": 4.32
    },
    {
        "text": "Principle is completely constructed of the\nsame time.",
        "start": 1466.23,
        "duration": 4.26
    },
    {
        "text": "It's all about you to be true.",
        "start": 1470.49,
        "duration": 1.069
    },
    {
        "text": "You didn't even watch the movie with the rest\nof the base.",
        "start": 1471.559,
        "duration": 2.391
    },
    {
        "text": "I don't know.",
        "start": 1473.95,
        "duration": 1.0
    },
    {
        "text": "I don't care.",
        "start": 1474.95,
        "duration": 1.0
    },
    {
        "text": "I know it's a consequence.",
        "start": 1475.95,
        "duration": 1.99
    },
    {
        "text": "Whatever you need to know about the presence\nof the story, I'm a little bit of a boy on",
        "start": 1477.94,
        "duration": 6.97
    },
    {
        "text": "the floor.",
        "start": 1484.91,
        "duration": 2.83
    },
    {
        "text": "I don't know.",
        "start": 1487.74,
        "duration": 1.55
    },
    {
        "text": "I need you to explain to me what you say.",
        "start": 1489.29,
        "duration": 4.83
    },
    {
        "text": "What do you mean?",
        "start": 1494.12,
        "duration": 1.17
    },
    {
        "text": "Because I don't know what you're talking about.",
        "start": 1495.29,
        "duration": 3.139
    },
    {
        "text": "That?",
        "start": 1498.429,
        "duration": 1.261
    },
    {
        "text": "That was all the time.",
        "start": 1499.69,
        "duration": 6.3
    },
    {
        "text": "Would have been a good time.",
        "start": 1505.99,
        "duration": 7.559
    },
    {
        "text": "It's a little uneven right now.",
        "start": 1513.549,
        "duration": 2.121
    },
    {
        "text": "This is, again, the present right now and\nmaybe a little bit of what we can expect in",
        "start": 1515.67,
        "duration": 4.119
    },
    {
        "text": "the next few years.",
        "start": 1519.789,
        "duration": 1.191
    },
    {
        "text": "What I want to move into now, which is really\nthe mind blowing stuff, is where this is going.",
        "start": 1520.98,
        "duration": 6.949
    },
    {
        "text": "Max, what is artificial general intelligence\nand how is it different than what we have",
        "start": 1527.929,
        "duration": 5.522
    },
    {
        "text": "now?",
        "start": 1533.451,
        "duration": 1.0
    },
    {
        "text": "Yeah, if we can have this picture up here,\nI'll explain how I like to think about this.",
        "start": 1534.451,
        "duration": 6.068
    },
    {
        "text": "I like to think about this question in terms\nof this abstract landscape of tasks where",
        "start": 1540.519,
        "duration": 4.941
    },
    {
        "text": "the elevation represents how hard it is for\nAI to do each task at human level and the",
        "start": 1545.46,
        "duration": 5.599
    },
    {
        "text": "sea level represents what AI can do today.",
        "start": 1551.059,
        "duration": 3.711
    },
    {
        "text": "The sea level is obviously rising so there's\na kind of global warming going on here in",
        "start": 1554.77,
        "duration": 4.71
    },
    {
        "text": "the task landscape.",
        "start": 1559.48,
        "duration": 1.079
    },
    {
        "text": "The obvious take away from this is you should\navoid careers right at the waterfront of course,",
        "start": 1560.559,
        "duration": 5.051
    },
    {
        "text": "which will soon be disrupted by automation.",
        "start": 1565.61,
        "duration": 1.16
    },
    {
        "text": "The much bigger question that you're going\nfor is, how high will the water end up rising?",
        "start": 1566.77,
        "duration": 6.73
    },
    {
        "text": "Will it eventually submerge all land matching\nhuman intelligence at all tasks?",
        "start": 1573.5,
        "duration": 5.419
    },
    {
        "text": "This is the definition of artificial general\nintelligence.",
        "start": 1578.919,
        "duration": 2.931
    },
    {
        "text": "This has been the Holy Grail of AI research\never since its inception.",
        "start": 1581.85,
        "duration": 6.049
    },
    {
        "text": "Right, it's so hard to understand because\nwe've never experienced a world where there's",
        "start": 1587.899,
        "duration": 5.921
    },
    {
        "text": "something that's generally intelligent on\na human level other than humans.",
        "start": 1593.82,
        "duration": 2.96
    },
    {
        "text": "It's going to be something different than\nhumans that is also smart the way humans are.",
        "start": 1596.78,
        "duration": 5.639
    },
    {
        "text": "That is so mindboggling that we can't apply\nour own experience and say, \"Well, it might",
        "start": 1602.419,
        "duration": 4.14
    },
    {
        "text": "be something like that.\"",
        "start": 1606.559,
        "duration": 2.191
    },
    {
        "text": "It's going to be very hard for us to even\nimagine.",
        "start": 1608.75,
        "duration": 2.23
    },
    {
        "text": "Yann, you talk about that it's ... You almost\nrefer to it as hypothetical at this point.",
        "start": 1610.98,
        "duration": 6.34
    },
    {
        "text": "Well, not only don't we have the technology\nfor this, we don't even have the science,",
        "start": 1617.32,
        "duration": 4.77
    },
    {
        "text": "so we don't know what principles the intelligent\nmachines at the level of human intelligence",
        "start": 1622.09,
        "duration": 4.79
    },
    {
        "text": "will be based on.",
        "start": 1626.88,
        "duration": 2.879
    },
    {
        "text": "Now, we like to think of ourselves as being\ngenerally intelligent, but we're not.",
        "start": 1629.759,
        "duration": 3.811
    },
    {
        "text": "We're actually very specialized as well.",
        "start": 1633.57,
        "duration": 2.329
    },
    {
        "text": "We're more general than, of course, all the\nmachines that we have, but our brains are",
        "start": 1635.899,
        "duration": 3.16
    },
    {
        "text": "very specialized.",
        "start": 1639.059,
        "duration": 1.08
    },
    {
        "text": "There's only certain things we do well and\nif there's anything that experiments like",
        "start": 1640.139,
        "duration": 4.081
    },
    {
        "text": "AlphaGo has proved in the recent years is\nthat we totally suck at Go.",
        "start": 1644.22,
        "duration": 4.13
    },
    {
        "text": "We're really bad at Go.",
        "start": 1648.35,
        "duration": 2.279
    },
    {
        "text": "The stupid machine can beat us by a very,\nvery large margin.",
        "start": 1650.629,
        "duration": 7.741
    },
    {
        "text": "We're not very good at exploring trees, for\nexample, of options because we don't have",
        "start": 1658.37,
        "duration": 3.769
    },
    {
        "text": "that much memory.",
        "start": 1662.139,
        "duration": 1.481
    },
    {
        "text": "There's a lot of tasks like this that ... We're\nnot very good at planning a path from a city",
        "start": 1663.62,
        "duration": 4.84
    },
    {
        "text": "to another.",
        "start": 1668.46,
        "duration": 1.0
    },
    {
        "text": "This algorithm that runs on your GPS is much\nbetter at this than you are.",
        "start": 1669.46,
        "duration": 4.23
    },
    {
        "text": "There are things like this that we're not\nparticularly good at.",
        "start": 1673.69,
        "duration": 2.0
    },
    {
        "text": "We know how to do them somehow, but our brains\nare somewhat specialized.",
        "start": 1675.69,
        "duration": 4.739
    },
    {
        "text": "Now, the thing is, you were talking about\na new species, AI being very different from",
        "start": 1680.429,
        "duration": 5.49
    },
    {
        "text": "human intelligence.",
        "start": 1685.919,
        "duration": 1.0
    },
    {
        "text": "It will be very different from human intelligence\nand there is one, it's sort of a trap, that",
        "start": 1686.919,
        "duration": 8.941
    },
    {
        "text": "is very easy to fall into which is to assume\nthat when machines will be intelligent, they",
        "start": 1695.86,
        "duration": 4.491
    },
    {
        "text": "will have all the side effects if you want,\nall the characteristics of human intelligence.",
        "start": 1700.351,
        "duration": 7.239
    },
    {
        "text": "They will not.",
        "start": 1707.59,
        "duration": 1.42
    },
    {
        "text": "For example, there is the traditional Terminator\nscenario that we've all heard about of machines",
        "start": 1709.01,
        "duration": 8.1
    },
    {
        "text": "will become super intelligent and then they\nwill want to take over the world and kill",
        "start": 1717.11,
        "duration": 3.42
    },
    {
        "text": "us all.There's a lot of people who have been\nclaiming this is going to happen and it's",
        "start": 1720.53,
        "duration": 4.369
    },
    {
        "text": "inevitable and blah, blah, blah, or at least\nit's a definite danger.",
        "start": 1724.899,
        "duration": 3.691
    },
    {
        "text": "Now, the thing is, even in the human species,\nthe desire to take over is not actually correlated",
        "start": 1728.59,
        "duration": 9.25
    },
    {
        "text": "with intelligence.",
        "start": 1737.84,
        "duration": 1.0
    },
    {
        "text": "It's true.",
        "start": 1738.84,
        "duration": 1.0
    },
    {
        "text": "That is true.",
        "start": 1739.84,
        "duration": 8.66
    },
    {
        "text": "It's not like the people who are in leadership\npositions are necessarily the smartest.",
        "start": 1748.5,
        "duration": 7.139
    },
    {
        "text": "In fact, there is an evolutionary argument\nfor the fact that it's if you are stupid that",
        "start": 1755.639,
        "duration": 6.99
    },
    {
        "text": "you want to be the chief.",
        "start": 1762.629,
        "duration": 3.051
    },
    {
        "text": "Because if you are smart to survive on your\nown, you don't need to convince anybody to",
        "start": 1765.68,
        "duration": 4.129
    },
    {
        "text": "help you, but if you are stupid, you need\neverybody else to help you feed you essentially.",
        "start": 1769.809,
        "duration": 7.031
    },
    {
        "text": "The desire to take over is not correlated\nwith intelligence.",
        "start": 1776.84,
        "duration": 2.24
    },
    {
        "text": "It's correlated with testosterone probably.",
        "start": 1779.08,
        "duration": 2.04
    },
    {
        "text": "Yeah.",
        "start": 1781.12,
        "duration": 1.0
    },
    {
        "text": "Tim, if I may just add a little bit to what\nI said.",
        "start": 1782.12,
        "duration": 1.899
    },
    {
        "text": "I completely agree with you, Yann, of course,\nthat the Terminator stuff is silly and absolutely",
        "start": 1784.019,
        "duration": 5.731
    },
    {
        "text": "not something that we should worry about,\nbut I think it's worth emphasizing a little",
        "start": 1789.75,
        "duration": 3.549
    },
    {
        "text": "bit more why, nonetheless, artificial general\nintelligence is such a big deal if we ever",
        "start": 1793.299,
        "duration": 6.561
    },
    {
        "text": "get there.",
        "start": 1799.86,
        "duration": 1.39
    },
    {
        "text": "First of all, it's important to remember that\nintelligence can give power.",
        "start": 1801.25,
        "duration": 5.13
    },
    {
        "text": "If you had artificial general intelligence\nand you are, for example, Google, you could",
        "start": 1806.38,
        "duration": 5.69
    },
    {
        "text": "replace your 40,000 engineers by 40,000 AIs\nthat could work much faster and didn't have",
        "start": 1812.07,
        "duration": 5.58
    },
    {
        "text": "to take breaks.",
        "start": 1817.65,
        "duration": 2.32
    },
    {
        "text": "Before too long, you could be incredibly rich\nand powerful and start having a vast amount",
        "start": 1819.97,
        "duration": 5.459
    },
    {
        "text": "of real power in the physical world.",
        "start": 1825.429,
        "duration": 2.351
    },
    {
        "text": "In that sense, it gives great power.",
        "start": 1827.78,
        "duration": 5.649
    },
    {
        "text": "Then, you can ask the question even if the\nAI doesn't, as in sci-fi movies itself, somehow",
        "start": 1833.429,
        "duration": 8.411
    },
    {
        "text": "break out and take over, do we want whatever\nhumans happen to be controlling the first",
        "start": 1841.84,
        "duration": 4.809
    },
    {
        "text": "AGI to unelected be able to take power over\nthe planet or would we like this power to",
        "start": 1846.649,
        "duration": 6.041
    },
    {
        "text": "be shared more broadly?",
        "start": 1852.69,
        "duration": 2.42
    },
    {
        "text": "That's one example of why it's such a big\ndeal.",
        "start": 1855.11,
        "duration": 1.939
    },
    {
        "text": "A second example of why AGI, I think, would\nbe a huge deal is because even though I completely",
        "start": 1857.049,
        "duration": 6.51
    },
    {
        "text": "agree with you, Yann, that we humans are very\ndumb and my teenage sons remind of this very",
        "start": 1863.559,
        "duration": 7.041
    },
    {
        "text": "often that I'm very dumb, there's so much\nthat we can't do You might think there's nothing",
        "start": 1870.6,
        "duration": 3.949
    },
    {
        "text": "special about human intelligence in the grand\nscheme of things, but there is actually.",
        "start": 1874.549,
        "duration": 4.47
    },
    {
        "text": "Because in the evolution of Earth, we have\nexactly just barely reached the level we are",
        "start": 1879.019,
        "duration": 4.991
    },
    {
        "text": "able to develop technology that might be able\nto supersede us.",
        "start": 1884.01,
        "duration": 6.48
    },
    {
        "text": "If we have machines, which can do everything\nwe can, they will then perhaps also be able",
        "start": 1890.49,
        "duration": 4.38
    },
    {
        "text": "to be used to develop ever better machines.",
        "start": 1894.87,
        "duration": 2.1
    },
    {
        "text": "It's still better and that can enable AI to\nbootstrap itself to become not just a tiny",
        "start": 1896.97,
        "duration": 4.789
    },
    {
        "text": "bit smarter than us, but way smarter.",
        "start": 1901.759,
        "duration": 2.591
    },
    {
        "text": "That leads to this whole controversial discussion\nabout an intelligence explosion, singularity",
        "start": 1904.35,
        "duration": 5.909
    },
    {
        "text": "and so on that's also very controversial.",
        "start": 1910.259,
        "duration": 2.52
    },
    {
        "text": "Those are the two reasons why I feel that\nAGI would be such a huge deal even though",
        "start": 1912.779,
        "duration": 6.081
    },
    {
        "text": "I agree with what you said.",
        "start": 1918.86,
        "duration": 2.419
    },
    {
        "text": "Let's also bring in, I think it's an elephant\nin the room, any time you're talking about",
        "start": 1921.279,
        "duration": 3.211
    },
    {
        "text": "human level of beyond intelligent computers,\nconsciousness.",
        "start": 1924.49,
        "duration": 10.299
    },
    {
        "text": "Of all the different debates in AI that are\nhugely controversial, this is probably the",
        "start": 1934.789,
        "duration": 4.22
    },
    {
        "text": "most.",
        "start": 1939.009,
        "duration": 1.0
    },
    {
        "text": "You have people all over the place.",
        "start": 1940.009,
        "duration": 3.37
    },
    {
        "text": "Let's just define consciousness so we can\nall be on the same page.",
        "start": 1943.379,
        "duration": 6.361
    },
    {
        "text": "Susan, what is consciousness to you?",
        "start": 1949.74,
        "duration": 1.74
    },
    {
        "text": "Well, it's the felt quality of experience.",
        "start": 1951.48,
        "duration": 2.63
    },
    {
        "text": "Right now, it feels like something from the\ninside to be you.",
        "start": 1954.11,
        "duration": 3.39
    },
    {
        "text": "Every moment of your waking life and even\nwhen you're dreaming, you are experiencing",
        "start": 1957.5,
        "duration": 4.559
    },
    {
        "text": "the world.",
        "start": 1962.059,
        "duration": 1.561
    },
    {
        "text": "Consciousness needs to be distinguished from\nconscious.",
        "start": 1963.62,
        "duration": 3.309
    },
    {
        "text": "A lot of people run them together at first\nwhen they're first thinking about it.",
        "start": 1966.929,
        "duration": 5.22
    },
    {
        "text": "To have a conscious is entirely different\nthan having that felt quality.",
        "start": 1972.149,
        "duration": 4.591
    },
    {
        "text": "That's just what it is to be alert and alive.",
        "start": 1976.74,
        "duration": 4.809
    },
    {
        "text": "When you see the rich hues of a sunset, when\nyou smell the aroma of your morning coffee,",
        "start": 1981.549,
        "duration": 4.76
    },
    {
        "text": "you're having conscious experience.",
        "start": 1986.309,
        "duration": 2.431
    },
    {
        "text": "I completely agree that consciousness is a\nsubjective experience.",
        "start": 1988.74,
        "duration": 5.24
    },
    {
        "text": "It's nothing else than that, but it's very\nspecial in that it is a domain of highly precompiled",
        "start": 1993.98,
        "duration": 9.559
    },
    {
        "text": "representations over which mental operators\ncan operate.",
        "start": 2003.539,
        "duration": 4.39
    },
    {
        "text": "The key operator, I think is attention, especially\nvolitional attention.",
        "start": 2007.929,
        "duration": 3.95
    },
    {
        "text": "You might have locked-in syndrome and you\ncould shift your volitional attention to the",
        "start": 2011.879,
        "duration": 3.16
    },
    {
        "text": "radio or the TV, so you'd even then have a\nkind of volitional control even in this domain",
        "start": 2015.039,
        "duration": 4.21
    },
    {
        "text": "of your consciousness.",
        "start": 2019.249,
        "duration": 1.991
    },
    {
        "text": "Consciousness is for something.",
        "start": 2021.24,
        "duration": 1.509
    },
    {
        "text": "It's for these planning areas to have a world.",
        "start": 2022.749,
        "duration": 3.071
    },
    {
        "text": "In one sense, it's a veridical hallucination,\nbut it's not a hallucination because it's",
        "start": 2025.82,
        "duration": 5.14
    },
    {
        "text": "not saying what's not there or it's saying\nwhat is there.",
        "start": 2030.96,
        "duration": 5.98
    },
    {
        "text": "It allows us to act in this world.",
        "start": 2036.94,
        "duration": 2.239
    },
    {
        "text": "That's only half of consciousness.",
        "start": 2039.179,
        "duration": 1.11
    },
    {
        "text": "The other half of consciousness is imagination.",
        "start": 2040.289,
        "duration": 2.36
    },
    {
        "text": "If I were to buzz you, probably about half\nof you right now are zoning out and thinking",
        "start": 2042.649,
        "duration": 5.191
    },
    {
        "text": "about this or that, but we spend about half\nof our lives in this imaginary virtual reality",
        "start": 2047.84,
        "duration": 7.46
    },
    {
        "text": "or our own creation.",
        "start": 2055.3,
        "duration": 1.579
    },
    {
        "text": "In this domain, we have total freedom.",
        "start": 2056.879,
        "duration": 1.561
    },
    {
        "text": "We can do anything and then we can go and\nbuild it in the world if we want.",
        "start": 2058.44,
        "duration": 4.64
    },
    {
        "text": "Consciousness is for something and it takes\nquite a while to make it.",
        "start": 2063.08,
        "duration": 3.98
    },
    {
        "text": "The photons in the world hit your retina at\ntime zero, your consciousness is not happening",
        "start": 2067.06,
        "duration": 4.29
    },
    {
        "text": "at time zero.",
        "start": 2071.35,
        "duration": 1.0
    },
    {
        "text": "There's a lot of processing that goes on in\nthe first quarter to a third of a second and",
        "start": 2072.35,
        "duration": 4.309
    },
    {
        "text": "then you experience a full-blown world that\nallows you then to act in the world.",
        "start": 2076.659,
        "duration": 5.901
    },
    {
        "text": "Yeah, I share the definition that you both\ngave of consciousness as subjective experience.",
        "start": 2082.56,
        "duration": 5.02
    },
    {
        "text": "When I drive down the street, I'm experiencing\ncolors and sounds and vibrations and motions,",
        "start": 2087.58,
        "duration": 5.4
    },
    {
        "text": "but does the self-driving car experience anything?",
        "start": 2092.98,
        "duration": 3.449
    },
    {
        "text": "That's a question I think we honestly don't\nhave a good scientific answer for yet.",
        "start": 2096.429,
        "duration": 7.16
    },
    {
        "text": "I love how controversial this is.",
        "start": 2103.589,
        "duration": 1.982
    },
    {
        "text": "If you look up the word consciousness in the\nMacmillan Dictionary of Psychology from a",
        "start": 2105.571,
        "duration": 4.499
    },
    {
        "text": "few years back, it says nothing of interest\nhas ever been written on the subject.",
        "start": 2110.07,
        "duration": 4.269
    },
    {
        "text": "Even when I asked a lot of science colleagues,\nmost of them say, \"Consciousness is just B.S.\"",
        "start": 2114.339,
        "duration": 7.581
    },
    {
        "text": "When I ask them why, I notice that they form\nthe two camps that disagree violently with",
        "start": 2121.92,
        "duration": 5.86
    },
    {
        "text": "each other about why it's B.S.",
        "start": 2127.78,
        "duration": 1.66
    },
    {
        "text": "Half of them say it's B.S. because, of course,\nmachines can't be conscious.",
        "start": 2129.44,
        "duration": 4.29
    },
    {
        "text": "You have to be made of meat to be conscious.",
        "start": 2133.73,
        "duration": 2.93
    },
    {
        "text": "Then, the other half says, \"Of course, this\nis B.S. because consciousness and intelligence",
        "start": 2136.66,
        "duration": 6.57
    },
    {
        "text": "are just the same thing.\"",
        "start": 2143.23,
        "duration": 1.17
    },
    {
        "text": "In other words, anything that acts as if it\nwere conscious will be conscious.",
        "start": 2144.4,
        "duration": 8.03
    },
    {
        "text": "To be contrarian, to most of my colleagues,\nI think the truth is probably somewhere in",
        "start": 2152.43,
        "duration": 3.901
    },
    {
        "text": "between because I know that most of the information\nprocessing in my brain I'm actually not conscious",
        "start": 2156.331,
        "duration": 5.639
    },
    {
        "text": "of, the heartbeat regulation and the vast\nmajority of other things.",
        "start": 2161.97,
        "duration": 3.69
    },
    {
        "text": "Actually, when I look up and be like, \"Oh,\nthere is Yann,\" I have no idea how all that",
        "start": 2165.66,
        "duration": 5.84
    },
    {
        "text": "information processing happens.",
        "start": 2171.5,
        "duration": 1.79
    },
    {
        "text": "What I'm aware of is just this CEO part of\nmy brain that gets emailed the end result",
        "start": 2173.29,
        "duration": 4.41
    },
    {
        "text": "of the computation.",
        "start": 2177.7,
        "duration": 5.09
    },
    {
        "text": "Not only do I think it's not a B.S. question,\nI think people who have been saying for so",
        "start": 2182.79,
        "duration": 4.71
    },
    {
        "text": "long it's a B.S. question have actually been\nlame and just running away from a genuine",
        "start": 2187.5,
        "duration": 6.819
    },
    {
        "text": "science question.",
        "start": 2194.319,
        "duration": 1.05
    },
    {
        "text": "'Cause usually if you have a great science\nquestion that lingers for hundreds of years",
        "start": 2195.369,
        "duration": 3.791
    },
    {
        "text": "it's because people just dismissed it rather\nthan doing the hard work.",
        "start": 2199.16,
        "duration": 3.84
    },
    {
        "text": "I think we need to do the hard work on this.",
        "start": 2203.0,
        "duration": 2.89
    },
    {
        "text": "If you're a physician in the emergency room\nand you have an unresponsive patient coming",
        "start": 2205.89,
        "duration": 3.75
    },
    {
        "text": "in, wouldn't it be great to have a consciousness\ndetector that can tell you whether this person",
        "start": 2209.64,
        "duration": 4.99
    },
    {
        "text": "is in a coma and there's one home or whether\nthey have locked-in syndrome?",
        "start": 2214.63,
        "duration": 4.25
    },
    {
        "text": "If you have a helper robot, wouldn't you want\nto know if it's conscious so you should feel",
        "start": 2218.88,
        "duration": 4.99
    },
    {
        "text": "guilty about switching it off?",
        "start": 2223.87,
        "duration": 2.15
    },
    {
        "text": "Or, whether it's just like a zombie so you\nshould feel creeped out when it's pretending",
        "start": 2226.02,
        "duration": 5.96
    },
    {
        "text": "to be happy about what you said?",
        "start": 2231.98,
        "duration": 3.109
    },
    {
        "text": "I'd like to know when we do these things.",
        "start": 2235.089,
        "duration": 4.421
    },
    {
        "text": "The question of consciousness is probably\nnot posed properly in the sense that back",
        "start": 2239.51,
        "duration": 8.72
    },
    {
        "text": "in the 18th century or 17th century or even\nperhaps earlier when a scientist discovered",
        "start": 2248.23,
        "duration": 7.9
    },
    {
        "text": "how the eye works and that the image on the\nretina forms upside down.",
        "start": 2256.13,
        "duration": 5.54
    },
    {
        "text": "They were baffled by the fact that we see\nright-side up.",
        "start": 2261.67,
        "duration": 2.93
    },
    {
        "text": "How is it that we don't see upside down because\nthe image in the back of our eyes upside down?",
        "start": 2264.6,
        "duration": 4.22
    },
    {
        "text": "It was a big mystery.",
        "start": 2268.82,
        "duration": 1.0
    },
    {
        "text": "Now that we know what information processing\nis all about, we think this question makes",
        "start": 2269.82,
        "duration": 4.15
    },
    {
        "text": "absolutely no sense.",
        "start": 2273.97,
        "duration": 1.82
    },
    {
        "text": "The whole statement makes no sense.",
        "start": 2275.79,
        "duration": 1.64
    },
    {
        "text": "I think there are things about consciousness\nof that nature that we're not asking the right",
        "start": 2277.43,
        "duration": 3.659
    },
    {
        "text": "question, but there's a lot of contrarian\nopinions on this that I'd be happy to take",
        "start": 2281.089,
        "duration": 6.291
    },
    {
        "text": "at any moment not totally seriously because\nI don't completely believe in them.",
        "start": 2287.38,
        "duration": 4.87
    },
    {
        "text": "The fact, for example, that consciousness\nis an epi-phenomenon of being intelligent.",
        "start": 2292.25,
        "duration": 4.77
    },
    {
        "text": "So, any intelligent entity will have to be\nconscious because they will have to have some",
        "start": 2297.02,
        "duration": 4.53
    },
    {
        "text": "sort of model of itself.",
        "start": 2301.55,
        "duration": 1.36
    },
    {
        "text": "That's, according to some definition, that\nsatisfies consciousness.",
        "start": 2302.91,
        "duration": 5.23
    },
    {
        "text": "There's another one that I like which I connect\nwith, maybe other people connect with it as",
        "start": 2308.14,
        "duration": 5.969
    },
    {
        "text": "well, which is consciousness is actually a\nconsequence of our brains being very limited.",
        "start": 2314.109,
        "duration": 5.461
    },
    {
        "text": "We can only focus our attention on one thing\nat a time and therefore ... That's because",
        "start": 2319.57,
        "duration": 4.31
    },
    {
        "text": "our brain is limited hardware.",
        "start": 2323.88,
        "duration": 1.679
    },
    {
        "text": "We have our prefrontal cortex that has to\nfocus on one task or one particular situation",
        "start": 2325.559,
        "duration": 5.53
    },
    {
        "text": "and cannot do multiple things at the same\ntime.",
        "start": 2331.089,
        "duration": 2.111
    },
    {
        "text": "We have to have a process in our brain that\ndecides what to pay attention to and how to",
        "start": 2333.2,
        "duration": 4.84
    },
    {
        "text": "configure our prefrontal cortex to solve the\nproblem at hand.",
        "start": 2338.04,
        "duration": 4.98
    },
    {
        "text": "We interpret this as consciousness, but it's\njust the consequence of the fact that our",
        "start": 2343.02,
        "duration": 3.23
    },
    {
        "text": "brain is so small, that if our brain was ten\ntimes the size, then we could do ten things",
        "start": 2346.25,
        "duration": 4.64
    },
    {
        "text": "at the same time and maybe we wouldn't have\nthe same experience of consciousness.",
        "start": 2350.89,
        "duration": 3.89
    },
    {
        "text": "Maybe we will have ten simultaneous consciousnesses.",
        "start": 2354.78,
        "duration": 1.52
    },
    {
        "text": "Is there a plural for consciousness?",
        "start": 2356.3,
        "duration": 3.41
    },
    {
        "text": "Is it consciousnesses?",
        "start": 2359.71,
        "duration": 1.0
    },
    {
        "text": "Consciousnesses.",
        "start": 2360.71,
        "duration": 1.0
    },
    {
        "text": "Let's go with that.",
        "start": 2361.71,
        "duration": 1.0
    },
    {
        "text": "Okay.",
        "start": 2362.71,
        "duration": 1.0
    },
    {
        "text": "It's not a collective word, is it?",
        "start": 2363.71,
        "duration": 2.24
    },
    {
        "text": "Yeah.",
        "start": 2365.95,
        "duration": 1.79
    },
    {
        "text": "I thought-",
        "start": 2367.74,
        "duration": 1.0
    },
    {
        "text": "I think we just don't know enough really to\nask these kinds of questions.",
        "start": 2368.74,
        "duration": 3.9
    },
    {
        "text": "Let's start with Peter and then we'll go to\nSusan.",
        "start": 2372.64,
        "duration": 3.36
    },
    {
        "text": "All right, so bringing it back a little bit\nto the question of artificial intelligence,",
        "start": 2376.0,
        "duration": 4.39
    },
    {
        "text": "I think that why did consciousness evolve?",
        "start": 2380.39,
        "duration": 4.62
    },
    {
        "text": "Well, it's for something.",
        "start": 2385.01,
        "duration": 1.0
    },
    {
        "text": "It's for the frontal areas to be able to plan.",
        "start": 2386.01,
        "duration": 3.04
    },
    {
        "text": "You want to get the best representation of\nthe world that you can.",
        "start": 2389.05,
        "duration": 3.06
    },
    {
        "text": "Now, in order to do that you need to take\nincredibly ambiguous visual input and recover",
        "start": 2392.11,
        "duration": 6.05
    },
    {
        "text": "a disambiguated representation of the world\nso the areas can plan appropriately.",
        "start": 2398.16,
        "duration": 6.6
    },
    {
        "text": "Let's say I have a white-haired cat.",
        "start": 2404.76,
        "duration": 2.26
    },
    {
        "text": "It looks white to me because I want to recover\nwhat's intrinsically true about the cat, namely",
        "start": 2407.02,
        "duration": 2.631
    },
    {
        "text": "that it's a white-haired cat.",
        "start": 2409.651,
        "duration": 2.959
    },
    {
        "text": "Now it runs under a shadow or a blue light.",
        "start": 2412.61,
        "duration": 2.36
    },
    {
        "text": "Well, the light actually reflecting off of\nthe white hair is now blue, what's hitting",
        "start": 2414.97,
        "duration": 3.41
    },
    {
        "text": "my retina, but I want to discount that and\nrecover what's still intrinsically true, so",
        "start": 2418.38,
        "duration": 3.89
    },
    {
        "text": "I see it as a white cat that happens to be\nunder a blue light.",
        "start": 2422.27,
        "duration": 4.069
    },
    {
        "text": "I want to recover it's intrinsically true\nshape and size and distance and so forth.",
        "start": 2426.339,
        "duration": 4.411
    },
    {
        "text": "It's the best representation of what's intrinsically\nthe case.",
        "start": 2430.75,
        "duration": 3.03
    },
    {
        "text": "Again, what got built into this quasi-hallucination\nis, in addition to that kind of story about",
        "start": 2433.78,
        "duration": 6.569
    },
    {
        "text": "the physical world, stories like causation\nwhich is invisible.",
        "start": 2440.349,
        "duration": 4.75
    },
    {
        "text": "Go to any party, next time you're at a party,\nand have your confederate turn off the lights",
        "start": 2445.099,
        "duration": 5.761
    },
    {
        "text": "and you say, \"I can turn the lights off,\"\nand you go, boom.",
        "start": 2450.86,
        "duration": 3.44
    },
    {
        "text": "The person turns the lights off.",
        "start": 2454.3,
        "duration": 1.529
    },
    {
        "text": "Everyone's like, \"Wow, how did you do that?\"",
        "start": 2455.829,
        "duration": 1.951
    },
    {
        "text": "Because we are perceiving causation.",
        "start": 2457.78,
        "duration": 2.96
    },
    {
        "text": "We're also perceiving other minds.",
        "start": 2460.74,
        "duration": 1.619
    },
    {
        "text": "It's built into the construction.",
        "start": 2462.359,
        "duration": 2.541
    },
    {
        "text": "My guess is, that this is going to be very\ncentral to the creation ultimately of AGI",
        "start": 2464.9,
        "duration": 4.159
    },
    {
        "text": "or general intelligence 'cause it's so central\nto the creation of our models of the world.",
        "start": 2469.059,
        "duration": 4.911
    },
    {
        "text": "I understand what it's like for you to feel\npain because I feel pain or for you to have",
        "start": 2473.97,
        "duration": 4.619
    },
    {
        "text": "a broken heart because I once did.",
        "start": 2478.589,
        "duration": 2.27
    },
    {
        "text": "This is very central.",
        "start": 2480.859,
        "duration": 1.0
    },
    {
        "text": "I don't see how a system that has never felt\npain can understand what I mean when I'm talking",
        "start": 2481.859,
        "duration": 4.831
    },
    {
        "text": "about pain.",
        "start": 2486.69,
        "duration": 1.0
    },
    {
        "text": "Susan.",
        "start": 2487.69,
        "duration": 1.0
    },
    {
        "text": "That's interesting.",
        "start": 2488.69,
        "duration": 1.24
    },
    {
        "text": "I guess my general comment here, to go back\nto Yann's point about how attention is closely",
        "start": 2489.93,
        "duration": 7.77
    },
    {
        "text": "related to consciousness and we could have\ngot lucky because we have limited capacity.",
        "start": 2497.7,
        "duration": 6.5
    },
    {
        "text": "We can only entertain maybe seven variables\nin working memory at any given time, and we",
        "start": 2504.2,
        "duration": 5.08
    },
    {
        "text": "have trouble remembering phone numbers.",
        "start": 2509.28,
        "duration": 2.18
    },
    {
        "text": "Maybe consciousness is something we got that\nrelates to our limited capacity systems.",
        "start": 2511.46,
        "duration": 6.79
    },
    {
        "text": "Now, if that's true though, suppose we do\ncreate AGI and shortly thereafter we create",
        "start": 2518.25,
        "duration": 6.63
    },
    {
        "text": "intelligent synthetic beings that are smarter\nthan us in all sorts of ways, why think they're",
        "start": 2524.88,
        "duration": 5.729
    },
    {
        "text": "conscious?",
        "start": 2530.609,
        "duration": 1.0
    },
    {
        "text": "Just because they look like, say, Hanson Robotics\nSophia, they look human, does mean that they'll",
        "start": 2531.609,
        "duration": 5.381
    },
    {
        "text": "be conscious.",
        "start": 2536.99,
        "duration": 1.0
    },
    {
        "text": "Think about it.",
        "start": 2537.99,
        "duration": 1.0
    },
    {
        "text": "Do they need to have these limited capacity\nsystems?",
        "start": 2538.99,
        "duration": 2.78
    },
    {
        "text": "For example, a superintelligence could be\nas large as an entire planet.",
        "start": 2541.77,
        "duration": 5.5
    },
    {
        "text": "Its computronium, its computational resources\ncould span the entire internet.",
        "start": 2547.27,
        "duration": 5.25
    },
    {
        "text": "What would be novel to it requiring slow,\ndeliberative focus?",
        "start": 2552.52,
        "duration": 3.54
    },
    {
        "text": "Why would it be like us in any kind of meaningful\nsense?",
        "start": 2556.06,
        "duration": 6.33
    },
    {
        "text": "What I want to suggest is that we pull apart\nintelligence and consciousness and treat it",
        "start": 2562.39,
        "duration": 6.0
    },
    {
        "text": "as an empirical matter.",
        "start": 2568.39,
        "duration": 1.41
    },
    {
        "text": "If we want to figure out machine consciousness,\nwe need to ask for each type of AI architecture",
        "start": 2569.8,
        "duration": 6.43
    },
    {
        "text": "whether that type of system has conscious\nexperience and not just assume that because",
        "start": 2576.23,
        "duration": 4.829
    },
    {
        "text": "it looks human it feels something.",
        "start": 2581.059,
        "duration": 1.99
    },
    {
        "text": "Yeah, I want to applaud you there for distinguishing\nit's an artificial intelligence and artificial",
        "start": 2583.049,
        "duration": 6.401
    },
    {
        "text": "consciousness, which are way too often conflated\nwith each other.",
        "start": 2589.45,
        "duration": 3.0
    },
    {
        "text": "I think many people, for example, will say\nthings like, \"Oh, we're so scared that machines",
        "start": 2592.45,
        "duration": 6.01
    },
    {
        "text": "are going to become conscious and then suddenly\nthey're going to turn on us and be evil like",
        "start": 2598.46,
        "duration": 3.47
    },
    {
        "text": "in bad Hollywood movies.\"",
        "start": 2601.93,
        "duration": 1.179
    },
    {
        "text": "Somehow, it's the consciousness that you should\nworry about.",
        "start": 2603.109,
        "duration": 3.081
    },
    {
        "text": "That, I think, is a total red herring.",
        "start": 2606.19,
        "duration": 2.35
    },
    {
        "text": "Although I agree that consciousness is super\nimportant from a moral and ethical point of",
        "start": 2608.54,
        "duration": 4.44
    },
    {
        "text": "view-",
        "start": 2612.98,
        "duration": 1.0
    },
    {
        "text": "Yeah, of course.",
        "start": 2613.98,
        "duration": 1.0
    },
    {
        "text": "... in terms of whether you should worry or\nnot, you don't care about whether that heat-seeking",
        "start": 2614.98,
        "duration": 2.7
    },
    {
        "text": "missile chasing after you is conscious or\nnot or how it feels about this.",
        "start": 2617.68,
        "duration": 5.42
    },
    {
        "text": "You only care about what it does and it's\nperfectly possible for us to get in trouble",
        "start": 2623.1,
        "duration": 5.53
    },
    {
        "text": "with some incredibly intelligent machine even\nif it's not having any subjective experience.",
        "start": 2628.63,
        "duration": 7.75
    },
    {
        "text": "In other words, consciousness isn't something\nwe should worry about.",
        "start": 2636.38,
        "duration": 3.729
    },
    {
        "text": "That's not going to make any particular difference\nfrom that perspective, but I think it makes",
        "start": 2640.109,
        "duration": 8.23
    },
    {
        "text": "enormous moral difference.",
        "start": 2648.339,
        "duration": 1.851
    },
    {
        "text": "When I have colleagues who tell me that they\nthink we shouldn't talk about consciousness",
        "start": 2650.19,
        "duration": 4.55
    },
    {
        "text": "because it's just philosophical B.S., I ask\nthem to explain to me how you can have any",
        "start": 2654.74,
        "duration": 5.309
    },
    {
        "text": "morality if you refuse to talk about consciousness\nand subjective experience.",
        "start": 2660.049,
        "duration": 5.641
    },
    {
        "text": "What's wrong with torture if it's just, oh,\nthe elementary particles were moving around",
        "start": 2665.69,
        "duration": 3.929
    },
    {
        "text": "this way rather than that way?",
        "start": 2669.619,
        "duration": 2.45
    },
    {
        "text": "It's all about the negativity of the subjective\nexperience that's at hand.",
        "start": 2672.069,
        "duration": 4.661
    },
    {
        "text": "If we want to be moral people, we want to\ncreate a lot of positive experiences in the",
        "start": 2676.73,
        "duration": 4.01
    },
    {
        "text": "future, not just a bunch of zombies.",
        "start": 2680.74,
        "duration": 4.03
    },
    {
        "text": "This is a Nick Bostrom example.",
        "start": 2684.77,
        "duration": 1.4
    },
    {
        "text": "If there's a trillion simulations you're running\njust to test something of a general intelligent",
        "start": 2686.17,
        "duration": 4.51
    },
    {
        "text": "trillion, then you're like, \"Okay, I got what\nI needed.",
        "start": 2690.68,
        "duration": 2.05
    },
    {
        "text": "The inflows, let's shut them all off.\"",
        "start": 2692.73,
        "duration": 1.72
    },
    {
        "text": "If they're not conscious, it's like closing\nyour laptop.",
        "start": 2694.45,
        "duration": 1.889
    },
    {
        "text": "There's nothing wrong with that.",
        "start": 2696.339,
        "duration": 1.151
    },
    {
        "text": "If those things are conscious, you just created\nthe biggest genocide in the history of the",
        "start": 2697.49,
        "duration": 4.319
    },
    {
        "text": "human species.",
        "start": 2701.809,
        "duration": 1.0
    },
    {
        "text": "It's pretty relevant.",
        "start": 2702.809,
        "duration": 1.0
    },
    {
        "text": "It matters.",
        "start": 2703.809,
        "duration": 1.0
    },
    {
        "text": "Not if you have a backup.",
        "start": 2704.809,
        "duration": 1.5
    },
    {
        "text": "The reason why we care about each other is\nbecause we have a lot invested in each other.",
        "start": 2706.309,
        "duration": 4.141
    },
    {
        "text": "There is value to every human particularly\nthrough other humans who are close to that",
        "start": 2710.45,
        "duration": 5.12
    },
    {
        "text": "person It's possible that we'll have the same\nrelationship with our household robot that",
        "start": 2715.57,
        "duration": 8.269
    },
    {
        "text": "we trained.",
        "start": 2723.839,
        "duration": 1.171
    },
    {
        "text": "We have a lot invested in that household robot,\nthe same that we have invested in our cat",
        "start": 2725.01,
        "duration": 5.76
    },
    {
        "text": "or dogs.",
        "start": 2730.77,
        "duration": 3.319
    },
    {
        "text": "We won't want that robot to get destroyed\nbecause all of the time we invested in that",
        "start": 2734.089,
        "duration": 5.051
    },
    {
        "text": "robot will go away.",
        "start": 2739.14,
        "duration": 1.34
    },
    {
        "text": "But, if we have a backup, it's okay to smash\nit against the wall.",
        "start": 2740.48,
        "duration": 6.46
    },
    {
        "text": "If you have an identical twin, can I just\nthrow you into the sewer?",
        "start": 2746.94,
        "duration": 2.82
    },
    {
        "text": "No, there is all kinds of interesting questions\nlike this of imagine we invent ... We have",
        "start": 2749.76,
        "duration": 8.23
    },
    {
        "text": "a physicist here.",
        "start": 2757.99,
        "duration": 1.27
    },
    {
        "text": "We invent a Star Trek style transporter.",
        "start": 2759.26,
        "duration": 4.49
    },
    {
        "text": "You get dematerialized.",
        "start": 2763.75,
        "duration": 1.069
    },
    {
        "text": "You get destroyed.",
        "start": 2764.819,
        "duration": 1.0
    },
    {
        "text": "You get killed and you get reconstructed at\nthe other end.",
        "start": 2765.819,
        "duration": 4.471
    },
    {
        "text": "You experience death.",
        "start": 2770.29,
        "duration": 2.65
    },
    {
        "text": "This is a metaphor really for what is it that\nwe're upset at when someone gets killed or",
        "start": 2772.94,
        "duration": 8.81
    },
    {
        "text": "when an intelligent machine with its conscious\ngets destroyed?",
        "start": 2781.75,
        "duration": 4.76
    },
    {
        "text": "As long as there's no pain involved, which\nthere isn't when you go to anesthesia.",
        "start": 2786.51,
        "duration": 5.339
    },
    {
        "text": "As long as you have a backup or you can get\nrevived, there is no-",
        "start": 2791.849,
        "duration": 4.601
    },
    {
        "text": "But, if there's suffering-",
        "start": 2796.45,
        "duration": 1.0
    },
    {
        "text": "... no information loss.",
        "start": 2797.45,
        "duration": 1.0
    },
    {
        "text": "If there's suffering then that's a different\nthing.",
        "start": 2798.45,
        "duration": 2.18
    },
    {
        "text": "Yep.",
        "start": 2800.63,
        "duration": 1.0
    },
    {
        "text": "That's right.",
        "start": 2801.63,
        "duration": 1.0
    },
    {
        "text": "Then, consciousness does ...",
        "start": 2802.63,
        "duration": 1.0
    },
    {
        "text": "Okay, so now I ask the question, can machines\nhave emotions?",
        "start": 2803.63,
        "duration": 2.14
    },
    {
        "text": "You see, again, Star Trek Commander Data has\nthis chip they can turn on or off to have",
        "start": 2805.77,
        "duration": 6.72
    },
    {
        "text": "emotions or not 'cause somehow you have intelligent\nmachines that don't have emotions.",
        "start": 2812.49,
        "duration": 5.19
    },
    {
        "text": "I don't personally believe that it is possible\nto design or build autonomous intelligent",
        "start": 2817.68,
        "duration": 6.389
    },
    {
        "text": "machines without them having emotions.",
        "start": 2824.069,
        "duration": 2.391
    },
    {
        "text": "Emotion is part of intelligence.",
        "start": 2826.46,
        "duration": 1.909
    },
    {
        "text": "Now, we're going to have self-driving cars\nthat are not going to have much emotions,",
        "start": 2828.369,
        "duration": 4.311
    },
    {
        "text": "but it's because they're not going to be,\neven though we call them autonomous cars,",
        "start": 2832.68,
        "duration": 3.07
    },
    {
        "text": "they're not going to be autonomous intelligence.",
        "start": 2835.75,
        "duration": 1.52
    },
    {
        "text": "They're just designed to drive your car.",
        "start": 2837.27,
        "duration": 1.36
    },
    {
        "text": "If you're talking about autonomous intelligence,\nthen these are machines that can decide what",
        "start": 2838.63,
        "duration": 7.199
    },
    {
        "text": "they do.",
        "start": 2845.829,
        "duration": 1.0
    },
    {
        "text": "They have some intrinsic drive that makes\nthem wake up every morning or do particular",
        "start": 2846.829,
        "duration": 7.331
    },
    {
        "text": "things, justify their lives maybe, but no\npre-programmed behavior really.",
        "start": 2854.16,
        "duration": 10.27
    },
    {
        "text": "You can't have a machine like this without\nemotions.",
        "start": 2864.43,
        "duration": 2.25
    },
    {
        "text": "]",
        "start": 2866.68,
        "duration": 1.0
    },
    {
        "text": "Peter.",
        "start": 2867.68,
        "duration": 1.0
    },
    {
        "text": "Yeah, so I think it's a very interesting point\nthat emotions are going to prove central to",
        "start": 2868.68,
        "duration": 2.88
    },
    {
        "text": "the generation of artificial general intelligence.",
        "start": 2871.56,
        "duration": 3.18
    },
    {
        "text": "If you look at the evolution of animals, we\ncan learn something, I think, about the origin",
        "start": 2874.74,
        "duration": 5.15
    },
    {
        "text": "of the emotions and the desires because they\nare conscious states but they're teleological",
        "start": 2879.89,
        "duration": 5.74
    },
    {
        "text": "states within consciousness and they're often\nabout what's not visible.",
        "start": 2885.63,
        "duration": 4.92
    },
    {
        "text": "How would this get started?",
        "start": 2890.55,
        "duration": 1.0
    },
    {
        "text": "Well, you could imagine a fish that only responded\nto something it could see.",
        "start": 2891.55,
        "duration": 4.83
    },
    {
        "text": "It's stimulus present, it does this.",
        "start": 2896.38,
        "duration": 1.739
    },
    {
        "text": "If it sees a barracuda, it flees.Then, imagine\na new revolutionary fish that has a working",
        "start": 2898.119,
        "duration": 5.871
    },
    {
        "text": "memory.",
        "start": 2903.99,
        "duration": 1.0
    },
    {
        "text": "Now, when the barracuda peers behind a piece\nof coral, that fish can say, \"A-ha!",
        "start": 2904.99,
        "duration": 3.71
    },
    {
        "text": "I know it's going that way.",
        "start": 2908.7,
        "duration": 2.23
    },
    {
        "text": "I'm going to go that way.\"",
        "start": 2910.93,
        "duration": 1.399
    },
    {
        "text": "The representation of the invisible became,\nI think, very central.",
        "start": 2912.329,
        "duration": 2.211
    },
    {
        "text": "The need for working memory is very central,\nwhich is lacking in present architectures.",
        "start": 2914.54,
        "duration": 4.15
    },
    {
        "text": "Then, these teleological states that force\nus to seek mates and food and so forth and",
        "start": 2918.69,
        "duration": 7.389
    },
    {
        "text": "really having these teleological states, these\nemotions and desires, allowed us to form,",
        "start": 2926.079,
        "duration": 6.52
    },
    {
        "text": "not garden paths, but desert paths.",
        "start": 2932.599,
        "duration": 1.49
    },
    {
        "text": "A garden path is when you know locally this\nis best, locally this is best, locally this",
        "start": 2934.089,
        "duration": 4.46
    },
    {
        "text": "is best and then you end up in the jaws of\na lion.",
        "start": 2938.549,
        "duration": 2.351
    },
    {
        "text": "A desert path would be well locally I have\nto go without, I go without, I go without,",
        "start": 2940.9,
        "duration": 3.149
    },
    {
        "text": "but at the end of it, I might have a mate\nor food or shelter.",
        "start": 2944.049,
        "duration": 3.75
    },
    {
        "text": "This is a big revolution that afforded us\nthe ability to act in the world in the absence",
        "start": 2947.799,
        "duration": 4.681
    },
    {
        "text": "of input.",
        "start": 2952.48,
        "duration": 2.55
    },
    {
        "text": "Central to that also is the formation of mental\nmodels and cognitive maps of the whole landscape,",
        "start": 2955.03,
        "duration": 5.309
    },
    {
        "text": "physical and emotional as well as social.",
        "start": 2960.339,
        "duration": 2.48
    },
    {
        "text": "Actually, one of the big progress, a very\ninteresting development in deep learning over",
        "start": 2962.819,
        "duration": 4.3
    },
    {
        "text": "the last years, is deep learning systems that\nhave a working memory, neural networks, neural",
        "start": 2967.119,
        "duration": 5.621
    },
    {
        "text": "Turing machines, things like that.",
        "start": 2972.74,
        "duration": 2.43
    },
    {
        "text": "Those are models that actually have a separate\nmodule for competition and another one for",
        "start": 2975.17,
        "duration": 5.899
    },
    {
        "text": "storing memory, short-term memory.",
        "start": 2981.069,
        "duration": 3.141
    },
    {
        "text": "Similar to we actually have a particular module\nin our brains called the hippocampus which",
        "start": 2984.21,
        "duration": 6.34
    },
    {
        "text": "sort of plays that role more or less of storing\nshort-term memory.",
        "start": 2990.55,
        "duration": 3.71
    },
    {
        "text": "I think a very interesting place to look for\nlessons about how to build artificial intelligence",
        "start": 2994.26,
        "duration": 4.37
    },
    {
        "text": "systems will be not computers, but evolution's\nother experiments.",
        "start": 2998.63,
        "duration": 4.13
    },
    {
        "text": "I think the most interesting one is the octopus\nbecause complex brains evolved in three lineages,",
        "start": 3002.76,
        "duration": 5.99
    },
    {
        "text": "the chordates, and we're sort of the culmination\nof that 'cause were like chimps plus symbolic",
        "start": 3008.75,
        "duration": 4.51
    },
    {
        "text": "processing plus syntax.",
        "start": 3013.26,
        "duration": 1.5
    },
    {
        "text": "Then, some arthropods like praying mantises,\nbut honeybees, they have a couple hundred-thousand",
        "start": 3014.76,
        "duration": 4.34
    },
    {
        "text": "neurons.",
        "start": 3019.1,
        "duration": 1.0
    },
    {
        "text": "The octopus has 500 million, comparable to\na bear or a dog.",
        "start": 3020.1,
        "duration": 7.63
    },
    {
        "text": "If we want to understand computational principles\nthat might be universal, we should look at",
        "start": 3027.73,
        "duration": 4.9
    },
    {
        "text": "this animal because there might be only so\nmany ways to build a brain.",
        "start": 3032.63,
        "duration": 3.709
    },
    {
        "text": "Convergent evolution found that there's only\nso many ways to build a wing.",
        "start": 3036.339,
        "duration": 2.26
    },
    {
        "text": "You need some sort of membrane.",
        "start": 3038.599,
        "duration": 2.572
    },
    {
        "text": "In the chordates, the bats did this and the\nbirds did this and the pterodactyls did this,",
        "start": 3041.171,
        "duration": 5.009
    },
    {
        "text": "but they all have in common flapping and membranes.",
        "start": 3046.18,
        "duration": 1.95
    },
    {
        "text": "There's only so many ways to build a wing.",
        "start": 3048.13,
        "duration": 1.87
    },
    {
        "text": "There might be only so many ways to build\na brain.",
        "start": 3050.0,
        "duration": 2.47
    },
    {
        "text": "Some people have argued, for example, that\nthe vertical lobe of the octopus brain is",
        "start": 3052.47,
        "duration": 4.04
    },
    {
        "text": "completely or very analogous to our hippocampus\nwith very similar circuitry.",
        "start": 3056.51,
        "duration": 3.89
    },
    {
        "text": "Well, convergent evolution has brought us\nthere 'cause our common ancestors probably",
        "start": 3060.4,
        "duration": 3.56
    },
    {
        "text": "Precambrian.",
        "start": 3063.96,
        "duration": 1.0
    },
    {
        "text": "It was probably a little flatworm way, way\nback in the ancient, warm seas.",
        "start": 3064.96,
        "duration": 4.93
    },
    {
        "text": "That's really interesting because to go back\nto this idea of superintelligence, one wonders",
        "start": 3069.89,
        "duration": 5.22
    },
    {
        "text": "if we could discover through thinking of both\nAI and intriguing systems that nature gives",
        "start": 3075.11,
        "duration": 6.179
    },
    {
        "text": "us like the octopus if there are universal\nproperties of intelligence and, in so doing,",
        "start": 3081.289,
        "duration": 4.82
    },
    {
        "text": "anticipate the shape of superintelligence.",
        "start": 3086.109,
        "duration": 2.781
    },
    {
        "text": "Because after this panel, I have to confess,\nI'm actually a little bit more worried about",
        "start": 3088.89,
        "duration": 1.0
    },
    {
        "text": "super intelligence\n.",
        "start": 3089.89,
        "duration": 1.0
    },
    {
        "text": "Our basic behaviors, as humans, are driven\nby our basal ganglia basically.",
        "start": 3090.89,
        "duration": 4.469
    },
    {
        "text": "The base of our brain, that's where human\nnature is hardwired.",
        "start": 3095.359,
        "duration": 4.451
    },
    {
        "text": "That's what drives a lot of our basic behaviors.",
        "start": 3099.81,
        "duration": 3.39
    },
    {
        "text": "Then our brain on top of this makes our behavior\nserve those drives with intelligent, hopefully",
        "start": 3103.2,
        "duration": 10.45
    },
    {
        "text": "intelligent, actions, but our basic drives\nare driven by this hardwired basal ganglia.",
        "start": 3113.65,
        "duration": 9.58
    },
    {
        "text": "That's what computes whether we are happy\nor not, whether what we do is going to make",
        "start": 3123.23,
        "duration": 3.82
    },
    {
        "text": "us happy or not.",
        "start": 3127.05,
        "duration": 1.28
    },
    {
        "text": "It drives all of our behavior.",
        "start": 3128.33,
        "duration": 1.47
    },
    {
        "text": "We need this for intelligent machines.",
        "start": 3129.8,
        "duration": 1.539
    },
    {
        "text": "The fact that an intelligent machine will\nbe autonomous will mean that it will have",
        "start": 3131.339,
        "duration": 4.391
    },
    {
        "text": "to have this kind of hardwired piece in its\nbrain that drives its behavior.",
        "start": 3135.73,
        "duration": 6.04
    },
    {
        "text": "The big question is, how do you build it in\nsuch a way that those basic drives are aligned",
        "start": 3141.77,
        "duration": 6.269
    },
    {
        "text": "with human values?",
        "start": 3148.039,
        "duration": 1.861
    },
    {
        "text": "It's going to be probably very difficult to\nhardwire this by hand.",
        "start": 3149.9,
        "duration": 3.889
    },
    {
        "text": "We're going to be able to hardwire some very\nbasic behavior to make sure that robots are",
        "start": 3153.789,
        "duration": 5.031
    },
    {
        "text": "safe.",
        "start": 3158.82,
        "duration": 1.0
    },
    {
        "text": "For example, if you have a knife in your hand,\ndon't flail it around if there are humans",
        "start": 3159.82,
        "duration": 3.21
    },
    {
        "text": "around, sort of very basic things like this.",
        "start": 3163.03,
        "duration": 2.5
    },
    {
        "text": "There's probably thousands of rules like this\nthat we can't really implement really easily.",
        "start": 3165.53,
        "duration": 4.69
    },
    {
        "text": "What we're going to have to do is train those\nmachines to, again, distinguish good from",
        "start": 3170.22,
        "duration": 6.839
    },
    {
        "text": "evil, behave in society and not injure people.",
        "start": 3177.059,
        "duration": 5.591
    },
    {
        "text": "Yeah, I hear people say it's the artificial\nsuperintelligence, which is kind of general",
        "start": 3182.65,
        "duration": 6.9
    },
    {
        "text": "intelligence once it's way better than we\nare.",
        "start": 3189.55,
        "duration": 2.25
    },
    {
        "text": "It's the last invention we'll ever make because\nif it's doing what we want, then all the things",
        "start": 3191.8,
        "duration": 6.7
    },
    {
        "text": "that we think are hard ... It's like a monkey\nhitting a padlock forever and a human walks",
        "start": 3198.5,
        "duration": 4.63
    },
    {
        "text": "in and they look at the instructions and in\njust one second open it.",
        "start": 3203.13,
        "duration": 3.16
    },
    {
        "text": "That all these things, poverty, climate change,\ndisease, even morality, child's play to something",
        "start": 3206.29,
        "duration": 6.84
    },
    {
        "text": "that is that level of intelligent.",
        "start": 3213.13,
        "duration": 2.36
    },
    {
        "text": "It's this utopia that we could be in if we\ncould pull it off.",
        "start": 3215.49,
        "duration": 3.94
    },
    {
        "text": "So, you wouldn't have to invent anything in\nthat world because it invents everything for",
        "start": 3219.43,
        "duration": 4.46
    },
    {
        "text": "you.",
        "start": 3223.89,
        "duration": 1.0
    },
    {
        "text": "The other scenario is that it's ... I don't\nhear a lot of experts talking about Terminator,",
        "start": 3224.89,
        "duration": 5.36
    },
    {
        "text": "evil robots, that's anthropomorphizing..",
        "start": 3230.25,
        "duration": 2.43
    },
    {
        "text": "It's the last invention we'll ever face then\n'cause extinct species don't invent things.",
        "start": 3232.68,
        "duration": 4.34
    },
    {
        "text": "The stakes are monumentally high and this\nis what you just kind of touched on",
        "start": 3237.02,
        "duration": 4.03
    },
    {
        "text": "We only have a few minutes left.",
        "start": 3241.05,
        "duration": 1.289
    },
    {
        "text": "I really want to hear what you guys have to\nsay about ... I feel like we woke up in the",
        "start": 3242.339,
        "duration": 3.831
    },
    {
        "text": "middle of a thriller movie in the climax of\nthis thriller movie, but it's just moving",
        "start": 3246.17,
        "duration": 3.649
    },
    {
        "text": "slowly in our minds so we don't see that what's\nhappening, but it's the choose-your-own-adventure,",
        "start": 3249.819,
        "duration": 4.721
    },
    {
        "text": "choose-your-own-ending.",
        "start": 3254.54,
        "duration": 1.88
    },
    {
        "text": "How can we nudge this in the right direction?",
        "start": 3256.42,
        "duration": 2.1
    },
    {
        "text": "Yeah.",
        "start": 3258.52,
        "duration": 1.0
    },
    {
        "text": "If you're taking a big step back and looking\nat it after 13.8 billion years of cosmic history,",
        "start": 3259.52,
        "duration": 7.0
    },
    {
        "text": "here we are, we figured out how to replace\nmost of our muscle work by machines.",
        "start": 3266.52,
        "duration": 3.68
    },
    {
        "text": "That was the industrial revolution.",
        "start": 3270.2,
        "duration": 1.419
    },
    {
        "text": "Now, we're figuring out how to replace our\nmental work by machines.",
        "start": 3271.619,
        "duration": 3.571
    },
    {
        "text": "Eventually, that's going to be AGI superintelligence.",
        "start": 3275.19,
        "duration": 1.33
    },
    {
        "text": "So, how can we make it good?",
        "start": 3276.52,
        "duration": 2.21
    },
    {
        "text": "I think Yann mentioned that the key challenge\nthere about making sure that its goals are",
        "start": 3278.73,
        "duration": 5.65
    },
    {
        "text": "aligned with ours, it doesn't have to be a\nbad news being surrounded by more intelligent",
        "start": 3284.38,
        "duration": 4.12
    },
    {
        "text": "entities because we all did that when we were\ntwo years old, mommy and daddy.",
        "start": 3288.5,
        "duration": 5.16
    },
    {
        "text": "It worked out for us because their goals were\naligned with ours.",
        "start": 3293.66,
        "duration": 4.18
    },
    {
        "text": "How can we ensure that this will happen with\nAGI?",
        "start": 3297.84,
        "duration": 3.37
    },
    {
        "text": "Well, AI safety research is the answer.",
        "start": 3301.21,
        "duration": 3.409
    },
    {
        "text": "We're investing billions of dollars now into\nmaking AI more powerful, but we also have",
        "start": 3304.619,
        "duration": 6.131
    },
    {
        "text": "to invest money in developing the wisdom needed\nto keep this AI beneficial.",
        "start": 3310.75,
        "duration": 5.89
    },
    {
        "text": "For example, applicable to what you said,\nYann, I think we have to figure out how to",
        "start": 3316.64,
        "duration": 3.439
    },
    {
        "text": "make machines understand our goals, adopt\nour goals, and retain our goals as they get",
        "start": 3320.079,
        "duration": 6.931
    },
    {
        "text": "smarter.",
        "start": 3327.01,
        "duration": 1.0
    },
    {
        "text": "All of those are really tough.",
        "start": 3328.01,
        "duration": 1.0
    },
    {
        "text": "If you tell your future self-driving Uber\nto take you to JFK as fast as possible and",
        "start": 3329.01,
        "duration": 4.53
    },
    {
        "text": "you get there covered in vomit and chased\nby helicopters, \"No, no, no, no.",
        "start": 3333.54,
        "duration": 4.63
    },
    {
        "text": "This isn't what I asked for.\"",
        "start": 3338.17,
        "duration": 2.369
    },
    {
        "text": "And, it goes, \"that's exactly what you asked\nfor.\"",
        "start": 3340.539,
        "duration": 3.641
    },
    {
        "text": "Then, you appreciate how hard it is to make\nmachines understand our real goal.",
        "start": 3344.18,
        "duration": 4.06
    },
    {
        "text": "Raise your hand if you have kids.",
        "start": 3348.24,
        "duration": 3.49
    },
    {
        "text": "Then, you know how big the difference is between\nhaving them understand your goals and actually",
        "start": 3351.73,
        "duration": 4.67
    },
    {
        "text": "adopting your goals, doing what you want.",
        "start": 3356.4,
        "duration": 1.92
    },
    {
        "text": "Also, who's the parent deciding what the goals\nare?",
        "start": 3358.32,
        "duration": 1.7
    },
    {
        "text": "Well, in this case-",
        "start": 3360.02,
        "duration": 1.0
    },
    {
        "text": "ISIS thinks it's doing good.",
        "start": 3361.02,
        "duration": 1.37
    },
    {
        "text": "It does\n.",
        "start": 3362.39,
        "duration": 1.16
    },
    {
        "text": "Yeah.",
        "start": 3363.55,
        "duration": 1.0
    },
    {
        "text": "We put a lot of effort into raising our kids.",
        "start": 3364.55,
        "duration": 1.63
    },
    {
        "text": "We need to put even more effort into raising\nhumanity's proverbial kids if we develop ever",
        "start": 3366.18,
        "duration": 4.609
    },
    {
        "text": "machines that are more powerful than us.",
        "start": 3370.789,
        "duration": 1.961
    },
    {
        "text": "I actually disagree with this.",
        "start": 3372.75,
        "duration": 1.53
    },
    {
        "text": "Well, okay.",
        "start": 3374.28,
        "duration": 1.0
    },
    {
        "text": "Let's go down the line here.",
        "start": 3375.28,
        "duration": 1.009
    },
    {
        "text": "Some of the changes that will have to happen\nwill not only be on the AI side but on the",
        "start": 3376.289,
        "duration": 4.591
    },
    {
        "text": "cultural side, the transformation of our cultures.",
        "start": 3380.88,
        "duration": 4.08
    },
    {
        "text": "For example, any technology can be used for\ngood or evil.",
        "start": 3384.96,
        "duration": 2.599
    },
    {
        "text": "A hammer can kill somebody or build a house.",
        "start": 3387.559,
        "duration": 1.581
    },
    {
        "text": "An airplane can transport people or bomb people.",
        "start": 3389.14,
        "duration": 2.64
    },
    {
        "text": "This is also true of AI, but the ethical systems\nthat we have inherited from the past are not",
        "start": 3391.78,
        "duration": 6.269
    },
    {
        "text": "sufficient to deal with this.",
        "start": 3398.049,
        "duration": 2.131
    },
    {
        "text": "2,000 years ago there was ten bad things you\ncan do and they said, \"Okay, God said don't",
        "start": 3400.18,
        "duration": 4.52
    },
    {
        "text": "sleep with his wife and don't steal his stuff,\"\nand so forth.",
        "start": 3404.7,
        "duration": 5.82
    },
    {
        "text": "Commandment number 853,211, thou shalt not\nimplant bioluminescent protein alleles from",
        "start": 3410.52,
        "duration": 7.2
    },
    {
        "text": "fireflies into tomato, no glow-in-the-dark\ntomatoes.",
        "start": 3417.72,
        "duration": 3.109
    },
    {
        "text": "Thou shalt not raise embryos for their dopaminergic\nneurons to implant into Parkinson's patients.",
        "start": 3420.829,
        "duration": 9.53
    },
    {
        "text": "Technology has driven ... There's now infinitely\nmany things that are bad, harmful so we need",
        "start": 3430.359,
        "duration": 6.75
    },
    {
        "text": "to come up with a new ethical framework for\nfiguring out the right course of action in",
        "start": 3437.109,
        "duration": 3.871
    },
    {
        "text": "these infinitely many cases.",
        "start": 3440.98,
        "duration": 1.91
    },
    {
        "text": "I would say a first step would be thinking\nof what is good is that which is fostering",
        "start": 3442.89,
        "duration": 4.679
    },
    {
        "text": "life and especially human life, but also life\nin general.",
        "start": 3447.569,
        "duration": 3.331
    },
    {
        "text": "That which is harmful to life is not good.",
        "start": 3450.9,
        "duration": 3.909
    },
    {
        "text": "That way we can confront lots of things and\ntry to think about not only what can we do,",
        "start": 3454.809,
        "duration": 5.03
    },
    {
        "text": "but what should we do.",
        "start": 3459.839,
        "duration": 2.551
    },
    {
        "text": "I think we're in a fortunate situation actually\nwhere pretty much everything you can do which",
        "start": 3462.39,
        "duration": 5.53
    },
    {
        "text": "will increase the chances of superintelligence\nor AGI going well, that kind of safety research,",
        "start": 3467.92,
        "duration": 6.659
    },
    {
        "text": "actually has its first baby step doing something\nwhich is already useful and the short-term",
        "start": 3474.579,
        "duration": 4.51
    },
    {
        "text": "like better cybersecurity research so we don't\nget hacked all the time, for example.",
        "start": 3479.089,
        "duration": 5.831
    },
    {
        "text": "Let's do those things better 'cause I think\nwe're actually pathetically flippant with",
        "start": 3484.92,
        "duration": 6.08
    },
    {
        "text": "things like that now and who's going to trust\nyour AGI if it can get hacked?",
        "start": 3491.0,
        "duration": 7.39
    },
    {
        "text": "We're going to get very non-powerful AGI before\nwe get very powerful AGIs.",
        "start": 3498.39,
        "duration": 4.85
    },
    {
        "text": "Our first AGI will have the autonomy and the\nintelligence level of a rat if that.",
        "start": 3503.24,
        "duration": 5.94
    },
    {
        "text": "Okay.",
        "start": 3509.18,
        "duration": 1.0
    },
    {
        "text": "I considered it a major success in my career\nif, by the end of my career, which is coming",
        "start": 3510.18,
        "duration": 4.659
    },
    {
        "text": "fast, we have a machine that has the same\nlevel of common sense as a rat or let's say",
        "start": 3514.839,
        "duration": 5.27
    },
    {
        "text": "a cat.",
        "start": 3520.109,
        "duration": 1.0
    },
    {
        "text": "The cat has 700 million neurons.",
        "start": 3521.109,
        "duration": 2.001
    },
    {
        "text": "We don't have the technology for this already.",
        "start": 3523.11,
        "duration": 2.259
    },
    {
        "text": "We don't have the science for it.",
        "start": 3525.369,
        "duration": 2.761
    },
    {
        "text": "Once we figure out the design of an intelligent,\nautonomous system, it will have the intelligence",
        "start": 3528.13,
        "duration": 3.929
    },
    {
        "text": "of a cat or a rat.",
        "start": 3532.059,
        "duration": 1.111
    },
    {
        "text": "It's not going to take over the world.",
        "start": 3533.17,
        "duration": 2.13
    },
    {
        "text": "With this, we can experiment to figure out\nhow do we build into it the fact that it should",
        "start": 3535.3,
        "duration": 6.85
    },
    {
        "text": "behave in society and not kill everything\naround it.",
        "start": 3542.15,
        "duration": 3.169
    },
    {
        "text": "Let me just point out that ...",
        "start": 3545.319,
        "duration": 2.72
    },
    {
        "text": "The thing that ...",
        "start": 3548.039,
        "duration": 1.77
    },
    {
        "text": "I'm sorry.",
        "start": 3549.809,
        "duration": 1.0
    },
    {
        "text": "Go ahead.",
        "start": 3550.809,
        "duration": 1.0
    },
    {
        "text": "Oh, no.",
        "start": 3551.809,
        "duration": 1.0
    },
    {
        "text": "Go ahead.",
        "start": 3552.809,
        "duration": 1.0
    },
    {
        "text": "Okay, thanks.",
        "start": 3553.809,
        "duration": 1.0
    },
    {
        "text": "Coming out of neuroscience, we just have really\nbasic fundamental questions that we don't",
        "start": 3554.809,
        "duration": 1.0
    },
    {
        "text": "know the answer to yet.",
        "start": 3555.809,
        "duration": 1.0
    },
    {
        "text": "Science says it's all about what we don't\nknow, so we should just put this on the table.",
        "start": 3556.809,
        "duration": 1.0
    },
    {
        "text": "One of these is what's the neural basis of\nconsciousness?",
        "start": 3557.809,
        "duration": 2.3
    },
    {
        "text": "Another is what is the neural code?",
        "start": 3560.109,
        "duration": 1.531
    },
    {
        "text": "The kind of neural networks that Yann has\ncreated are rooted in a kind of view of the",
        "start": 3561.64,
        "duration": 5.81
    },
    {
        "text": "neural code involving changing weights.",
        "start": 3567.45,
        "duration": 2.369
    },
    {
        "text": "In recent years, something people have thought,\n\"Okay, that's surely an important part of",
        "start": 3569.819,
        "duration": 3.891
    },
    {
        "text": "the puzzle, but maybe there's other parts\nof the puzzle.\"",
        "start": 3573.71,
        "duration": 3.109
    },
    {
        "text": "It's not simply about what's connected with\nwhat at what level of connectivity, and this",
        "start": 3576.819,
        "duration": 4.931
    },
    {
        "text": "is what underlies connectomics ... Rather\nthan viewing the brain as a highway system",
        "start": 3581.75,
        "duration": 5.71
    },
    {
        "text": "of different connections, it's more like a\ntrain track system where there's constant",
        "start": 3587.46,
        "duration": 3.77
    },
    {
        "text": "sudden switches.",
        "start": 3591.23,
        "duration": 2.079
    },
    {
        "text": "This piece of track can be part of an epi-connectivity\nbetween Boston and San Diego or an epi-connectivity",
        "start": 3593.309,
        "duration": 4.861
    },
    {
        "text": "between Boston and San Francisco depending\non these shuts.",
        "start": 3598.17,
        "duration": 4.35
    },
    {
        "text": "Maybe the neural code is actually a very dynamic\nneural code with these rapid synaptic weight",
        "start": 3602.52,
        "duration": 4.98
    },
    {
        "text": "changes.",
        "start": 3607.5,
        "duration": 1.0
    },
    {
        "text": "That's one direction.",
        "start": 3608.5,
        "duration": 1.549
    },
    {
        "text": "More recently, some people have argued, and\nif this turns out to be true, it will be revolutionary,",
        "start": 3610.049,
        "duration": 4.441
    },
    {
        "text": "that memories and information, in general,\nis not only stored in synaptic weights but",
        "start": 3614.49,
        "duration": 6.97
    },
    {
        "text": "actually inside the cell.",
        "start": 3621.46,
        "duration": 1.71
    },
    {
        "text": "There's some really incredible work done by\nTonegawa at MIT or, I think, David Glanzman",
        "start": 3623.17,
        "duration": 7.04
    },
    {
        "text": "at UCLA, that I think has convincingly shown\nthat synaptic weights might be the path to",
        "start": 3630.21,
        "duration": 5.28
    },
    {
        "text": "accessing the information, but the actual\ninformation might lie inside the cell.",
        "start": 3635.49,
        "duration": 4.589
    },
    {
        "text": "Glanzman says it's patterns of methylation\non DNA.",
        "start": 3640.079,
        "duration": 1.921
    },
    {
        "text": "Now, that's really radical.",
        "start": 3642.0,
        "duration": 1.0
    },
    {
        "text": "He's the only one saying that but if it's\ntrue, it will change everything.",
        "start": 3643.0,
        "duration": 4.089
    },
    {
        "text": "We have so far to go in understanding the\nbrain and present AI is based upon a metaphor",
        "start": 3647.089,
        "duration": 6.03
    },
    {
        "text": "of neural nets as understood in the brain\n10, 20 years ago, but it's changing very fast",
        "start": 3653.119,
        "duration": 5.881
    },
    {
        "text": "in real brain science.",
        "start": 3659.0,
        "duration": 2.579
    },
    {
        "text": "My guess is once we crack the neural code,\nit will be as momentous for our society as",
        "start": 3661.579,
        "duration": 4.96
    },
    {
        "text": "the cracking of the genetic code.",
        "start": 3666.539,
        "duration": 1.511
    },
    {
        "text": "All right, Susan.",
        "start": 3668.05,
        "duration": 1.0
    },
    {
        "text": "Very interesting.",
        "start": 3669.05,
        "duration": 1.0
    },
    {
        "text": "I want to hear it ... We have a couple minutes\nleft.",
        "start": 3670.05,
        "duration": 2.492
    },
    {
        "text": "Susan, how do we make it good in the future?",
        "start": 3672.542,
        "duration": 1.388
    },
    {
        "text": "Well, we could have an AI that becomes AGI\nand then rapidly evolves into superintelligence.",
        "start": 3673.93,
        "duration": 8.369
    },
    {
        "text": "Whether it be based on the neural code in\nthe brain or on something highly not brain-like,",
        "start": 3682.299,
        "duration": 5.941
    },
    {
        "text": "it could very quickly change its own architecture.",
        "start": 3688.24,
        "duration": 2.52
    },
    {
        "text": "Then, I wonder, how we'll be able to stay\nabreast of it.",
        "start": 3690.76,
        "duration": 4.87
    },
    {
        "text": "We have to hit the ground running on AI safety.",
        "start": 3695.63,
        "duration": 3.11
    },
    {
        "text": "I wholeheartedly agree with Max.",
        "start": 3698.74,
        "duration": 1.72
    },
    {
        "text": "I also wanted to add something which has not\nbeen discussed, which is, I think, as a society,",
        "start": 3700.46,
        "duration": 5.76
    },
    {
        "text": "we need to think about this idea of merging\nwith AI.",
        "start": 3706.22,
        "duration": 2.81
    },
    {
        "text": "Elon Musk has recently suggested that in order\nfor us to keep up with technological unemployment",
        "start": 3709.03,
        "duration": 6.66
    },
    {
        "text": "and to deal with the threat of super intelligence,\nwe, ourselves, need to bring AI into the brain.",
        "start": 3715.69,
        "duration": 8.21
    },
    {
        "text": "I think that as a culture, we need to start\ndiscussing that AI will not be a world that",
        "start": 3723.9,
        "duration": 5.919
    },
    {
        "text": "looks like the Jetsons where they're unenhanced\nhumans surrounded by all this fancy robotic",
        "start": 3729.819,
        "duration": 6.49
    },
    {
        "text": "equipment.",
        "start": 3736.309,
        "duration": 1.0
    },
    {
        "text": "The AI will change us as well.",
        "start": 3737.309,
        "duration": 2.881
    },
    {
        "text": "I just want to leave you with that thought.",
        "start": 3740.19,
        "duration": 2.139
    },
    {
        "text": "I like that thought.",
        "start": 3742.329,
        "duration": 3.451
    },
    {
        "text": "Thank you.",
        "start": 3745.78,
        "duration": 5.22
    },
    {
        "text": "Thank you.",
        "start": 3751.0,
        "duration": 5.21
    }
]