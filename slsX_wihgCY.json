[
    {
        "text": "Facebook is an idealistic and optimistic company.",
        "start": 9.98,
        "duration": 3.88
    },
    {
        "text": "For most of our existence, we focused on all\nthe good that connecting people can do.",
        "start": 13.86,
        "duration": 5.23
    },
    {
        "text": "Mr. Zuckerberg, what is Facebook doing to\nprevent foreign actors from interfering in",
        "start": 19.09,
        "duration": 7.08
    },
    {
        "text": "US elections?",
        "start": 26.17,
        "duration": 1.55
    },
    {
        "text": "If you've messaged anybody this week, would\nyou share with us the names of the people",
        "start": 27.72,
        "duration": 5.589
    },
    {
        "text": "you've messaged?",
        "start": 33.309,
        "duration": 1.031
    },
    {
        "text": "Senator, no, I would probably not choose to\ndo that publicly here.",
        "start": 34.34,
        "duration": 4.17
    },
    {
        "text": "I think that might be what this is all about.",
        "start": 38.51,
        "duration": 3.39
    },
    {
        "text": "Do you believe you're more responsible with\nmillions of Americans' personal data than",
        "start": 41.9,
        "duration": 3.47
    },
    {
        "text": "the Federal Government would be?",
        "start": 45.37,
        "duration": 16.55
    },
    {
        "text": "The early internet is a really interesting\nand fascinating to study.",
        "start": 61.92,
        "duration": 3.209
    },
    {
        "text": "It was a time when pretty much everyone who\nwas involved was really optimistic about what",
        "start": 65.129,
        "duration": 5.511
    },
    {
        "text": "it could mean.",
        "start": 70.64,
        "duration": 1.45
    },
    {
        "text": "The web is going to be the defining social\nmoment for computing.",
        "start": 72.09,
        "duration": 5.95
    },
    {
        "text": "It will give free access to knowledge to people\nwhen you really needed it.",
        "start": 78.04,
        "duration": 3.54
    },
    {
        "text": "It suddenly seemed to shrink the world, and\nsuddenly even being a part of vast distances",
        "start": 81.58,
        "duration": 5.78
    },
    {
        "text": "from people didn't matter as much.",
        "start": 87.36,
        "duration": 2.21
    },
    {
        "text": "Move fast and break things, kids coming out\nof dorm rooms and starting companies.",
        "start": 89.57,
        "duration": 4.96
    },
    {
        "text": "All the walls that used to separate people\nfrom information and from each other were",
        "start": 94.53,
        "duration": 3.41
    },
    {
        "text": "being broken down and used to create again\na new open egalitarian world.",
        "start": 97.94,
        "duration": 4.2
    },
    {
        "text": "American society and American political culture\nallowed these companies to grow and to mediate",
        "start": 102.14,
        "duration": 5.569
    },
    {
        "text": "all our interactions now that we have.",
        "start": 107.709,
        "duration": 3.011
    },
    {
        "text": "People were thinking like is technology good\nfor us?",
        "start": 110.72,
        "duration": 3.1
    },
    {
        "text": "Is the Internet good for us?",
        "start": 113.82,
        "duration": 2.02
    },
    {
        "text": "This will change everything.",
        "start": 115.84,
        "duration": 2.72
    },
    {
        "text": "I think it was clear that the main goal was\nto get it to a stable version and monetize",
        "start": 118.56,
        "duration": 6.77
    },
    {
        "text": "it.",
        "start": 125.33,
        "duration": 1.0
    },
    {
        "text": "Business is working well, the majority of\nour revenues, of course, are in advertising.",
        "start": 126.33,
        "duration": 6.31
    },
    {
        "text": "No one really knew how fast things would evolve.",
        "start": 132.64,
        "duration": 3.4
    },
    {
        "text": "No one really knew how quickly and basically\nhow willingly platforms were willing to sell",
        "start": 136.04,
        "duration": 12.77
    },
    {
        "text": "out users.",
        "start": 148.81,
        "duration": 3.78
    },
    {
        "text": "When I first started covering Silicon Valley,\nI began to try to understand how Silicon Valley",
        "start": 152.59,
        "duration": 4.27
    },
    {
        "text": "companies like Facebook and Google made money.",
        "start": 156.86,
        "duration": 2.23
    },
    {
        "text": "What was their business model?",
        "start": 159.09,
        "duration": 1.97
    },
    {
        "text": "The earliest moment that I can remember when\nprivacy became an issue, the Internet experience,",
        "start": 161.06,
        "duration": 4.659
    },
    {
        "text": "was in 2004 when Google launched Gmail.",
        "start": 165.719,
        "duration": 3.001
    },
    {
        "text": "It was going to do that, it was going to finance\nthis by essentially reading all your emails",
        "start": 168.72,
        "duration": 4.389
    },
    {
        "text": "and then serving you targeted advertising.",
        "start": 173.109,
        "duration": 1.44
    },
    {
        "text": "This was a new thing for most people because\npeople didn't realize how Google was financing",
        "start": 174.549,
        "duration": 4.291
    },
    {
        "text": "its operations until then.",
        "start": 178.84,
        "duration": 1.94
    },
    {
        "text": "Suddenly people became much more savvy about\nwhat was happening on the Internet.",
        "start": 180.78,
        "duration": 5.27
    },
    {
        "text": "A decade ago, like 15 years ago, I would not\nhave found this was possible, not just in",
        "start": 186.05,
        "duration": 4.76
    },
    {
        "text": "terms of ethically, but also technology-wise.",
        "start": 190.81,
        "duration": 3.72
    },
    {
        "text": "Changing your privacy settings at this point\nis like rearranging the chairs on the Titanic",
        "start": 194.53,
        "duration": 5.329
    },
    {
        "text": "in a way.",
        "start": 199.859,
        "duration": 1.761
    },
    {
        "text": "Not only because already a lot of this data\nhas been collected and curated, but also because",
        "start": 201.62,
        "duration": 4.229
    },
    {
        "text": "you even when you change your settings, there\nare ways for people to still scrape information",
        "start": 205.849,
        "duration": 8.491
    },
    {
        "text": "from these websites.",
        "start": 214.34,
        "duration": 3.75
    },
    {
        "text": "The thing that is interesting to me the most\ncurrently is the result that algorithms play",
        "start": 218.09,
        "duration": 6.259
    },
    {
        "text": "in the formation of these online communities.",
        "start": 224.349,
        "duration": 4.461
    },
    {
        "text": "The way these algorithms work is they find\npatterns in data by looking at what humans",
        "start": 228.81,
        "duration": 6.959
    },
    {
        "text": "have provided them as examples.",
        "start": 235.769,
        "duration": 3.791
    },
    {
        "text": "This is one area where buyers could actually\nbe introduced into algorithms.",
        "start": 239.56,
        "duration": 4.97
    },
    {
        "text": "If you think of a word like CEO and a word\nlike man, most likely what you'll see if you",
        "start": 244.53,
        "duration": 6.84
    },
    {
        "text": "mapped him into this vector space, you have\nman here and most likely a CEO is going to",
        "start": 251.37,
        "duration": 4.97
    },
    {
        "text": "be very close to man, but very far away from\nwoman.",
        "start": 256.34,
        "duration": 3.61
    },
    {
        "text": "Looking at this type of algorithm, you could\nalso envision how a system like Google would",
        "start": 259.95,
        "duration": 3.71
    },
    {
        "text": "start to use these type of results.",
        "start": 263.66,
        "duration": 3.76
    },
    {
        "text": "People are really pushing forward for its\nalgorithms to be used in every facet of human",
        "start": 267.42,
        "duration": 3.74
    },
    {
        "text": "life.",
        "start": 271.16,
        "duration": 1.0
    },
    {
        "text": "We don't actually understand fully the consequences.",
        "start": 272.16,
        "duration": 6.38
    },
    {
        "text": "Social media has the power to bring people\ntogether formally like without a voice.",
        "start": 278.54,
        "duration": 5.42
    },
    {
        "text": "We've seen hopeful stories, like the Arab\nSpring.",
        "start": 283.96,
        "duration": 3.28
    },
    {
        "text": "We've seen the MeToo Movement, we've seen\nBlack Lives Matter.",
        "start": 287.24,
        "duration": 5.11
    },
    {
        "text": "The Internet is a great organizing tool.",
        "start": 292.35,
        "duration": 2.34
    },
    {
        "text": "Are we better off now after the Internet has\ncome into existence than we were 30 years",
        "start": 294.69,
        "duration": 4.87
    },
    {
        "text": "ago?",
        "start": 299.56,
        "duration": 1.0
    },
    {
        "text": "Well, it's changed it.",
        "start": 300.56,
        "duration": 1.07
    },
    {
        "text": "It's made some things much better, but again\ninfluence is how it makes money.",
        "start": 301.63,
        "duration": 7.07
    },
    {
        "text": "Platforms generally need to acknowledge that\nthey have responsibility.",
        "start": 308.7,
        "duration": 4.95
    },
    {
        "text": "Users should have a reasonable amount of trust\nin a platform, in a service they're using",
        "start": 313.65,
        "duration": 5.95
    },
    {
        "text": "that their data is not being sold.",
        "start": 319.6,
        "duration": 1.4
    },
    {
        "text": "Some of these companies have started to realize\nthe role that they've played and are moving",
        "start": 321.0,
        "duration": 5.56
    },
    {
        "text": "towards solutions to that end.",
        "start": 326.56,
        "duration": 4.15
    },
    {
        "text": "Here's the question that all of us got to\nanswer, given what's happened here, why we",
        "start": 330.71,
        "duration": 5.24
    },
    {
        "text": "should let you self-regulate?",
        "start": 335.95,
        "duration": 1.25
    },
    {
        "text": "Well, Senator, my position is not that there\nshould be no regulation.",
        "start": 337.2,
        "duration": 4.95
    },
    {
        "text": "I think the Internet is increasingly important.",
        "start": 342.15,
        "duration": 1.541
    },
    {
        "text": "Do you embrace regulation?",
        "start": 343.691,
        "duration": 1.509
    },
    {
        "text": "So, we're going to begin our program with\none of the forefathers of virtual reality.",
        "start": 345.2,
        "duration": 6.1
    },
    {
        "text": "He was there in the beginning since the early\n1980s, I believe.",
        "start": 351.3,
        "duration": 4.36
    },
    {
        "text": "He helped craft a vision for the Internet\nas a way to bring people together.",
        "start": 355.66,
        "duration": 4.02
    },
    {
        "text": "He's a scientist, a musician, and an author,\nand his new book is Ten Arguments for Deleting",
        "start": 359.68,
        "duration": 5.82
    },
    {
        "text": "Your Social Media Accounts right now.",
        "start": 365.5,
        "duration": 2.98
    },
    {
        "text": "Please welcome Jaron Lanier.",
        "start": 368.48,
        "duration": 2.4
    },
    {
        "text": "Jaron, good to see you.",
        "start": 370.88,
        "duration": 3.0
    },
    {
        "text": "Hello, hello.",
        "start": 373.88,
        "duration": 1.2
    },
    {
        "text": "Well, you've said that we don't have to throw\nthe whole thing away, but you also say that",
        "start": 375.08,
        "duration": 6.73
    },
    {
        "text": "this Internet AI has turned us into Pavlovian\ndogs carrying around devices suitable for",
        "start": 381.81,
        "duration": 5.83
    },
    {
        "text": "what you call mass behavior modification.",
        "start": 387.64,
        "duration": 2.2
    },
    {
        "text": "What do you mean by that?",
        "start": 389.84,
        "duration": 2.86
    },
    {
        "text": "Ah, well, there was a time when we used the\nmail, and I should point out when you sent",
        "start": 392.7,
        "duration": 7.49
    },
    {
        "text": "a letter by mail, nobody else read it.",
        "start": 400.19,
        "duration": 2.54
    },
    {
        "text": "You paid for it, but it was strictly your\nbusiness.",
        "start": 402.73,
        "duration": 2.17
    },
    {
        "text": "It was a remarkable thing, almost unimaginable\ntoday.",
        "start": 404.9,
        "duration": 4.95
    },
    {
        "text": "So in those days, you could find yourself\nunder observation by somebody who's trying",
        "start": 409.85,
        "duration": 6.7
    },
    {
        "text": "to be sneaky and manipulate you.",
        "start": 416.55,
        "duration": 1.9
    },
    {
        "text": "One way to do it would be to volunteer for\na psychology test in the basement of the psych",
        "start": 418.45,
        "duration": 4.57
    },
    {
        "text": "building on campus, and then some undergraduates\nwould be behind the one-way mirror trying",
        "start": 423.02,
        "duration": 6.17
    },
    {
        "text": "to get you to do something, or you could get\ninto an abusive relationship, or you could",
        "start": 429.19,
        "duration": 4.83
    },
    {
        "text": "join a cult.",
        "start": 434.02,
        "duration": 2.56
    },
    {
        "text": "You could find yourself on the wrong side\nof an interrogation desk.",
        "start": 436.58,
        "duration": 3.59
    },
    {
        "text": "There are all kinds of ways it could happen,\nbut they were all very localized and unusual.",
        "start": 440.17,
        "duration": 6.86
    },
    {
        "text": "Now it's happening to everybody.",
        "start": 447.03,
        "duration": 2.74
    },
    {
        "text": "Everybody is under constant observation and\nconstant manipulation, albeit just to be very",
        "start": 449.77,
        "duration": 6.28
    },
    {
        "text": "clear, it's slight.",
        "start": 456.05,
        "duration": 2.7
    },
    {
        "text": "So at this point, the degree of observation\nis less than in the scenarios I just described,",
        "start": 458.75,
        "duration": 7.53
    },
    {
        "text": "although it's getting more so every day.",
        "start": 466.28,
        "duration": 4.93
    },
    {
        "text": "The thing is, slight differences, slight behavior\nmodification applied consistently over time",
        "start": 471.21,
        "duration": 6.09
    },
    {
        "text": "can shift society.",
        "start": 477.3,
        "duration": 1.0
    },
    {
        "text": "It's like compound interest.",
        "start": 478.3,
        "duration": 1.4
    },
    {
        "text": "At any particular moment, you might say, oh,\nhow much difference could it make?",
        "start": 479.7,
        "duration": 4.09
    },
    {
        "text": "So I saw an ad from the Russian intelligence\nwarfare people.",
        "start": 483.79,
        "duration": 3.65
    },
    {
        "text": "So it got me a little cranky over something\nor other, who cares?",
        "start": 487.44,
        "duration": 3.57
    },
    {
        "text": "But cumulatively, it does have a statistical\neffect on the whole society.",
        "start": 491.01,
        "duration": 4.17
    },
    {
        "text": "Then as far as why I'm asking people to quit,\nI'll tell you why.",
        "start": 495.18,
        "duration": 3.11
    },
    {
        "text": "It's 'cause I love Silicon Valley.",
        "start": 498.29,
        "duration": 2.18
    },
    {
        "text": "I love making digital products.",
        "start": 500.47,
        "duration": 1.54
    },
    {
        "text": "I've sold a company to Google.",
        "start": 502.01,
        "duration": 1.1
    },
    {
        "text": "I'm working with Microsoft.",
        "start": 503.11,
        "duration": 1.19
    },
    {
        "text": "I adore my community.",
        "start": 504.3,
        "duration": 1.64
    },
    {
        "text": "It's my home, and I don't want you to be passive\nsheep customers.",
        "start": 505.94,
        "duration": 4.81
    },
    {
        "text": "I want you to be demanding tough customers,\nand I want you to make us work to make you",
        "start": 510.75,
        "duration": 4.729
    },
    {
        "text": "happy.",
        "start": 515.479,
        "duration": 1.0
    },
    {
        "text": "Right now, you're all turning into passive\nsheep, and it bugs me.",
        "start": 516.479,
        "duration": 2.821
    },
    {
        "text": "All right.",
        "start": 519.3,
        "duration": 1.0
    },
    {
        "text": "So if you quit, you're at least prodding us.",
        "start": 520.3,
        "duration": 2.229
    },
    {
        "text": "You're at least not just sitting there passively\naccepting whatever we feed you.",
        "start": 522.529,
        "duration": 3.92
    },
    {
        "text": "So I think it would be better for us.",
        "start": 526.449,
        "duration": 1.341
    },
    {
        "text": "I want you to challenge us, because that way\nwe're not disconnected from the world anymore.",
        "start": 527.79,
        "duration": 5.419
    },
    {
        "text": "Can you see that?",
        "start": 533.209,
        "duration": 1.591
    },
    {
        "text": "Like when you engage with Silicon Valley,\nwhen you're tough, you're actually saving",
        "start": 534.8,
        "duration": 4.25
    },
    {
        "text": "us from being abandoned on some desolate island\nof the super empowered.",
        "start": 539.05,
        "duration": 6.38
    },
    {
        "text": "You actually help us.",
        "start": 545.43,
        "duration": 1.519
    },
    {
        "text": "You actually reconnect the world.",
        "start": 546.949,
        "duration": 2.101
    },
    {
        "text": "To get precise about what you're saying, the\ntrend lines are being watched, in how we do",
        "start": 549.05,
        "duration": 6.019
    },
    {
        "text": "respond in tiny bits, are being watched by\nalgorithms that can see what the trend is",
        "start": 555.069,
        "duration": 4.921
    },
    {
        "text": "pointing to, and so it subtlety changes our\nbehavior.",
        "start": 559.99,
        "duration": 2.69
    },
    {
        "text": "Is that how it works?",
        "start": 562.68,
        "duration": 1.0
    },
    {
        "text": "Yeah, the way it works is there are very few\nsort of sneaky people in cubicles trying to",
        "start": 563.68,
        "duration": 6.849
    },
    {
        "text": "figure out how to manipulate you directly.",
        "start": 570.529,
        "duration": 3.831
    },
    {
        "text": "The Russians have some in their employee,\nbut the much more common thing that makes",
        "start": 574.36,
        "duration": 3.649
    },
    {
        "text": "the whole system work is algorithms.",
        "start": 578.009,
        "duration": 2.041
    },
    {
        "text": "So the algorithm will do a little bit of random\nstuff.",
        "start": 580.05,
        "duration": 3.37
    },
    {
        "text": "It will say, well, during what time of the\nmonth is this person more susceptible to this",
        "start": 583.42,
        "duration": 6.099
    },
    {
        "text": "kind of pitch?",
        "start": 589.519,
        "duration": 1.371
    },
    {
        "text": "What about other people who correlate with\nthis person in some way?",
        "start": 590.89,
        "duration": 2.54
    },
    {
        "text": "So all of these correlations turn into this\nstatistical, I wouldn't call it a model of",
        "start": 593.43,
        "duration": 6.82
    },
    {
        "text": "you because it wouldn't pass muster as a scientific\nmodel, but it's kind of a predictive portrait",
        "start": 600.25,
        "duration": 5.42
    },
    {
        "text": "of you that can be used slightly reliably.",
        "start": 605.67,
        "duration": 3.969
    },
    {
        "text": "I mean this stuff is only barely better than\nrandom, but it is a little better than random.",
        "start": 609.639,
        "duration": 4.7
    },
    {
        "text": "So it gradually finds a way to engage with\nyou.",
        "start": 614.339,
        "duration": 3.761
    },
    {
        "text": "We use the word engage instead of addict.",
        "start": 618.1,
        "duration": 1.75
    },
    {
        "text": "What I mean is addict.",
        "start": 619.85,
        "duration": 1.739
    },
    {
        "text": "We gradually addict you through algorithmic\nexploration until we find whatever it is that",
        "start": 621.589,
        "duration": 5.211
    },
    {
        "text": "will get you.",
        "start": 626.8,
        "duration": 1.24
    },
    {
        "text": "What's the business model behind all of that?",
        "start": 628.04,
        "duration": 2.919
    },
    {
        "text": "Well, the business model is it's really kind\nof interesting.",
        "start": 630.959,
        "duration": 5.991
    },
    {
        "text": "I've had occasion to be at these events where\nall of the Silicon Valley companies sell their",
        "start": 636.95,
        "duration": 5.84
    },
    {
        "text": "biggest advertisers big package deals for\nthe next year.",
        "start": 642.79,
        "duration": 3.109
    },
    {
        "text": "It's an amazing spectacle to behold, because\neach of the companies in turn, Facebook and",
        "start": 645.899,
        "duration": 3.771
    },
    {
        "text": "Google and so on, will grab a stage and then\npresent to the biggest advertising buyers,",
        "start": 649.67,
        "duration": 4.64
    },
    {
        "text": "often I kid you not with dancers and special\neffects.",
        "start": 654.31,
        "duration": 2.87
    },
    {
        "text": "It's like this big production.",
        "start": 657.18,
        "duration": 1.81
    },
    {
        "text": "If you listen to the way the companies talk\nabout what they can do to their own customers,",
        "start": 658.99,
        "duration": 4.01
    },
    {
        "text": "the advertisers, you hear this extraordinary\nbragging, like \"We can really nail in on a",
        "start": 663.0,
        "duration": 5.459
    },
    {
        "text": "person.",
        "start": 668.459,
        "duration": 1.0
    },
    {
        "text": "We can get them to do something.\"",
        "start": 669.459,
        "duration": 1.0
    },
    {
        "text": "It's actually a little exaggerated.",
        "start": 670.459,
        "duration": 1.711
    },
    {
        "text": "Then the public face is, \"Oh, no, no, no,\nno.",
        "start": 672.17,
        "duration": 2.62
    },
    {
        "text": "We only do things in your interest.\"",
        "start": 674.79,
        "duration": 1.349
    },
    {
        "text": "But it really is kind of two-faced.",
        "start": 676.139,
        "duration": 1.791
    },
    {
        "text": "There's this very aggressive way that the\ncompanies sell themselves.",
        "start": 677.93,
        "duration": 4.469
    },
    {
        "text": "I think what happens to the advertisers, to\nthe people who are putting all these many",
        "start": 682.399,
        "duration": 3.86
    },
    {
        "text": "billions of dollars into the system, is they\nget scared because they're thinking, \"Oh my",
        "start": 686.259,
        "duration": 4.291
    },
    {
        "text": "god, if we don't pay into these companies,\nit's like we won't exist.\"",
        "start": 690.55,
        "duration": 3.36
    },
    {
        "text": "It's kind of like an existential version of\na mafia protection racket.",
        "start": 693.91,
        "duration": 5.59
    },
    {
        "text": "It's like you're saying, \"You pay us or nobody\nwill know about you.\"",
        "start": 699.5,
        "duration": 4.699
    },
    {
        "text": "I think while the official version is that\nwe're giving you the ads that are more useful,",
        "start": 704.199,
        "duration": 5.39
    },
    {
        "text": "and then the sales version is we're able to\nmind control people for your benefit, the",
        "start": 709.589,
        "duration": 4.471
    },
    {
        "text": "actual truth is we're going to scare you into\nthinking if you don't give us money, you'll",
        "start": 714.06,
        "duration": 3.769
    },
    {
        "text": "cease to exist.",
        "start": 717.829,
        "duration": 1.0
    },
    {
        "text": "So I think those are the three different versions\nof the same business plan.",
        "start": 718.829,
        "duration": 3.07
    },
    {
        "text": "And if I'm not mistaken, you've actually written\nsomewhere that all of this is turning into,",
        "start": 721.899,
        "duration": 5.281
    },
    {
        "text": "these are your words, quote, you said, \"into\nassholes.\"",
        "start": 727.18,
        "duration": 5.219
    },
    {
        "text": "Right, well, I wanted to sound presidential.",
        "start": 732.399,
        "duration": 4.6
    },
    {
        "text": "I should say something about that.",
        "start": 736.999,
        "duration": 8.25
    },
    {
        "text": "Oh, I see.",
        "start": 745.249,
        "duration": 1.481
    },
    {
        "text": "What happens is that when you get somebody\naddicted to something, whether it's an opioid",
        "start": 746.73,
        "duration": 4.19
    },
    {
        "text": "or social media, their personality changes.",
        "start": 750.92,
        "duration": 2.44
    },
    {
        "text": "They get kind of cranky and selfish.",
        "start": 753.36,
        "duration": 1.87
    },
    {
        "text": "There's this thing.",
        "start": 755.23,
        "duration": 1.0
    },
    {
        "text": "Anybody who's known an addict will recognize\nthis, and social media addicts do tend to",
        "start": 756.23,
        "duration": 4.899
    },
    {
        "text": "get this quality, which is sometimes called\nthe snowflake personality where it's almost",
        "start": 761.129,
        "duration": 5.32
    },
    {
        "text": "like they're asking for a fight.",
        "start": 766.449,
        "duration": 2.151
    },
    {
        "text": "They want attention so badly.",
        "start": 768.6,
        "duration": 1.919
    },
    {
        "text": "So it does kind of make you into that thing\nthat was mentioned.",
        "start": 770.519,
        "duration": 3.541
    },
    {
        "text": "I've heard, you've pointed out that some of\nthe tech titans, of which there are not that",
        "start": 774.06,
        "duration": 4.18
    },
    {
        "text": "many, don't let their kids go anywhere near\ntechnology.",
        "start": 778.24,
        "duration": 2.529
    },
    {
        "text": "of my friends in the industry are shocked.",
        "start": 780.769,
        "duration": 2.601
    },
    {
        "text": "I kind of let my daughter do whatever she\nwants.",
        "start": 783.37,
        "duration": 1.759
    },
    {
        "text": "I figure she has to learn her own lessons,\nand they're shocked.",
        "start": 785.129,
        "duration": 1.99
    },
    {
        "text": "\"You let her have a phone?\"",
        "start": 787.119,
        "duration": 1.481
    },
    {
        "text": "I'm like, well, she's going to have to figure\nit out.",
        "start": 788.6,
        "duration": 2.669
    },
    {
        "text": "But a lot of people are incredibly anti-tech\nwithin the tech community.",
        "start": 791.269,
        "duration": 4.81
    },
    {
        "text": "It's rather remarkable.",
        "start": 796.079,
        "duration": 1.0
    },
    {
        "text": "And you've also said that this is approaching\nsomething like the divine right of kings,",
        "start": 797.079,
        "duration": 5.48
    },
    {
        "text": "turning us into people who are following without\nrealizing that we're following, but we're",
        "start": 802.559,
        "duration": 6.681
    },
    {
        "text": "just giving over to it anyway?",
        "start": 809.24,
        "duration": 1.82
    },
    {
        "text": "It is the strangest thing.",
        "start": 811.06,
        "duration": 3.36
    },
    {
        "text": "I don't have anything against the individuals\nI'll mention 'cause a lot of them are people",
        "start": 814.42,
        "duration": 5.69
    },
    {
        "text": "I know, but it's really weird.",
        "start": 820.11,
        "duration": 2.37
    },
    {
        "text": "One of the tech companies is the first large\npublic company controlled by a single person",
        "start": 822.48,
        "duration": 4.789
    },
    {
        "text": "and has all of this power.",
        "start": 827.269,
        "duration": 2.13
    },
    {
        "text": "Why should that be so?",
        "start": 829.399,
        "duration": 1.831
    },
    {
        "text": "It's a very peculiar thing, but we had such\na fervent belief in the myth of the hacker",
        "start": 831.23,
        "duration": 6.159
    },
    {
        "text": "cowboy who would dent reality, in the words\nof Steve Jobs, that somehow we're enacting",
        "start": 837.389,
        "duration": 7.76
    },
    {
        "text": "it.",
        "start": 845.149,
        "duration": 1.0
    },
    {
        "text": "One of the things I'm a little concerned of\nactually is that sometimes when a society",
        "start": 846.149,
        "duration": 4.771
    },
    {
        "text": "chooses figures to be godlike figures, then\nthey'll tear them down.",
        "start": 850.92,
        "duration": 5.149
    },
    {
        "text": "So they'll elect a Mussolini and then hang\nthe Mussolini, or they'll elect the Aztec",
        "start": 856.069,
        "duration": 4.721
    },
    {
        "text": "prince for a year, and then sacrifice that\nperson.",
        "start": 860.79,
        "duration": 4.729
    },
    {
        "text": "I'm a little concerned about some kind of\nwave of hatred against tech, which would be",
        "start": 865.519,
        "duration": 6.66
    },
    {
        "text": "totally inappropriate because we actually\nare doing something important.",
        "start": 872.179,
        "duration": 4.251
    },
    {
        "text": "What I ask is not to hate us, but to engage\nus and to force us to be better.",
        "start": 876.43,
        "duration": 4.599
    },
    {
        "text": "That's a much better scenario.",
        "start": 881.029,
        "duration": 1.24
    },
    {
        "text": "I can understand that, and yet we've seen\nexamples lately where it's being pointed out",
        "start": 882.269,
        "duration": 4.661
    },
    {
        "text": "to us that the smart phones conveying what\nthey're able to convey are turning into propagators",
        "start": 886.93,
        "duration": 8.379
    },
    {
        "text": "of maniacal social violence, weaponized in\nMyanmar, the Rohingya problem.",
        "start": 895.309,
        "duration": 5.03
    },
    {
        "text": "In South Sudan, social media is literally\na deadly weapon.",
        "start": 900.339,
        "duration": 3.78
    },
    {
        "text": "In South Sudan, explain that.",
        "start": 904.119,
        "duration": 1.94
    },
    {
        "text": "Yeah, so this has been one of the awful things\nthat's happened.",
        "start": 906.059,
        "duration": 4.371
    },
    {
        "text": "Early on, Silicon Valley is part of the Bay\nArea in California and tends to swing left,",
        "start": 910.43,
        "duration": 7.67
    },
    {
        "text": "right?",
        "start": 918.1,
        "duration": 1.0
    },
    {
        "text": "Very early on, there was this, I would say,\na certainty that if you just let people talk",
        "start": 919.1,
        "duration": 6.769
    },
    {
        "text": "to each other, it'll create positive leftist\nchanges in the world.",
        "start": 925.869,
        "duration": 5.551
    },
    {
        "text": "One of the first great triumphs of that was\nthe Arab Spring, like, oh, we'll just give",
        "start": 931.42,
        "duration": 3.389
    },
    {
        "text": "power to the people.",
        "start": 934.809,
        "duration": 1.03
    },
    {
        "text": "They'll overthrow dictators.",
        "start": 935.839,
        "duration": 1.06
    },
    {
        "text": "They'll create this beautiful democracy.",
        "start": 936.899,
        "duration": 2.151
    },
    {
        "text": "Now, the thing is the algorithms that are\nwatching participants in something like the",
        "start": 939.05,
        "duration": 6.55
    },
    {
        "text": "Arab Spring aren't left or right.",
        "start": 945.6,
        "duration": 2.139
    },
    {
        "text": "They're not humanistic.",
        "start": 947.739,
        "duration": 1.5
    },
    {
        "text": "They have no feelings at all.",
        "start": 949.239,
        "duration": 2.03
    },
    {
        "text": "They're just trying to find any path to maximize\naddiction and maximize influence algorithmically,",
        "start": 951.269,
        "duration": 5.901
    },
    {
        "text": "just through searching.",
        "start": 957.17,
        "duration": 1.52
    },
    {
        "text": "Eventually, they discover, the algorithms\ndiscover in a blind algorithmic way that the",
        "start": 958.69,
        "duration": 6.089
    },
    {
        "text": "negative emotions, the negative people are\neasier to engage.",
        "start": 964.779,
        "duration": 2.941
    },
    {
        "text": "So everything starts tilting towards amplifying\nthose people.",
        "start": 967.72,
        "duration": 3.309
    },
    {
        "text": "So you'll have an ISIS that gets even more\nmileage from the same tools that propelled",
        "start": 971.029,
        "duration": 4.73
    },
    {
        "text": "an Arab Spring, or you'll get a resurgent\nKKK and neo-Nazi movie that gets even more",
        "start": 975.759,
        "duration": 5.481
    },
    {
        "text": "mileage from the same nexus of communications\nthat propelled the Black Lives Matter, is",
        "start": 981.24,
        "duration": 6.039
    },
    {
        "text": "an example that happened here.",
        "start": 987.279,
        "duration": 2.37
    },
    {
        "text": "We see this again and again.",
        "start": 989.649,
        "duration": 2.66
    },
    {
        "text": "Can I get just slightly geeky for a second?",
        "start": 992.309,
        "duration": 2.101
    },
    {
        "text": "Please, please.",
        "start": 994.41,
        "duration": 1.0
    },
    {
        "text": "Okay.",
        "start": 995.41,
        "duration": 1.0
    },
    {
        "text": "But you geeks have given this to us.",
        "start": 996.41,
        "duration": 1.94
    },
    {
        "text": "Yeah, okay, well, then thank you for giving\nus another chance to screw you up here.",
        "start": 998.35,
        "duration": 7.219
    },
    {
        "text": "In classical behaviorism, the earliest experiments\nused things like candy and electric shocks",
        "start": 1005.569,
        "duration": 6.221
    },
    {
        "text": "to give people stimulus response to what they\ndid to change their behavior, right?",
        "start": 1011.79,
        "duration": 3.949
    },
    {
        "text": "That's the Skinner box.",
        "start": 1015.739,
        "duration": 2.111
    },
    {
        "text": "Now, we don't yet have drones hovering over\npeople dropping candy or electric shocks on",
        "start": 1017.85,
        "duration": 5.679
    },
    {
        "text": "them, right?",
        "start": 1023.529,
        "duration": 1.0
    },
    {
        "text": "That's coming, but it's not here yet, so we\nuse symbols, analogous to Pavlov's bell.",
        "start": 1024.529,
        "duration": 6.251
    },
    {
        "text": "But we use social experience to give people\nlittle dopamine hits, as we call them in the",
        "start": 1030.78,
        "duration": 5.159
    },
    {
        "text": "trade, the little positive feeling when you\nget retweeted or something, and then the negative",
        "start": 1035.939,
        "duration": 4.27
    },
    {
        "text": "ones, when you get treated badly, when you\nget harassed online, insulted.",
        "start": 1040.209,
        "duration": 9.621
    },
    {
        "text": "So the thing is that in a broad sense, positive\nand negative stimuli are both powerful in",
        "start": 1049.83,
        "duration": 8.86
    },
    {
        "text": "people, but they have different time profiles.",
        "start": 1058.69,
        "duration": 2.229
    },
    {
        "text": "So what happens is the positive ones can take\nlonger to build and can be broken more quickly,",
        "start": 1060.919,
        "duration": 5.081
    },
    {
        "text": "and the negative ones can come up faster.",
        "start": 1066.0,
        "duration": 1.809
    },
    {
        "text": "So it's faster to get startled or scared than\nit is to relax, but it takes longer to build",
        "start": 1067.809,
        "duration": 6.101
    },
    {
        "text": "trust than it takes to lose trust.",
        "start": 1073.91,
        "duration": 1.63
    },
    {
        "text": "So you can see, they're reverses.",
        "start": 1075.54,
        "duration": 1.81
    },
    {
        "text": "So since the algorithms are responding on\na rapid feedback loop, they select out and",
        "start": 1077.35,
        "duration": 4.699
    },
    {
        "text": "amplify the negative stuff, and that's why\nISIS gets more mileage than the Arab Spring,",
        "start": 1082.049,
        "duration": 4.771
    },
    {
        "text": "and that's why the Klan gets more mileage\nthan Black Lives Matter.",
        "start": 1086.82,
        "duration": 2.54
    },
    {
        "text": "So what's the solution?",
        "start": 1089.36,
        "duration": 1.0
    },
    {
        "text": "Do we have to step away and abandon the free\nmodel?",
        "start": 1090.36,
        "duration": 4.96
    },
    {
        "text": "think there's a variety of possible solutions.",
        "start": 1095.32,
        "duration": 2.06
    },
    {
        "text": "The one that I'm really interested in is changing\nthe underlying business model.",
        "start": 1097.38,
        "duration": 4.039
    },
    {
        "text": "So if you have an underlying business model\nwhere the only way you can make a penny, what",
        "start": 1101.419,
        "duration": 5.971
    },
    {
        "text": "we're doing now is so insane.",
        "start": 1107.39,
        "duration": 1.19
    },
    {
        "text": "Can you imagine if in the old days, if you\nmailed somebody a letter, instead of buying",
        "start": 1108.58,
        "duration": 3.65
    },
    {
        "text": "postage, the letter would be free, but some\ncustomer would only pay money if they were",
        "start": 1112.23,
        "duration": 6.65
    },
    {
        "text": "confident that they could change the letter\nin a way that they would influence events.",
        "start": 1118.88,
        "duration": 3.9
    },
    {
        "text": "That would be extraordinary, right?",
        "start": 1122.78,
        "duration": 1.17
    },
    {
        "text": "But that's exactly what we've done.",
        "start": 1123.95,
        "duration": 1.209
    },
    {
        "text": "Right now, if you and I are to have contact\nover the Internet, this thing that's supposed",
        "start": 1125.159,
        "duration": 3.231
    },
    {
        "text": "to be open and free, the only way that can\nbe financed is by a third party who we don't",
        "start": 1128.39,
        "duration": 4.45
    },
    {
        "text": "know about who wishes to influence us both.",
        "start": 1132.84,
        "duration": 2.66
    },
    {
        "text": "So once you have that business model, it's\nlike this red carpet invitation to the Russians",
        "start": 1135.5,
        "duration": 4.049
    },
    {
        "text": "and other bad actors in the Klan and whoever\nto use it, because they can get incredible",
        "start": 1139.549,
        "duration": 5.35
    },
    {
        "text": "mileage out of it of a disruptive and negative\nsort.",
        "start": 1144.899,
        "duration": 3.891
    },
    {
        "text": "So bring back postage.",
        "start": 1148.79,
        "duration": 2.55
    },
    {
        "text": "Make it paid.",
        "start": 1151.34,
        "duration": 3.78
    },
    {
        "text": "In the days when Facebook was being founded,\neverybody thought that the way movies and",
        "start": 1155.12,
        "duration": 4.27
    },
    {
        "text": "TV would be created would be like the Wikipedia.",
        "start": 1159.39,
        "duration": 2.72
    },
    {
        "text": "It would be this massive volunteer free thing.",
        "start": 1162.11,
        "duration": 2.22
    },
    {
        "text": "Everybody in Silicon Valley, not in Hollywood.",
        "start": 1164.33,
        "duration": 2.55
    },
    {
        "text": "We had an honest test.",
        "start": 1166.88,
        "duration": 1.53
    },
    {
        "text": "That was tried.",
        "start": 1168.41,
        "duration": 1.0
    },
    {
        "text": "A lot of people tried to do that, but then\nwe had Netflix, HBO, Hulu, et cetera, and",
        "start": 1169.41,
        "duration": 3.989
    },
    {
        "text": "it turns out that when people pay for TV,\nwe got this thing called peak TV.",
        "start": 1173.399,
        "duration": 4.41
    },
    {
        "text": "We did an honest test, we got an honest result.",
        "start": 1177.809,
        "duration": 2.901
    },
    {
        "text": "So what I want Facebook to turn into, I don't\nwant the good stuff on Facebook to disappear,",
        "start": 1180.71,
        "duration": 4.9
    },
    {
        "text": "I think there's a lot of extremely positive\nstuff that happens on social media, I want",
        "start": 1185.61,
        "duration": 4.62
    },
    {
        "text": "it to turn into a cross between Netflix and\nEtsy.",
        "start": 1190.23,
        "duration": 4.62
    },
    {
        "text": "I want you to pay for it like you pay for\nNetflix so you can get peak social media,",
        "start": 1194.85,
        "duration": 3.799
    },
    {
        "text": "but if you do something special that means\na lot, I want you to be able to get money",
        "start": 1198.649,
        "duration": 3.101
    },
    {
        "text": "for your craft, like you would on Etsy.",
        "start": 1201.75,
        "duration": 1.69
    },
    {
        "text": "So I want that to be the future of Facebook.",
        "start": 1203.44,
        "duration": 2.14
    },
    {
        "text": "It sounds good, but to get a little bit realistic,\nthat would take an awful lot.",
        "start": 1205.58,
        "duration": 3.19
    },
    {
        "text": "Do you think any technology company would\nactually go for this?",
        "start": 1208.77,
        "duration": 2.4
    },
    {
        "text": "They'll do better.",
        "start": 1211.17,
        "duration": 1.0
    },
    {
        "text": "I mean, this is just normal capitalism.",
        "start": 1212.17,
        "duration": 3.749
    },
    {
        "text": "This idea of people coming in from the side\nand getting in the middle of everybody and",
        "start": 1215.919,
        "duration": 4.522
    },
    {
        "text": "manipulating society as the only business\nmodel is not capitalism.",
        "start": 1220.441,
        "duration": 3.098
    },
    {
        "text": "It's some bizarre dystopic thing.",
        "start": 1223.539,
        "duration": 3.811
    },
    {
        "text": "I'm suggesting just normal capitalism, like\npeople pay for stuff they like and they have",
        "start": 1227.35,
        "duration": 4.01
    },
    {
        "text": "a choice about it.",
        "start": 1231.36,
        "duration": 1.0
    },
    {
        "text": "It's just normal.",
        "start": 1232.36,
        "duration": 3.11
    },
    {
        "text": "I think it would be better for Facebook, it\nwould be better for Google, I think it would",
        "start": 1235.47,
        "duration": 3.32
    },
    {
        "text": "be better for everybody.",
        "start": 1238.79,
        "duration": 1.0
    },
    {
        "text": "I think their shareholders would be happy.",
        "start": 1239.79,
        "duration": 1.55
    },
    {
        "text": "I think it's just the better solution.",
        "start": 1241.34,
        "duration": 2.12
    },
    {
        "text": "If we could figure out how to have that happen\nall at once.",
        "start": 1243.46,
        "duration": 2.03
    },
    {
        "text": "But let me ask you one other question.",
        "start": 1245.49,
        "duration": 1.09
    },
    {
        "text": "All right.",
        "start": 1246.58,
        "duration": 1.0
    },
    {
        "text": "You've said that this was all making politics\nimpossible as we understand it.",
        "start": 1247.58,
        "duration": 3.959
    },
    {
        "text": "I must say because the way the rights of individuals\nfor voting and all was conceived in an age",
        "start": 1251.539,
        "duration": 7.5
    },
    {
        "text": "when we didn't have any of this magical stuff,\nit's changed the definition of politics almost.",
        "start": 1259.039,
        "duration": 6.441
    },
    {
        "text": "Yeah, I mean we live in a bizarre world now\nthat just happened recently.",
        "start": 1265.48,
        "duration": 5.4
    },
    {
        "text": "I feel sorry for young people who couldn't\nexperience the contrast with what came earlier",
        "start": 1270.88,
        "duration": 4.61
    },
    {
        "text": "where nothing seems real, everything seems\nlike it's manipulated by unseen forces, everybody's",
        "start": 1275.49,
        "duration": 7.53
    },
    {
        "text": "on edge all the time.",
        "start": 1283.02,
        "duration": 2.1
    },
    {
        "text": "Not that we had utopia before, but we had\na little bit more reality.",
        "start": 1285.12,
        "duration": 7.07
    },
    {
        "text": "We must get back there to survive.",
        "start": 1292.19,
        "duration": 1.69
    },
    {
        "text": "I don't see how we can survive if we're insane.",
        "start": 1293.88,
        "duration": 3.039
    },
    {
        "text": "But one big question is whether anyone's criticism\nwill matter?",
        "start": 1296.919,
        "duration": 3.271
    },
    {
        "text": "So there's this bit of a confusion on this\nmatter.",
        "start": 1300.19,
        "duration": 3.709
    },
    {
        "text": "Sometime in the Silicon Valley atmosphere,\nthere's this thing like, well, if you're optimistic,",
        "start": 1303.899,
        "duration": 3.581
    },
    {
        "text": "it means your complacent 'cause you're sure\nthings will work out automatically, it'll",
        "start": 1307.48,
        "duration": 3.91
    },
    {
        "text": "just naturally get better.",
        "start": 1311.39,
        "duration": 1.19
    },
    {
        "text": "I don't think that's ever been true.",
        "start": 1312.58,
        "duration": 1.67
    },
    {
        "text": "I think we have progressed and things have\ngotten better and the various trend lines",
        "start": 1314.25,
        "duration": 4.32
    },
    {
        "text": "of betterment are very real, but every single\nincrement of that betterment was due to somebody",
        "start": 1318.57,
        "duration": 4.26
    },
    {
        "text": "putting their foot down and saying things\ncan be better.",
        "start": 1322.83,
        "duration": 2.229
    },
    {
        "text": "Jaron Lanier, thank you very much for joining\nus and ending on a positive note.",
        "start": 1325.059,
        "duration": 4.75
    },
    {
        "text": "Thank you very much.",
        "start": 1329.809,
        "duration": 2.48
    },
    {
        "text": "Thank you so much.",
        "start": 1332.289,
        "duration": 2.48
    },
    {
        "text": "What is the science behind these AI systems\nthat are impacting everything from the news",
        "start": 1334.769,
        "duration": 4.831
    },
    {
        "text": "you read, healthcare, who gets hired, promoted,\ndeported, What does living in a world run",
        "start": 1339.6,
        "duration": 5.61
    },
    {
        "text": "by algorithms mean?",
        "start": 1345.21,
        "duration": 1.349
    },
    {
        "text": "Joining us now to dig deeper into all of this,\nDirector of the Harvard and MIT Ethics and",
        "start": 1346.559,
        "duration": 5.591
    },
    {
        "text": "Governance AI Initiative and the former Google\nGlobal Public Policy lead for artificial intelligence",
        "start": 1352.15,
        "duration": 8.139
    },
    {
        "text": "and machine learning, please welcome Tim Hwang.",
        "start": 1360.289,
        "duration": 5.37
    },
    {
        "text": "Tim?",
        "start": 1365.659,
        "duration": 1.48
    },
    {
        "text": "Co-founder of the AI Now Institute that's\nbased at NYU, she is a research scientist",
        "start": 1367.139,
        "duration": 6.92
    },
    {
        "text": "and founder of the Google Open Research Group.",
        "start": 1374.059,
        "duration": 3.36
    },
    {
        "text": "Please welcome Meredith Whittaker.",
        "start": 1377.419,
        "duration": 3.38
    },
    {
        "text": "Aviv Ovadya is Chief Technologist at the Center\nfor Social Media Responsibility at the University",
        "start": 1380.799,
        "duration": 9.151
    },
    {
        "text": "of Michigan School of Information.",
        "start": 1389.95,
        "duration": 1.94
    },
    {
        "text": "He has worked to improve and provided research\nfor Amazon, the MIT Media Lab, for Morgan",
        "start": 1391.89,
        "duration": 7.57
    },
    {
        "text": "Stanley, Quora, Yerdle, the Tow Center for\nDigital Journalism, and Google.",
        "start": 1399.46,
        "duration": 6.26
    },
    {
        "text": "Please welcome Aviv Ovadya.",
        "start": 1405.72,
        "duration": 3.769
    },
    {
        "text": "And last but not least, a professor of law,\nbusiness, and economics at Villanova University,",
        "start": 1409.489,
        "duration": 5.851
    },
    {
        "text": "he's also an affiliated scholar of the Center\nfor Internet Society at Stanford Law School.",
        "start": 1415.34,
        "duration": 6.98
    },
    {
        "text": "Please welcome Brett Frischmann.",
        "start": 1422.32,
        "duration": 4.959
    },
    {
        "text": "So let's start with Brett.",
        "start": 1427.279,
        "duration": 2.441
    },
    {
        "text": "Your book, Re-Engineering Humanity, posits\nthat technology is turning us into machines.",
        "start": 1429.72,
        "duration": 6.52
    },
    {
        "text": "Is it?",
        "start": 1436.24,
        "duration": 1.51
    },
    {
        "text": "Well, the idea behind the book is to get us\nto ask ourselves how often in our life you",
        "start": 1437.75,
        "duration": 7.02
    },
    {
        "text": "feel like or you behave as if automatically\nor comparable to a machine, right?",
        "start": 1444.77,
        "duration": 6.25
    },
    {
        "text": "So the idea of thinking about, am I performing\na script?",
        "start": 1451.02,
        "duration": 4.96
    },
    {
        "text": "Am I behaving habitually or automatically,\nand if so who wrote that script?",
        "start": 1455.98,
        "duration": 5.85
    },
    {
        "text": "So the idea is to think more and more about\nhow the technical systems, the world we're",
        "start": 1461.83,
        "duration": 5.94
    },
    {
        "text": "building or really engineering for ourselves\naffects who we are as human beings, how we",
        "start": 1467.77,
        "duration": 6.49
    },
    {
        "text": "think, how we relate to each other, how we\ninteract with each other in different settings.",
        "start": 1474.26,
        "duration": 4.23
    },
    {
        "text": "Tim, let me ask you about the good and bad.",
        "start": 1478.49,
        "duration": 2.98
    },
    {
        "text": "AI seems to be a label that's put on everything\nthese days.",
        "start": 1481.47,
        "duration": 3.12
    },
    {
        "text": "It sure is.",
        "start": 1484.59,
        "duration": 2.02
    },
    {
        "text": "What does the term AI really mean in the context\nthat we have here?",
        "start": 1486.61,
        "duration": 4.409
    },
    {
        "text": "Training computers to perform tasks, how do\nyou train a computer?",
        "start": 1491.019,
        "duration": 3.221
    },
    {
        "text": "That's right.",
        "start": 1494.24,
        "duration": 1.0
    },
    {
        "text": "So, when you talk about AI, it's important\nto keep two things separate.",
        "start": 1495.24,
        "duration": 3.279
    },
    {
        "text": "One of them is the marketing of AI, which\nis what you're referring to, and then there's",
        "start": 1498.519,
        "duration": 4.591
    },
    {
        "text": "the sort of computer science of AI.",
        "start": 1503.11,
        "duration": 3.039
    },
    {
        "text": "Really that is a subfield of artificial intelligence\nthat's known as machine learning.",
        "start": 1506.149,
        "duration": 5.211
    },
    {
        "text": "The basics of machine learning that you need\nto know is it's sort of the study of algorithms",
        "start": 1511.36,
        "duration": 4.159
    },
    {
        "text": "that get better the more data that they see.",
        "start": 1515.519,
        "duration": 2.711
    },
    {
        "text": "So the notion is if you want to teach a machine\nto understand how to recognize a cat in an",
        "start": 1518.23,
        "duration": 4.329
    },
    {
        "text": "image, you show it lots of images of cats.",
        "start": 1522.559,
        "duration": 2.901
    },
    {
        "text": "There's a certain set of methodologies that\nare used to allow it to accomplish that task,",
        "start": 1525.46,
        "duration": 5.079
    },
    {
        "text": "and really that's the subfield that's been\ndriving really a lot of the progress that",
        "start": 1530.539,
        "duration": 3.561
    },
    {
        "text": "you've seen in the last few years.",
        "start": 1534.1,
        "duration": 1.699
    },
    {
        "text": "These machines are learning machines.",
        "start": 1535.799,
        "duration": 2.37
    },
    {
        "text": "How does that really work?",
        "start": 1538.169,
        "duration": 2.591
    },
    {
        "text": "So, a lot of it is based on the recognition\nof what's known as features.",
        "start": 1540.76,
        "duration": 4.539
    },
    {
        "text": "For example, if you imagined trying to recognize\na cat, the example that I just gave you earlier,",
        "start": 1545.299,
        "duration": 6.091
    },
    {
        "text": "back in the day the idea is that you get a\nbunch of programs together to think about",
        "start": 1551.39,
        "duration": 2.749
    },
    {
        "text": "how they recognize a cat themselves, and then\nthey'd program explicit rules into a machine.",
        "start": 1554.139,
        "duration": 4.53
    },
    {
        "text": "So they'd say, \"Well, a cat's fuzzy and a\ncat is usually these kinds of colors.\"",
        "start": 1558.669,
        "duration": 4.11
    },
    {
        "text": "You'd actually put those rules in.",
        "start": 1562.779,
        "duration": 1.9
    },
    {
        "text": "One of the unique things about machine learning\nthough is that it's able to identify these",
        "start": 1564.679,
        "duration": 3.99
    },
    {
        "text": "features by itself.",
        "start": 1568.669,
        "duration": 2.441
    },
    {
        "text": "After lots and lots of examples, machines\ncan do what they call inference.",
        "start": 1571.11,
        "duration": 4.059
    },
    {
        "text": "They're able to say, \"Well, in all the cases\nthat I've seen, these are the types of things",
        "start": 1575.169,
        "duration": 3.781
    },
    {
        "text": "that are associated with cats.\"",
        "start": 1578.95,
        "duration": 1.0
    },
    {
        "text": "It turns out that once you do it that way,\nyou get these systems that are much, much",
        "start": 1579.95,
        "duration": 3.39
    },
    {
        "text": "better than we had before in doing these types\nof tasks.",
        "start": 1583.34,
        "duration": 4.079
    },
    {
        "text": "Better, smarter?",
        "start": 1587.419,
        "duration": 1.421
    },
    {
        "text": "Sure, depending on how you define smart.",
        "start": 1588.84,
        "duration": 1.85
    },
    {
        "text": "That's part of our problem here today.",
        "start": 1590.69,
        "duration": 2.989
    },
    {
        "text": "So, Meredith,\nYou've said that we've rushed these technologies",
        "start": 1593.679,
        "duration": 3.171
    },
    {
        "text": "into some of the most sensitive areas of our\nlives,",
        "start": 1596.85,
        "duration": 3.13
    },
    {
        "text": "I'm going to ask your permission to go off\nscript immediately and sort of answer the",
        "start": 1599.98,
        "duration": 6.809
    },
    {
        "text": "question you asked to Tim, 'cause I think\nwe need to set up where we are right now socially",
        "start": 1606.789,
        "duration": 4.39
    },
    {
        "text": "and politically.",
        "start": 1611.179,
        "duration": 1.391
    },
    {
        "text": "Fine.",
        "start": 1612.57,
        "duration": 1.0
    },
    {
        "text": "Then we can get into some of the examples.",
        "start": 1613.57,
        "duration": 1.73
    },
    {
        "text": "But when you ask what AI is, I have been in\nthe tech industry for almost 12 years now.",
        "start": 1615.3,
        "duration": 8.099
    },
    {
        "text": "I have thought a lot about these issues.",
        "start": 1623.399,
        "duration": 3.341
    },
    {
        "text": "That's not an easy question to answer, even\nfor somebody who is enmeshed in these technologies.",
        "start": 1626.74,
        "duration": 5.409
    },
    {
        "text": "That's partly because while it's an old field,\nover 60 years old, it is newly adopted in",
        "start": 1632.149,
        "duration": 9.26
    },
    {
        "text": "the last five to ten years, and everyone can\nattest to this.",
        "start": 1641.409,
        "duration": 3.381
    },
    {
        "text": "You can't pass a newsstand without seeing\nanother shiny white robot and some promise",
        "start": 1644.79,
        "duration": 4.93
    },
    {
        "text": "of singularity futures, right?",
        "start": 1649.72,
        "duration": 2.789
    },
    {
        "text": "I think we have to ask, okay, why is this?",
        "start": 1652.509,
        "duration": 3.27
    },
    {
        "text": "Why did this just crop up like mushrooms everywhere\nwe go?",
        "start": 1655.779,
        "duration": 4.39
    },
    {
        "text": "When you ask that question, you begin to see\nthat, oh, this happened right around the time",
        "start": 1660.169,
        "duration": 4.451
    },
    {
        "text": "that big tech corporations were consolidating,\nthat this business model had taken over.",
        "start": 1664.62,
        "duration": 6.809
    },
    {
        "text": "Where finally you have these organizations\nthat have incredible compute power, they have",
        "start": 1671.429,
        "duration": 5.74
    },
    {
        "text": "super computing infrastructure.",
        "start": 1677.169,
        "duration": 1.49
    },
    {
        "text": "They are actually able to process the massive\namounts of data that is needed to, as Tim",
        "start": 1678.659,
        "duration": 5.131
    },
    {
        "text": "said, train these systems to recognize patterns.",
        "start": 1683.79,
        "duration": 3.769
    },
    {
        "text": "They have this data because they have vast\nmarket reach, from Facebook to Google to whatever",
        "start": 1687.559,
        "duration": 7.181
    },
    {
        "text": "other app you've installed, they are able\nto continually collect huge amounts of data.",
        "start": 1694.74,
        "duration": 4.39
    },
    {
        "text": "They have the infrastructure to store it,\nand then they have incredibly talented engineers",
        "start": 1699.13,
        "duration": 6.24
    },
    {
        "text": "that they can afford to pay to build these\nalgorithms.",
        "start": 1705.37,
        "duration": 3.47
    },
    {
        "text": "So we look at this as sort of a commodification\nof a earlier theoretical, I would say, not",
        "start": 1708.84,
        "duration": 10.651
    },
    {
        "text": "a prominent branch of computer science for\nmany years that suddenly became marketable.",
        "start": 1719.491,
        "duration": 4.589
    },
    {
        "text": "So we have to ask when we look at AI, whose\nstories are we hearing?",
        "start": 1724.08,
        "duration": 3.94
    },
    {
        "text": "And a lot of times, what we're hearing are\nthe stories that are written by the marketing",
        "start": 1728.02,
        "duration": 4.07
    },
    {
        "text": "departments of the corporations that have\nrecognized the marketability and the profitability",
        "start": 1732.09,
        "duration": 4.73
    },
    {
        "text": "of these techniques that have been around\nfor a while.",
        "start": 1736.82,
        "duration": 4.0
    },
    {
        "text": "That raises the question of motive.",
        "start": 1740.82,
        "duration": 1.53
    },
    {
        "text": "For example, you have written and spoken about\nthe fact that there are algorithms that claim",
        "start": 1742.35,
        "duration": 5.27
    },
    {
        "text": "to be able to discover which people are more\nlikely to commit a crime.",
        "start": 1747.62,
        "duration": 5.21
    },
    {
        "text": "Absolutely, and you have to ask, if you look\nat one of the companies that has claimed to",
        "start": 1752.83,
        "duration": 7.53
    },
    {
        "text": "be able to do this and their researchers and\nbusinesses that are looking at this as a technology",
        "start": 1760.36,
        "duration": 5.569
    },
    {
        "text": "is Axon, which used to be called Taser, which\nhas a huge cache of police body cam data.",
        "start": 1765.929,
        "duration": 7.111
    },
    {
        "text": "So they acquired two AI companies about a\nyear and a half ago and are busy creating",
        "start": 1773.04,
        "duration": 5.96
    },
    {
        "text": "real time facial recognition systems that\nwill analyze the data captured by police body",
        "start": 1779.0,
        "duration": 6.01
    },
    {
        "text": "cams.",
        "start": 1785.01,
        "duration": 1.0
    },
    {
        "text": "Now their premise is, hey, police encounter\ncriminals, we have this dataset that will",
        "start": 1786.01,
        "duration": 3.85
    },
    {
        "text": "then model criminality.",
        "start": 1789.86,
        "duration": 1.99
    },
    {
        "text": "We'll train the AI to see what a criminal\nlooks like, if you're thinking eugenics, physiognomy,",
        "start": 1791.85,
        "duration": 4.98
    },
    {
        "text": "phrenology, you're right.",
        "start": 1796.83,
        "duration": 2.38
    },
    {
        "text": "Then we will be able to identify pre-crime.",
        "start": 1799.21,
        "duration": 2.74
    },
    {
        "text": "Innocent until proven guilty, it sounds like\nit's under some kind of threat.",
        "start": 1801.95,
        "duration": 3.79
    },
    {
        "text": "Yeah.",
        "start": 1805.74,
        "duration": 1.0
    },
    {
        "text": "Yeah, and I think that's part of the concern\naround the marketing of it, because I think",
        "start": 1806.74,
        "duration": 3.86
    },
    {
        "text": "there is such a big feeding frenzy over the\npromise of the technology.",
        "start": 1810.6,
        "duration": 3.909
    },
    {
        "text": "That's often quite at odds with what the technology\ncan actually do.",
        "start": 1814.509,
        "duration": 2.741
    },
    {
        "text": "So I think part of the concern is that you\nactually see this technology being deployed",
        "start": 1817.25,
        "duration": 3.53
    },
    {
        "text": "in all sorts of situations where it's not\nready for primetime and may not ever be ready",
        "start": 1820.78,
        "duration": 4.889
    },
    {
        "text": "for primetime.",
        "start": 1825.669,
        "duration": 1.0
    },
    {
        "text": "I think we have to ask the categorical question\nof even if it worked as well as we believe",
        "start": 1826.669,
        "duration": 3.21
    },
    {
        "text": "it did, would it still be something we'd want\nto do?",
        "start": 1829.879,
        "duration": 2.881
    },
    {
        "text": "And its effect on the labor force, on employment?",
        "start": 1832.76,
        "duration": 3.539
    },
    {
        "text": "Again, stepping back just a second, one of\nthe real issues with speaking categorically",
        "start": 1836.299,
        "duration": 6.021
    },
    {
        "text": "about these things is that they are being\ndeployed without our knowledge.",
        "start": 1842.32,
        "duration": 4.16
    },
    {
        "text": "So we don't know how often we encounter a\nsystem that classifies us, and as the classified,",
        "start": 1846.48,
        "duration": 5.87
    },
    {
        "text": "we don't often know that the results, the\nopportunities we're given or denied, the resources",
        "start": 1852.35,
        "duration": 5.0
    },
    {
        "text": "we're given or denied, we're actually informed\nby an algorithmic backend system.",
        "start": 1857.35,
        "duration": 4.42
    },
    {
        "text": "There is no transparency about these systems.",
        "start": 1861.77,
        "duration": 2.21
    },
    {
        "text": "We don't have standardized ways to measure\nthem, and they're often sold by vendors to",
        "start": 1863.98,
        "duration": 3.72
    },
    {
        "text": "businesses without informing the public.",
        "start": 1867.7,
        "duration": 2.429
    },
    {
        "text": "This is a huge issue.",
        "start": 1870.129,
        "duration": 2.4
    },
    {
        "text": "I can talk about what we do know about their\nimpact, but I think we need to level set there",
        "start": 1872.529,
        "duration": 4.78
    },
    {
        "text": "that there is a huge need for transparency\nand accountability.",
        "start": 1877.309,
        "duration": 5.791
    },
    {
        "text": "Aviv, do you think that people, since we've\nheard about the Facebook scandal and we've",
        "start": 1883.1,
        "duration": 4.279
    },
    {
        "text": "heard about so many things, do you think people\ndo understand this threat better now?",
        "start": 1887.379,
        "duration": 4.93
    },
    {
        "text": "I think far better than they did, let's say,\nthree months ago, six months ago, a year ago,",
        "start": 1892.309,
        "duration": 5.61
    },
    {
        "text": "a year and a half ago.",
        "start": 1897.919,
        "duration": 2.031
    },
    {
        "text": "The good part of a lot of the current crisis\nis at least people are more aware of the way",
        "start": 1899.95,
        "duration": 6.479
    },
    {
        "text": "in which technology is impacting their day-to-day,\nwhat information they consume, how they're",
        "start": 1906.429,
        "duration": 4.771
    },
    {
        "text": "being manipulated in some cases, and also\nthe recommendation systems that affect what",
        "start": 1911.2,
        "duration": 6.16
    },
    {
        "text": "they see and what they believe.",
        "start": 1917.36,
        "duration": 1.74
    },
    {
        "text": "I think just the fact that algorithm has become\na word that many people know is a new phenomenon",
        "start": 1919.1,
        "duration": 5.549
    },
    {
        "text": "I think over the last year.",
        "start": 1924.649,
        "duration": 1.331
    },
    {
        "text": "That is very valuable, because in the same\nway that government that people need to know,",
        "start": 1925.98,
        "duration": 2.799
    },
    {
        "text": "algorithm is a word people need to know.",
        "start": 1928.779,
        "duration": 1.0
    },
    {
        "text": "There's another issue that you're all I think\nheading towards.",
        "start": 1929.779,
        "duration": 1.201
    },
    {
        "text": "It's the fact that a small handful of people\nwho are designing a lot of these come from,",
        "start": 1930.98,
        "duration": 5.789
    },
    {
        "text": "well, they're white men in the Bay Area basically\nAs the woman of the panel, yes, they are.",
        "start": 1936.769,
        "duration": 8.071
    },
    {
        "text": "They're white men in the Bay Area in the Western\ncontext, and they are of a similar upper middle-class",
        "start": 1944.84,
        "duration": 7.829
    },
    {
        "text": "to very rich social strata.",
        "start": 1952.669,
        "duration": 2.37
    },
    {
        "text": "They are often educated with exactly the same\nbackground, because to do this, we're not",
        "start": 1955.039,
        "duration": 4.451
    },
    {
        "text": "just talking about going to coding camp, we're\ntalking about a series of very specific advanced",
        "start": 1959.49,
        "duration": 5.47
    },
    {
        "text": "degrees.",
        "start": 1964.96,
        "duration": 3.24
    },
    {
        "text": "For all the best intentions, and some of these\npeople might be your friends, that's a worldview.",
        "start": 1968.2,
        "duration": 4.709
    },
    {
        "text": "That's a worldview that is embedded in, say,\nthe features you choose to emphasize in your",
        "start": 1972.909,
        "duration": 4.72
    },
    {
        "text": "cat detection, right?",
        "start": 1977.629,
        "duration": 1.371
    },
    {
        "text": "That's a worldview that's embedded in how\nyou understand gender classification, how",
        "start": 1979.0,
        "duration": 4.231
    },
    {
        "text": "you understand some of these softer relational\ncategories.",
        "start": 1983.231,
        "duration": 3.078
    },
    {
        "text": "That's a worldview that becomes baked into\nthis technology that then scales globally,",
        "start": 1986.309,
        "duration": 6.401
    },
    {
        "text": "seriously globally, in ways that are remapping\nthe world according to that vision.",
        "start": 1992.71,
        "duration": 8.219
    },
    {
        "text": "We should be worried about that.",
        "start": 2000.929,
        "duration": 1.551
    },
    {
        "text": "Indeed, the data scientist Cathy O'Neil has\nterms a coin for algorithms that are secret",
        "start": 2002.48,
        "duration": 6.159
    },
    {
        "text": "and harmful, weapons of math destruction.",
        "start": 2008.639,
        "duration": 3.101
    },
    {
        "text": "Yeah, it's a good pun.",
        "start": 2011.74,
        "duration": 3.24
    },
    {
        "text": "One thing that would help discourse about\nthese issues is to always remember that AI",
        "start": 2014.98,
        "duration": 4.62
    },
    {
        "text": "is, always will be, always should be, nothing\nmore than a tool designed, owned, managed,",
        "start": 2019.6,
        "duration": 6.819
    },
    {
        "text": "deployed by human beings.",
        "start": 2026.419,
        "duration": 1.72
    },
    {
        "text": "So whenever you're talking about AI and its\nimpact or its influence or claims, it's never",
        "start": 2028.139,
        "duration": 5.471
    },
    {
        "text": "claims by AI, it's claims about AI made by\npurveyors of AI.",
        "start": 2033.61,
        "duration": 5.22
    },
    {
        "text": "It's peeking behind the hood, looking who\nowns it, who designs it, who manages it, and",
        "start": 2038.83,
        "duration": 5.089
    },
    {
        "text": "it tends to be concentrated in certain ways.",
        "start": 2043.919,
        "duration": 3.21
    },
    {
        "text": "Go ahead.",
        "start": 2047.129,
        "duration": 1.27
    },
    {
        "text": "I would just quickly add to that because I\ncompletely agree.",
        "start": 2048.399,
        "duration": 2.711
    },
    {
        "text": "We also need to look at whose power it serves,\nbecause when we're talking about the workplace",
        "start": 2051.11,
        "duration": 4.88
    },
    {
        "text": "examples you gave, right on, right?",
        "start": 2055.99,
        "duration": 3.05
    },
    {
        "text": "When is the last time you went to a CVS and\nthe automated checkout worked?",
        "start": 2059.04,
        "duration": 2.99
    },
    {
        "text": "It's not replacing us anytime soon, but what\nit is doing is it is increasingly monitoring,",
        "start": 2062.03,
        "duration": 8.45
    },
    {
        "text": "surveilling, and determining which workers\nare valuable, good, and promotable, and which",
        "start": 2070.48,
        "duration": 5.449
    },
    {
        "text": "aren't.",
        "start": 2075.929,
        "duration": 1.0
    },
    {
        "text": "Of course, this is trained on data gathered\nfrom the current workforce, which shows deep",
        "start": 2076.929,
        "duration": 4.23
    },
    {
        "text": "skews in inequity, and I can get into some\nexamples there.",
        "start": 2081.159,
        "duration": 3.73
    },
    {
        "text": "But this is a question of power alongside\na question of exactly how the technology is",
        "start": 2084.889,
        "duration": 5.121
    },
    {
        "text": "constructed.",
        "start": 2090.01,
        "duration": 1.97
    },
    {
        "text": "Just to add one thing beyond that, it's not\njust what power it serves, but it's also what",
        "start": 2091.98,
        "duration": 4.26
    },
    {
        "text": "power it entrenches, as in as a result of\nthis technology, like being deployed in this",
        "start": 2096.24,
        "duration": 5.45
    },
    {
        "text": "way, who now has more power than they had\nbefore and what can they now do with that?",
        "start": 2101.69,
        "duration": 4.36
    },
    {
        "text": "Are there some areas, do any of you feel,\nwhere this new technology should never be",
        "start": 2106.05,
        "duration": 6.7
    },
    {
        "text": "used?",
        "start": 2112.75,
        "duration": 1.0
    },
    {
        "text": "Some institutions were algorithms should never\nbe used?",
        "start": 2113.75,
        "duration": 3.63
    },
    {
        "text": "I think the question is not do I want to put\nmy foot down and say never here ever.",
        "start": 2117.38,
        "duration": 5.33
    },
    {
        "text": "I think the question is what proof do we have\nthat they work and how do we validate that?",
        "start": 2122.71,
        "duration": 4.629
    },
    {
        "text": "In most cases, we have very little proof at\nall.",
        "start": 2127.339,
        "duration": 2.391
    },
    {
        "text": "We haven't even started developing the mechanisms\nto say that this is actually safe.",
        "start": 2129.73,
        "duration": 3.93
    },
    {
        "text": "This actually works across populations.",
        "start": 2133.66,
        "duration": 2.949
    },
    {
        "text": "This actually does what the marketing department\nsays it does.",
        "start": 2136.609,
        "duration": 3.071
    },
    {
        "text": "So I think the more sensitive the area we\ndeploy it into, say education, healthcare,",
        "start": 2139.68,
        "duration": 4.2
    },
    {
        "text": "et cetera, the more we have to wait until\nwe have those techniques in place before we",
        "start": 2143.88,
        "duration": 4.54
    },
    {
        "text": "trust it.",
        "start": 2148.42,
        "duration": 1.31
    },
    {
        "text": "That being said though, I think it is interesting\nchasing after problems where even if we did",
        "start": 2149.73,
        "duration": 4.52
    },
    {
        "text": "all that verification and it turns out that\nit is better, that for other values and other",
        "start": 2154.25,
        "duration": 3.92
    },
    {
        "text": "reasons we might still say no.",
        "start": 2158.17,
        "duration": 1.64
    },
    {
        "text": "I think those classes are a very tricky set\nof classes where, I think like in the justice",
        "start": 2159.81,
        "duration": 4.11
    },
    {
        "text": "context specifically, where we could actually\nimagine, well, maybe we actually do introduce",
        "start": 2163.92,
        "duration": 3.45
    },
    {
        "text": "these systems that are measurably better,\nbut maybe there's something about justice",
        "start": 2167.37,
        "duration": 3.34
    },
    {
        "text": "or providing the death sentence that actually\nrequires a human to be in that.",
        "start": 2170.71,
        "duration": 4.149
    },
    {
        "text": "So the relevant question is what's better,\nright?",
        "start": 2174.859,
        "duration": 2.651
    },
    {
        "text": "Sure.",
        "start": 2177.51,
        "duration": 1.0
    },
    {
        "text": "Better in terms of accuracy with respect to\na scientifically defined or computation problem",
        "start": 2178.51,
        "duration": 3.66
    },
    {
        "text": "that we can all agree on?",
        "start": 2182.17,
        "duration": 1.41
    },
    {
        "text": "Or better in terms of some set of values that\nmay very well be about fairness, equity, due",
        "start": 2183.58,
        "duration": 6.82
    },
    {
        "text": "process, or other values that aren't necessarily\neasily captured in sort of an empirical question",
        "start": 2190.4,
        "duration": 6.14
    },
    {
        "text": "about accuracy?",
        "start": 2196.54,
        "duration": 1.0
    },
    {
        "text": "Those are constantly trade-offs across a whole\nhost of areas.",
        "start": 2197.54,
        "duration": 3.809
    },
    {
        "text": "So one way to think about it is for every\ngiven case to be made in favor of using AI",
        "start": 2201.349,
        "duration": 5.071
    },
    {
        "text": "as a tool in a particular context of the sort\nyour question raise-",
        "start": 2206.42,
        "duration": 3.64
    },
    {
        "text": "Like the priority of a doctor's office, for\nexample?",
        "start": 2210.06,
        "duration": 1.6
    },
    {
        "text": "Right, so you should compare alternative tools.",
        "start": 2211.66,
        "duration": 4.35
    },
    {
        "text": "Comparing various tools in context provides\na means for thinking about accuracy, effects,",
        "start": 2216.01,
        "duration": 6.01
    },
    {
        "text": "power relationships, who's behind the tools,\nwhere's the information flow behind the scenes,",
        "start": 2222.02,
        "duration": 6.18
    },
    {
        "text": "or where is information coming and going from?",
        "start": 2228.2,
        "duration": 2.99
    },
    {
        "text": "Those are all a host of complex contextual\nvariables that aren't easily even captured",
        "start": 2231.19,
        "duration": 7.929
    },
    {
        "text": "in most of the conversations about AI.",
        "start": 2239.119,
        "duration": 2.521
    },
    {
        "text": "I would also add that we need to also think\nabout what are the checks and balances that",
        "start": 2241.64,
        "duration": 7.209
    },
    {
        "text": "we're putting into place as we deploy these\nsystems.",
        "start": 2248.849,
        "duration": 2.171
    },
    {
        "text": "Maybe it does make sense in this context,\neven in this criminal justice context, as",
        "start": 2251.02,
        "duration": 3.76
    },
    {
        "text": "we consider the trade-offs and our values\naround it, which is absolutely crucial.",
        "start": 2254.78,
        "duration": 5.13
    },
    {
        "text": "But then what are the checks to make sure\nthat this is being used in the way that we",
        "start": 2259.91,
        "duration": 4.0
    },
    {
        "text": "want it to be used?",
        "start": 2263.91,
        "duration": 1.0
    },
    {
        "text": "Because if we're just dealing with black box\nsystems, that doesn't necessarily fly in some",
        "start": 2264.91,
        "duration": 5.34
    },
    {
        "text": "contexts.",
        "start": 2270.25,
        "duration": 1.0
    },
    {
        "text": "Right, so now let's look at some more variables.",
        "start": 2271.25,
        "duration": 1.77
    },
    {
        "text": "We have to add into this, this recent phenomenon\nof fake news, which first popped up before",
        "start": 2273.02,
        "duration": 5.69
    },
    {
        "text": "the 2016 election.",
        "start": 2278.71,
        "duration": 1.43
    },
    {
        "text": "We began seeing dubious news stories online\nthat were engineered for maximum disruption.",
        "start": 2280.14,
        "duration": 5.26
    },
    {
        "text": "What happens when anyone can make it appear\nas if anything has happened, regardless of",
        "start": 2285.4,
        "duration": 3.93
    },
    {
        "text": "whether it did or not?",
        "start": 2289.33,
        "duration": 1.25
    },
    {
        "text": "Let's look at this short film we have on that\ndifficult question.",
        "start": 2290.58,
        "duration": 4.02
    },
    {
        "text": "All this information is coming from all these\ndifferent sources, and it's getting harder",
        "start": 2294.6,
        "duration": 3.65
    },
    {
        "text": "and harder and harder to understand and to\nfigure out for ourselves what is actually",
        "start": 2298.25,
        "duration": 5.2
    },
    {
        "text": "true and what is not.",
        "start": 2303.45,
        "duration": 2.67
    },
    {
        "text": "And I want you all to know that we are fighting\nthe fake news.",
        "start": 2306.12,
        "duration": 4.62
    },
    {
        "text": "It's fake, phony, fake.",
        "start": 2310.74,
        "duration": 7.3
    },
    {
        "text": "Fake news came out of the 2016 election.",
        "start": 2318.04,
        "duration": 2.579
    },
    {
        "text": "That's when it became a thing.",
        "start": 2320.619,
        "duration": 3.061
    },
    {
        "text": "One of the scariest advancements in AI suddenly\nhas been the machinery that can be used to",
        "start": 2323.68,
        "duration": 7.95
    },
    {
        "text": "create fake media and fake idea.",
        "start": 2331.63,
        "duration": 2.66
    },
    {
        "text": "Especially our friends who are lesbian, gay,\nbisexual, or transgender.",
        "start": 2334.29,
        "duration": 4.89
    },
    {
        "text": "I visited with the families of many of the\nvictims on Thursday.",
        "start": 2339.18,
        "duration": 5.159
    },
    {
        "text": "I think the technology will get to the point\nwhere even the media finds the expert will",
        "start": 2344.339,
        "duration": 2.641
    },
    {
        "text": "not be able to tell what is a true fake and\nwhat is not.",
        "start": 2346.98,
        "duration": 4.099
    },
    {
        "text": "It won't be far fetched to think of it as\nbeing used as maybe a cause for war sometimes.",
        "start": 2351.079,
        "duration": 8.111
    },
    {
        "text": "A country releasing a video that shows other\ncountry is loading nuclear missiles and ready",
        "start": 2359.19,
        "duration": 5.43
    },
    {
        "text": "to launch, they might use that as a cause\nto preemptively strike that country.",
        "start": 2364.62,
        "duration": 4.75
    },
    {
        "text": "Brett, you've come at this issue of fake news\nfrom a somewhat different perspective I think.",
        "start": 2369.37,
        "duration": 6.17
    },
    {
        "text": "You say people often ask how can people be\nso stupid to believe and engage this way,",
        "start": 2375.54,
        "duration": 5.69
    },
    {
        "text": "and you tell them the entire interface is\nmade to make you believe this way.",
        "start": 2381.23,
        "duration": 4.079
    },
    {
        "text": "How is it so?",
        "start": 2385.309,
        "duration": 1.881
    },
    {
        "text": "Right, so I got very frustrated when the story\nabout fake news is breaking and everyone is",
        "start": 2387.19,
        "duration": 7.442
    },
    {
        "text": "paying attention to it, how often I heard\nthe meme, I guess, that people are stupid",
        "start": 2394.632,
        "duration": 5.628
    },
    {
        "text": "and lazy for believing in fake news.",
        "start": 2400.26,
        "duration": 2.88
    },
    {
        "text": "So I would suggest that a lot of the people's\nsusceptibility or propensity to believe what",
        "start": 2403.14,
        "duration": 7.15
    },
    {
        "text": "they're seeing on various platforms is a function\nof the design of the platforms.",
        "start": 2410.29,
        "duration": 5.49
    },
    {
        "text": "So, if you're on a social media network to\nbe named, you guys can figure out which one",
        "start": 2415.78,
        "duration": 5.3
    },
    {
        "text": "you want, if it's designed for, optimized\nin its design for rapid clicking, quick scrolling,",
        "start": 2421.08,
        "duration": 8.32
    },
    {
        "text": "or certain forms of engagement based on profit,\nwhere the money is to be made or where data",
        "start": 2429.4,
        "duration": 5.14
    },
    {
        "text": "is to be gathered, that dis-encourages or\ndis-incentivizes people to stop and think",
        "start": 2434.54,
        "duration": 9.68
    },
    {
        "text": "or deliberate or research or ask deeper questions\nabout the content that they're receiving.",
        "start": 2444.22,
        "duration": 6.75
    },
    {
        "text": "So one species of fake news problem is a function\nof making profit, creating content to get",
        "start": 2450.97,
        "duration": 11.28
    },
    {
        "text": "clicked, right?",
        "start": 2462.25,
        "duration": 1.14
    },
    {
        "text": "They could care less, those purveyors of that\nkind of content could care less about convincing",
        "start": 2463.39,
        "duration": 4.959
    },
    {
        "text": "you or changing your beliefs.",
        "start": 2468.349,
        "duration": 1.181
    },
    {
        "text": "It's just click to make money and the platform\nenables that.",
        "start": 2469.53,
        "duration": 3.86
    },
    {
        "text": "The other species is a species of content\nthat's all about propaganda or changing beliefs",
        "start": 2473.39,
        "duration": 5.979
    },
    {
        "text": "or influencing how someone approaches a problem,\nand oftentimes that's not at all about making",
        "start": 2479.369,
        "duration": 5.641
    },
    {
        "text": "money.",
        "start": 2485.01,
        "duration": 1.0
    },
    {
        "text": "It's about changing beliefs.",
        "start": 2486.01,
        "duration": 1.02
    },
    {
        "text": "To deal with that, you need some form of judgment\nabout the quality, the veracity, the providence",
        "start": 2487.03,
        "duration": 8.48
    },
    {
        "text": "of the information itself, the nature of the\ncontent.",
        "start": 2495.51,
        "duration": 4.4
    },
    {
        "text": "Our current social media platforms struggle\non both fronts, both in terms of being designed",
        "start": 2499.91,
        "duration": 5.42
    },
    {
        "text": "for certain kinds of engagement that enable\na for-profit model, and on the other hand,",
        "start": 2505.33,
        "duration": 7.81
    },
    {
        "text": "for not wanting to engage in the development\nof editorial judgment or the exercise of editorial",
        "start": 2513.14,
        "duration": 6.49
    },
    {
        "text": "judgment by human beings because that risks\nputting them in sort of a content moderation",
        "start": 2519.63,
        "duration": 5.33
    },
    {
        "text": "position.",
        "start": 2524.96,
        "duration": 1.149
    },
    {
        "text": "Now that's started to change since the fake\nnews story has broke.",
        "start": 2526.109,
        "duration": 5.651
    },
    {
        "text": "Right, you've talked about this has created\na disease, techno social environment, that",
        "start": 2531.76,
        "duration": 5.15
    },
    {
        "text": "we're suffering from an engineered complacency.",
        "start": 2536.91,
        "duration": 3.169
    },
    {
        "text": "Does that frighten any of you?",
        "start": 2540.079,
        "duration": 2.841
    },
    {
        "text": "Does it frighten you?",
        "start": 2542.92,
        "duration": 2.179
    },
    {
        "text": "Engineered complacency?",
        "start": 2545.099,
        "duration": 1.831
    },
    {
        "text": "Maybe I should explain what I mean, and then\nyou guys can tell me if it frightens you.",
        "start": 2546.93,
        "duration": 2.419
    },
    {
        "text": "It's meant to frighten, ah!",
        "start": 2549.349,
        "duration": 1.921
    },
    {
        "text": "No, but what I mean by engineered complacency\nis that much of the environment is designed",
        "start": 2551.27,
        "duration": 6.36
    },
    {
        "text": "in a way that repeat interactions in the environment\nlead you to feel as if it's futile to resist,",
        "start": 2557.63,
        "duration": 6.35
    },
    {
        "text": "there are no other options.",
        "start": 2563.98,
        "duration": 2.17
    },
    {
        "text": "So if you think about, the easier example\nthan the fake news context is maybe online",
        "start": 2566.15,
        "duration": 4.53
    },
    {
        "text": "contracting.",
        "start": 2570.68,
        "duration": 1.0
    },
    {
        "text": "So what do you do when you see an I agree\nbutton pop up on a website?",
        "start": 2571.68,
        "duration": 3.84
    },
    {
        "text": "Not always, but most people most of the time\nclick I agree, as you're supposed to by virtue",
        "start": 2575.52,
        "duration": 5.61
    },
    {
        "text": "of both the design of the site and the interface,\nas well as the nature of the take it or leave",
        "start": 2581.13,
        "duration": 5.3
    },
    {
        "text": "it interaction that you're having, the nature\nof the transaction.",
        "start": 2586.43,
        "duration": 3.42
    },
    {
        "text": "Plus the fact that you repeat interactions\nwith that interface over time, so even if",
        "start": 2589.85,
        "duration": 5.729
    },
    {
        "text": "you thought, you know what, maybe I'll stop\nand think about the legal relationship I'm",
        "start": 2595.579,
        "duration": 4.601
    },
    {
        "text": "entering into for some of the websites that\nI'm visiting or some of the apps that I'm",
        "start": 2600.18,
        "duration": 4.27
    },
    {
        "text": "downloading or some of the devices I'm installing\nin my home, how do you decide which of the",
        "start": 2604.45,
        "duration": 5.95
    },
    {
        "text": "many different encounters with the interface\nwould 'cause you to stop and think?",
        "start": 2610.4,
        "duration": 3.73
    },
    {
        "text": "Indeed, that raises another question.",
        "start": 2614.13,
        "duration": 1.54
    },
    {
        "text": "Are we actually changing the way the brain\noperates?",
        "start": 2615.67,
        "duration": 2.61
    },
    {
        "text": "To what effect is this, Tim?",
        "start": 2618.28,
        "duration": 3.25
    },
    {
        "text": "Well, I would say I'm not a neuroscientist,\nbut I think there is habit formation.",
        "start": 2621.53,
        "duration": 7.67
    },
    {
        "text": "I think there's no doubt about that.",
        "start": 2629.2,
        "duration": 1.21
    },
    {
        "text": "I think one of the things that Brett's point\nout, which I think is really great, is that",
        "start": 2630.41,
        "duration": 3.399
    },
    {
        "text": "your experience of certain elements online\ntrain you for how you behave in future experiences",
        "start": 2633.809,
        "duration": 6.011
    },
    {
        "text": "with that, right?",
        "start": 2639.82,
        "duration": 1.0
    },
    {
        "text": "Yes.",
        "start": 2640.82,
        "duration": 1.0
    },
    {
        "text": "So I could even imagine a strange world that\nwe're in right now where we say everybody",
        "start": 2641.82,
        "duration": 2.56
    },
    {
        "text": "gets together and they all agree that this\nsituation's really bad and we should do something",
        "start": 2644.38,
        "duration": 2.63
    },
    {
        "text": "about it, and we actually change how the design\nof the software looks.",
        "start": 2647.01,
        "duration": 5.25
    },
    {
        "text": "But actually people's behaviors are actually\nstuck in a format that will make those behaviors",
        "start": 2652.26,
        "duration": 3.95
    },
    {
        "text": "sticky over time.",
        "start": 2656.21,
        "duration": 1.08
    },
    {
        "text": "So you could actually imagine let's just bust\nup and shut down Facebook tomorrow, whether",
        "start": 2657.29,
        "duration": 3.92
    },
    {
        "text": "or not it actually recreates itself as a result\nof the fact that the market now is entrained",
        "start": 2661.21,
        "duration": 4.57
    },
    {
        "text": "in certain ways.",
        "start": 2665.78,
        "duration": 1.67
    },
    {
        "text": "I think that's an interesting possibility\nand a really challenging one if you think",
        "start": 2667.45,
        "duration": 2.22
    },
    {
        "text": "about the fact that these two variables are\nactually related, right?",
        "start": 2669.67,
        "duration": 3.37
    },
    {
        "text": "That people are influenced, but then they\nactually influence the production in the system",
        "start": 2673.04,
        "duration": 3.86
    },
    {
        "text": "in return.",
        "start": 2676.9,
        "duration": 1.0
    },
    {
        "text": "Aviv, you're nodding vigorously there.",
        "start": 2677.9,
        "duration": 1.439
    },
    {
        "text": "I was just agreeing that I think this is another\nexample of the entrenchment of power, where",
        "start": 2679.339,
        "duration": 5.321
    },
    {
        "text": "here it's not even power in a particular organization,\nbut it's power in a particular almost process",
        "start": 2684.66,
        "duration": 6.11
    },
    {
        "text": "or way of using yourself and your brain and\nyour environment.",
        "start": 2690.77,
        "duration": 4.45
    },
    {
        "text": "I would add I agree and I would say and yet\nit is power in a particular organization.",
        "start": 2695.22,
        "duration": 7.49
    },
    {
        "text": "I have never known a product manager or engineer\nto get promoted for reducing engagement.",
        "start": 2702.71,
        "duration": 7.5
    },
    {
        "text": "There are certain types of incentive structures\nthat are driving the culture and ecosystems",
        "start": 2710.21,
        "duration": 6.19
    },
    {
        "text": "of these companies, and even if you're engaging\nwith propaganda that is not there to make",
        "start": 2716.4,
        "duration": 4.649
    },
    {
        "text": "money for clicks, the longer you stay on a\nsite, the more adrenalizing content you're",
        "start": 2721.049,
        "duration": 5.181
    },
    {
        "text": "exposed to, the more ads they show you.",
        "start": 2726.23,
        "duration": 2.369
    },
    {
        "text": "So there is a monetary incentive in these\nad business platforms to keep people on the",
        "start": 2728.599,
        "duration": 7.391
    },
    {
        "text": "site, which I think the politics of that are\nbecoming clear, the risks of that are becoming",
        "start": 2735.99,
        "duration": 4.96
    },
    {
        "text": "clear, but the business model remains pretty\nscolaric.",
        "start": 2740.95,
        "duration": 3.359
    },
    {
        "text": "And Brett, go ahead.",
        "start": 2744.309,
        "duration": 1.54
    },
    {
        "text": "I'd love to add one wrinkle to this discussion\nthough, too, 'cause I think a lot about this",
        "start": 2745.849,
        "duration": 5.311
    },
    {
        "text": "Catch 22 that platforms find themselves in,\nbecause they can say, \"Okay, we're not going",
        "start": 2751.16,
        "duration": 4.62
    },
    {
        "text": "to take action,\" in which case the public\nis like, \"You're negligent, you didn't take",
        "start": 2755.78,
        "duration": 3.16
    },
    {
        "text": "action.\"",
        "start": 2758.94,
        "duration": 1.0
    },
    {
        "text": "Then they're like, \"Okay, okay, so we're going\nto take action.\"",
        "start": 2759.94,
        "duration": 1.21
    },
    {
        "text": "Then they're like, \"You're imposing your ethical\nwill on me.\"",
        "start": 2761.15,
        "duration": 2.09
    },
    {
        "text": "I think this actually is part of the tricky\nthing that needs to be dealt with because",
        "start": 2763.24,
        "duration": 3.589
    },
    {
        "text": "I think when people ask the question, \"Facebook,\ndo you have a responsibility here?\"",
        "start": 2766.829,
        "duration": 3.701
    },
    {
        "text": "the question is should they be the ones who\nare delegated that responsibility?",
        "start": 2770.53,
        "duration": 4.329
    },
    {
        "text": "That ends up being a very interesting and\ntricky question, and I worry about situations",
        "start": 2774.859,
        "duration": 4.621
    },
    {
        "text": "where we say they could just do better, 'cause\nin some ways it sort of reinforces their position",
        "start": 2779.48,
        "duration": 4.9
    },
    {
        "text": "in making a lot of these decisions as well.",
        "start": 2784.38,
        "duration": 1.949
    },
    {
        "text": "So we may need to actually even rethink the\ngovernance of how these things were designed",
        "start": 2786.329,
        "duration": 3.631
    },
    {
        "text": "in a much bigger way.",
        "start": 2789.96,
        "duration": 1.69
    },
    {
        "text": "I would caution against us/them mentality\nin general.",
        "start": 2791.65,
        "duration": 5.219
    },
    {
        "text": "I think oftentimes, but it varies by context\nand it varies by the technology we're talking",
        "start": 2796.869,
        "duration": 5.291
    },
    {
        "text": "about.",
        "start": 2802.16,
        "duration": 1.0
    },
    {
        "text": "The rest of you must have strong feelings\nabout this.",
        "start": 2803.16,
        "duration": 5.48
    },
    {
        "text": "I'm concerned about what I call the Overton\nwindow of crisis here.",
        "start": 2808.64,
        "duration": 5.41
    },
    {
        "text": "The over-\nThe Overton window of crisis.",
        "start": 2814.05,
        "duration": 2.85
    },
    {
        "text": "Overton window, it's a concept from political\nscience that talks about what's politically",
        "start": 2816.9,
        "duration": 3.76
    },
    {
        "text": "acceptable?",
        "start": 2820.66,
        "duration": 1.699
    },
    {
        "text": "The notion is that certain events occasionally\nwill happen that will widen that window, where",
        "start": 2822.359,
        "duration": 4.061
    },
    {
        "text": "someone breaks various norms in politics and\nsuddenly a whole lot of activity is allowed",
        "start": 2826.42,
        "duration": 4.84
    },
    {
        "text": "that wasn't allowed before, it becomes plausible\nin a way that it wasn't.",
        "start": 2831.26,
        "duration": 3.97
    },
    {
        "text": "I think there was a view early on around these\nprivacy debates which is, okay, people don't",
        "start": 2835.23,
        "duration": 4.28
    },
    {
        "text": "care about privacy right now, but we just\nneed to wait until the first big crisis, the",
        "start": 2839.51,
        "duration": 3.349
    },
    {
        "text": "first big data bridge, and then everybody\nwill care about privacy.",
        "start": 2842.859,
        "duration": 3.081
    },
    {
        "text": "Then that moment came and went, and then came\nand went, and came and went, and came and",
        "start": 2845.94,
        "duration": 3.914
    },
    {
        "text": "went, and you get this feeling now that actually\nthat state of affairs has been normalized",
        "start": 2849.854,
        "duration": 4.026
    },
    {
        "text": "in a way that actually makes it quite difficult\nto mobilize change politically, within the",
        "start": 2853.88,
        "duration": 5.439
    },
    {
        "text": "ministry.",
        "start": 2859.319,
        "duration": 1.0
    },
    {
        "text": "I was talking to a person who does product\nmanagement recently.",
        "start": 2860.319,
        "duration": 3.0
    },
    {
        "text": "I was like, \"Oh, well, you know this product\nyou're building, you can kind of improve it",
        "start": 2863.319,
        "duration": 2.491
    },
    {
        "text": "in X, Y, Z ways.\"",
        "start": 2865.81,
        "duration": 1.559
    },
    {
        "text": "He said, \"Well, you know, we're going to get\nblamed by the public enemies no matter what",
        "start": 2867.369,
        "duration": 3.881
    },
    {
        "text": "we do, so we're just going to do it.\"",
        "start": 2871.25,
        "duration": 1.91
    },
    {
        "text": "I think that's a really interesting phenomenon\nwhere basically the response has been so built",
        "start": 2873.16,
        "duration": 5.64
    },
    {
        "text": "into the process that that creates a level\nof apathy onto itself.",
        "start": 2878.8,
        "duration": 5.019
    },
    {
        "text": "And the effectiveness of dissent has been\nmuted so much that that's just part of it.",
        "start": 2883.819,
        "duration": 6.011
    },
    {
        "text": "You look at the media for a while.",
        "start": 2889.83,
        "duration": 3.33
    },
    {
        "text": "There may be some stories about it, but there\nis not effective organizing.",
        "start": 2893.16,
        "duration": 4.87
    },
    {
        "text": "I guess another thing about this is I find\nthe current framework of privacy broken to",
        "start": 2898.03,
        "duration": 7.19
    },
    {
        "text": "talk about a lot of what we're speaking about.",
        "start": 2905.22,
        "duration": 3.19
    },
    {
        "text": "I don't know that I've ever personally felt\nor detected harm from a privacy breach, although",
        "start": 2908.41,
        "duration": 6.04
    },
    {
        "text": "I've been in all sorts of databases that have\nleaked because of egregious security practices.",
        "start": 2914.45,
        "duration": 6.349
    },
    {
        "text": "But I do know that we have collective harms,\nand I think we need to begin thinking about",
        "start": 2920.799,
        "duration": 5.111
    },
    {
        "text": "these things collectively.",
        "start": 2925.91,
        "duration": 2.51
    },
    {
        "text": "It's not I keep my personal data safe, it's\nthat we have major interests, the Federal",
        "start": 2928.42,
        "duration": 6.99
    },
    {
        "text": "Government and this smartwatch or whatever\nit is, large tech companies who are interested",
        "start": 2935.41,
        "duration": 5.56
    },
    {
        "text": "in understanding this data and then creating\nprofiles of us based on the data.",
        "start": 2940.97,
        "duration": 5.2
    },
    {
        "text": "So I may not have contributed my data, but\nI am suddenly profiled because there is a",
        "start": 2946.17,
        "duration": 4.199
    },
    {
        "text": "model about childhood activity.",
        "start": 2950.369,
        "duration": 2.851
    },
    {
        "text": "Who knows where that's going to go?",
        "start": 2953.22,
        "duration": 1.819
    },
    {
        "text": "Is that going to be used to weight college\nadmissions?",
        "start": 2955.039,
        "duration": 3.441
    },
    {
        "text": "Will that be sent to insurance companies to\nsee whose family gets insurance?",
        "start": 2958.48,
        "duration": 4.109
    },
    {
        "text": "But we have not asked for transparency or\noversight into these kinds of processes and",
        "start": 2962.589,
        "duration": 6.051
    },
    {
        "text": "assumptions.",
        "start": 2968.64,
        "duration": 1.0
    },
    {
        "text": "So when we talk about privacy, it's often\nsort of a very thin debate, 'cause I don't",
        "start": 2969.64,
        "duration": 3.39
    },
    {
        "text": "have time to do my laundry let alone read\nthrough a TOS and then take responsibility",
        "start": 2973.03,
        "duration": 3.75
    },
    {
        "text": "for where all of my data is.",
        "start": 2976.78,
        "duration": 2.23
    },
    {
        "text": "Aviv.",
        "start": 2979.01,
        "duration": 1.0
    },
    {
        "text": "I think that one of the other things to really\nkeep in mind here is that there are really",
        "start": 2980.01,
        "duration": 3.089
    },
    {
        "text": "hard trade-offs being made when you're thinking\nabout privacy.",
        "start": 2983.099,
        "duration": 3.561
    },
    {
        "text": "So one example is if you were talking about\nmisinformation in the 2016 election or even",
        "start": 2986.66,
        "duration": 5.47
    },
    {
        "text": "stuff that's being spread in let's say Myanmar,\nwhere you might have people creating fake",
        "start": 2992.13,
        "duration": 7.01
    },
    {
        "text": "accounts, and those fake accounts are spreading\nthis propaganda.",
        "start": 2999.14,
        "duration": 2.51
    },
    {
        "text": "That propaganda is causing violence or it's\nmisinforming voters.",
        "start": 3001.65,
        "duration": 3.85
    },
    {
        "text": "Well, how does a Facebook go and actually\ndetect those fake accounts?",
        "start": 3005.5,
        "duration": 3.099
    },
    {
        "text": "Well, they're looking at the IPs of all these\nusers.",
        "start": 3008.599,
        "duration": 3.361
    },
    {
        "text": "They're looking at every single signal they\ncan possibly get on that user and comparing",
        "start": 3011.96,
        "duration": 4.13
    },
    {
        "text": "it to what they know are real users and to\ntell the difference.",
        "start": 3016.09,
        "duration": 4.33
    },
    {
        "text": "So if they don't have that data, they can't\nmake that comparison, then that makes their",
        "start": 3020.42,
        "duration": 4.42
    },
    {
        "text": "job a lot harder in protecting our democracy.",
        "start": 3024.84,
        "duration": 1.759
    },
    {
        "text": "In fact, they're trying to do that which they\nnow ostensibly are.",
        "start": 3026.599,
        "duration": 3.871
    },
    {
        "text": "So I think that there are some very, very\ndifficult balances that we need to strike",
        "start": 3030.47,
        "duration": 4.639
    },
    {
        "text": "in order to ensure that we protect our democracy,\nwe protect our privacy, we protect our ability",
        "start": 3035.109,
        "duration": 4.711
    },
    {
        "text": "to speak freely.",
        "start": 3039.82,
        "duration": 1.18
    },
    {
        "text": "All of these things are in the balance and\nthere's a lot of values that are in tension.",
        "start": 3041.0,
        "duration": 3.4
    },
    {
        "text": "So you've set up the big question then, we\nare now going to I guess move to the inevitable,",
        "start": 3044.4,
        "duration": 6.31
    },
    {
        "text": "hopeful side of this, if we can find one.",
        "start": 3050.71,
        "duration": 4.0
    },
    {
        "text": "What are the fixes?",
        "start": 3054.71,
        "duration": 1.0
    },
    {
        "text": "What are we to do?",
        "start": 3055.71,
        "duration": 1.0
    },
    {
        "text": "Tim, how can we make this AI more ethical?",
        "start": 3056.71,
        "duration": 3.9
    },
    {
        "text": "Sure, so one of the things I think about particularly\nrelated to this discussion is the delegation",
        "start": 3060.61,
        "duration": 6.34
    },
    {
        "text": "question that I mentioned a little while back,\nwhich is that particularly after 2016 we're",
        "start": 3066.95,
        "duration": 3.98
    },
    {
        "text": "kind of in this tough spot where we're basically\nlike companies just solve the problem.",
        "start": 3070.93,
        "duration": 3.47
    },
    {
        "text": "Well, we feel really uncomfortable about Facebook\ntelling us what's true or not.",
        "start": 3074.4,
        "duration": 2.81
    },
    {
        "text": "All right, well, then let's pass a law.",
        "start": 3077.21,
        "duration": 1.43
    },
    {
        "text": "Then you're like, \"Oh, we don't actually want\ngovernment to tell us what's true or not.\"",
        "start": 3078.64,
        "duration": 2.425
    },
    {
        "text": "So there's actually this moment of we have\nto delegate to these two wolves, where both",
        "start": 3081.065,
        "duration": 4.885
    },
    {
        "text": "of them we feel actually pretty uncomfortable\nworking with them on issues of truth, for",
        "start": 3085.95,
        "duration": 4.78
    },
    {
        "text": "instance.",
        "start": 3090.73,
        "duration": 1.0
    },
    {
        "text": "It seems, particularly after 2016, there's\na general implosion I think in our faith around",
        "start": 3091.73,
        "duration": 7.17
    },
    {
        "text": "the ability for communities to self-organize\nand deal with some of these problems themselves.",
        "start": 3098.9,
        "duration": 6.42
    },
    {
        "text": "I think there is good intellectual work to\nbe done in terms of trying to figure out how",
        "start": 3105.32,
        "duration": 3.81
    },
    {
        "text": "platforms can make those things more robust.",
        "start": 3109.13,
        "duration": 3.65
    },
    {
        "text": "Right.",
        "start": 3112.78,
        "duration": 1.0
    },
    {
        "text": "Aviv, I see you nodding a great deal.",
        "start": 3113.78,
        "duration": 3.73
    },
    {
        "text": "We're hearing also every week from the platforms\nthat are stepping up.",
        "start": 3117.51,
        "duration": 3.28
    },
    {
        "text": "Twitter says it's going to limit tweets from\npeople behaving badly, and Facebook has just",
        "start": 3120.79,
        "duration": 4.519
    },
    {
        "text": "detailed policing for sex, terror, and hate\ncontent.",
        "start": 3125.309,
        "duration": 3.041
    },
    {
        "text": "Do you think they're going far enough?",
        "start": 3128.35,
        "duration": 3.269
    },
    {
        "text": "I think there's a number of steps that are\nin the right direction, and there's going",
        "start": 3131.619,
        "duration": 2.595
    },
    {
        "text": "to be some steps that backtrack as we learn\nmore and as we discover that, oh, wait, this",
        "start": 3134.214,
        "duration": 4.376
    },
    {
        "text": "isn't exactly what we wanted.",
        "start": 3138.59,
        "duration": 1.13
    },
    {
        "text": "I think that's part of this process.",
        "start": 3139.72,
        "duration": 2.17
    },
    {
        "text": "I'm happy that we're actually on this process\nas opposed to just ignoring it, which was",
        "start": 3141.89,
        "duration": 4.59
    },
    {
        "text": "sort of the status quo two years ago when\nthey said fake news is a 2016 problem that's",
        "start": 3146.48,
        "duration": 6.43
    },
    {
        "text": "in the US.",
        "start": 3152.91,
        "duration": 1.23
    },
    {
        "text": "A lot of the rest of the world has been dealing\nwith misinformation that's very deeply affecting",
        "start": 3154.14,
        "duration": 4.92
    },
    {
        "text": "their political systems for five, ten years\neven.",
        "start": 3159.06,
        "duration": 4.32
    },
    {
        "text": "I think that there are some things that really\ndo need to happen, and they're starting to",
        "start": 3163.38,
        "duration": 4.8
    },
    {
        "text": "happen within these organizations.",
        "start": 3168.18,
        "duration": 2.429
    },
    {
        "text": "In particular, we need to have empowered teams\nthat can look at the impacts of the technologies",
        "start": 3170.609,
        "duration": 9.401
    },
    {
        "text": "on these things that we care about, on let's\nsay our democracy, on inter-community trust",
        "start": 3180.01,
        "duration": 5.599
    },
    {
        "text": "so that you're not just increasing polarization.",
        "start": 3185.609,
        "duration": 2.371
    },
    {
        "text": "If you don't have someone who's paid to ensure\nthat your platform isn't deeply polarizing",
        "start": 3187.98,
        "duration": 4.47
    },
    {
        "text": "things, well, then your growth team that's\ntrying to get more users and trying to get",
        "start": 3192.45,
        "duration": 3.26
    },
    {
        "text": "more action might unintentionally just do\nthat.",
        "start": 3195.71,
        "duration": 2.52
    },
    {
        "text": "There has to be that back and forth, and they\nhave to be empowered enough to push back.",
        "start": 3198.23,
        "duration": 3.51
    },
    {
        "text": "Just fascinating possible solution to some\nof it, empowered by whom?",
        "start": 3201.74,
        "duration": 6.06
    },
    {
        "text": "Well, both within the organization and ideally\nwith some sort of external accountability",
        "start": 3207.8,
        "duration": 4.83
    },
    {
        "text": "where across these organizations.",
        "start": 3212.63,
        "duration": 2.6
    },
    {
        "text": "There's a number of different structures,\nbut the idea is that you not only have some",
        "start": 3215.23,
        "duration": 4.66
    },
    {
        "text": "sort of internal structure that's keeping\nan eye on this with people who their job responsibility",
        "start": 3219.89,
        "duration": 5.54
    },
    {
        "text": "is to maintain some of these things that we\nhear about, but you also have outside of the",
        "start": 3225.43,
        "duration": 5.95
    },
    {
        "text": "company, some way in which you're able to\nsee, oh, is that company doing a good job",
        "start": 3231.38,
        "duration": 3.689
    },
    {
        "text": "with this?",
        "start": 3235.069,
        "duration": 1.26
    },
    {
        "text": "Whether that's through a regulatory process,\nmaybe, maybe not, but I think there has to",
        "start": 3236.329,
        "duration": 5.561
    },
    {
        "text": "be some structure that creates those power\ndynamics.",
        "start": 3241.89,
        "duration": 2.66
    },
    {
        "text": "So an independent idealistic new profession\nthat we need to live in this new world?",
        "start": 3244.55,
        "duration": 5.59
    },
    {
        "text": "I mean, I don't know that it's new.",
        "start": 3250.14,
        "duration": 2.43
    },
    {
        "text": "Social scientists have been doing this sort\nof work for a million years.",
        "start": 3252.57,
        "duration": 3.83
    },
    {
        "text": "Maybe not a million, don't quote me on that.",
        "start": 3256.4,
        "duration": 3.12
    },
    {
        "text": "Maybe, I don't know.",
        "start": 3259.52,
        "duration": 2.64
    },
    {
        "text": "It feels like it.",
        "start": 3262.16,
        "duration": 2.649
    },
    {
        "text": "But I think the combination of people looking\nat how the technology is impacting society",
        "start": 3264.809,
        "duration": 8.371
    },
    {
        "text": "and really cross-functionally and having teams\nthat are doing that and that is their focus,",
        "start": 3273.18,
        "duration": 5.659
    },
    {
        "text": "to understand the way these platforms are\nimpacting things.",
        "start": 3278.839,
        "duration": 2.571
    },
    {
        "text": "I think even beyond that when you're talking\nabout something like these deep fakes, that's",
        "start": 3281.41,
        "duration": 5.169
    },
    {
        "text": "about not just stuff that's happening in these\ncompanies, in these platforms, but it's happening",
        "start": 3286.579,
        "duration": 7.181
    },
    {
        "text": "in research labs where you have researchers\nwho are just like, \"Oh, wouldn't this be cool?",
        "start": 3293.76,
        "duration": 4.279
    },
    {
        "text": "Oh, I can get a good paper out of this.\"",
        "start": 3298.039,
        "duration": 1.74
    },
    {
        "text": "That's great, I love good papers, I love cool\nthings.",
        "start": 3299.779,
        "duration": 5.79
    },
    {
        "text": "But it doesn't mean that you shouldn't be\nlooking at what are the potential negative",
        "start": 3305.569,
        "duration": 4.361
    },
    {
        "text": "impacts, and one thing that I've been really\nexcited to see is people within the academic",
        "start": 3309.93,
        "duration": 5.27
    },
    {
        "text": "community starting to really think about this\ndeeply.",
        "start": 3315.2,
        "duration": 2.02
    },
    {
        "text": "There's actually as of a few days ago, if\nyou go to negative impacts.org, there's this",
        "start": 3317.22,
        "duration": 8.04
    },
    {
        "text": "group, the ACM Computing of the Future, something\nalong those lines, where they're looking at",
        "start": 3325.26,
        "duration": 11.41
    },
    {
        "text": "the ways in which we can improve the purity\nof process to really incorporate not just",
        "start": 3336.67,
        "duration": 3.5
    },
    {
        "text": "the positive impacts of a technology, but\nalso keeping in mind the negative impacts.",
        "start": 3340.17,
        "duration": 3.52
    },
    {
        "text": "All right, we have just a couple of minutes\nleft, so your thoughts about where we're headed",
        "start": 3343.69,
        "duration": 4.95
    },
    {
        "text": "if we don't get ...\nWe're clearly headed to climate crisis, we're",
        "start": 3348.64,
        "duration": 5.82
    },
    {
        "text": "clearly headed to a lot of really serious\nissues that relate to this and don't relate",
        "start": 3354.46,
        "duration": 4.43
    },
    {
        "text": "to this.",
        "start": 3358.89,
        "duration": 1.0
    },
    {
        "text": "But I want to backup a little and make space\nfor the question, what world do we actually",
        "start": 3359.89,
        "duration": 4.6
    },
    {
        "text": "want?",
        "start": 3364.49,
        "duration": 1.54
    },
    {
        "text": "Do we want Facebook to be negotiating with\nthe US government to determine truthiness,",
        "start": 3366.03,
        "duration": 7.309
    },
    {
        "text": "or do we want Facebook?",
        "start": 3373.339,
        "duration": 3.041
    },
    {
        "text": "Do we want capitalism?",
        "start": 3376.38,
        "duration": 2.33
    },
    {
        "text": "What do we want this to be?",
        "start": 3378.71,
        "duration": 2.079
    },
    {
        "text": "Then think about what types of technologies\ncould you build or avoid building to create",
        "start": 3380.789,
        "duration": 5.78
    },
    {
        "text": "that?",
        "start": 3386.569,
        "duration": 1.0
    },
    {
        "text": "Because I think we fall into the trap of accepting\nthe status quo and then trying to tweak it",
        "start": 3387.569,
        "duration": 4.28
    },
    {
        "text": "around the edges.",
        "start": 3391.849,
        "duration": 1.091
    },
    {
        "text": "It's very clear that that's not at this point\nworking and that a number of the major social",
        "start": 3392.94,
        "duration": 5.52
    },
    {
        "text": "problems we're facing are enmeshed deeply\nwith the major technological issues and they",
        "start": 3398.46,
        "duration": 4.971
    },
    {
        "text": "are being exacerbated in ways that are very\ncomplex to tease apart from a systems perspective.",
        "start": 3403.431,
        "duration": 5.989
    },
    {
        "text": "So I would want to start with the imaginative\npotential of how do we create a better world?",
        "start": 3409.42,
        "duration": 5.57
    },
    {
        "text": "And then see do we want these bulwarks of\npower in this world in that world we have",
        "start": 3414.99,
        "duration": 5.52
    },
    {
        "text": "yet to create?",
        "start": 3420.51,
        "duration": 1.0
    },
    {
        "text": "Okay, and the last word, sorry to interrupt,\nbut we have just one.",
        "start": 3421.51,
        "duration": 1.0
    },
    {
        "text": "Where are we headed if we don't fix it?",
        "start": 3422.51,
        "duration": 1.269
    },
    {
        "text": "I think we're heading to science fiction dystopia\nwhere more and more of our lives are predicted",
        "start": 3423.779,
        "duration": 8.961
    },
    {
        "text": "and determined by technological systems controlled\nby a few.",
        "start": 3432.74,
        "duration": 4.66
    },
    {
        "text": "How we avoid that?",
        "start": 3437.4,
        "duration": 2.409
    },
    {
        "text": "The constitutional, the most fundamental issue\nfor us to confront in the 21st century is",
        "start": 3439.809,
        "duration": 4.56
    },
    {
        "text": "how to sustain our freedom to be off so that\nwe're not always on.",
        "start": 3444.369,
        "duration": 4.771
    },
    {
        "text": "How to build techno social environments through\ntechnology and social institutions that preserve",
        "start": 3449.14,
        "duration": 5.5
    },
    {
        "text": "under determinate environments within which\nwe can develop, play, experiment, interact",
        "start": 3454.64,
        "duration": 5.78
    },
    {
        "text": "with each other, in ways that allow us to\ndevelop our own lives rather than have them",
        "start": 3460.42,
        "duration": 3.879
    },
    {
        "text": "determined for us.",
        "start": 3464.299,
        "duration": 1.161
    },
    {
        "text": "It sounds like something for the lawyers,\nthe politicians, and everybody to get involved",
        "start": 3465.46,
        "duration": 3.71
    },
    {
        "text": "with, including you nerds who have given us\nall this stuff.",
        "start": 3469.17,
        "duration": 3.72
    },
    {
        "text": "Let's give it a round of applause.",
        "start": 3472.89,
        "duration": 3.389
    },
    {
        "text": "Thank you for sharing.",
        "start": 3476.279,
        "duration": 6.971
    }
]