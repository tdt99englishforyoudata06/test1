[
    {
        "text": "you may have been seeing some cool but",
        "start": 9.9,
        "duration": 4.6
    },
    {
        "text": "mildly disturbing pictures on the",
        "start": 12.58,
        "duration": 2.7
    },
    {
        "text": "internet recently",
        "start": 14.5,
        "duration": 2.009
    },
    {
        "text": "I mean pictures that are more disturbing",
        "start": 15.28,
        "duration": 2.76
    },
    {
        "text": "than usual and in a different way from",
        "start": 16.509,
        "duration": 3.541
    },
    {
        "text": "like that fish with people teeth the",
        "start": 18.04,
        "duration": 3.48
    },
    {
        "text": "images are part of a product that Google",
        "start": 20.05,
        "duration": 3.899
    },
    {
        "text": "is calling deep dream as in Inception",
        "start": 21.52,
        "duration": 5.22
    },
    {
        "text": "style digital daydreams it is actually",
        "start": 23.949,
        "duration": 4.41
    },
    {
        "text": "not too far from what they really are",
        "start": 26.74,
        "duration": 3.869
    },
    {
        "text": "because when you teach computers how to",
        "start": 28.359,
        "duration": 4.711
    },
    {
        "text": "recognize images and then ask them to",
        "start": 30.609,
        "duration": 5.251
    },
    {
        "text": "produce their own apparently this is",
        "start": 33.07,
        "duration": 4.89
    },
    {
        "text": "what you come up with deep dream is the",
        "start": 35.86,
        "duration": 3.81
    },
    {
        "text": "latest step towards solving a problem",
        "start": 37.96,
        "duration": 3.089
    },
    {
        "text": "that researchers have been dealing with",
        "start": 39.67,
        "duration": 4.44
    },
    {
        "text": "since the 1960s how to get a computer to",
        "start": 41.049,
        "duration": 5.671
    },
    {
        "text": "recognize objects in an image and so far",
        "start": 44.11,
        "duration": 4.35
    },
    {
        "text": "the best way seems to involve using",
        "start": 46.72,
        "duration": 3.75
    },
    {
        "text": "neural networks a form of artificial",
        "start": 48.46,
        "duration": 3.72
    },
    {
        "text": "intelligence where you link up a bunch",
        "start": 50.47,
        "duration": 3.96
    },
    {
        "text": "of individual processing units or nodes",
        "start": 52.18,
        "duration": 4.619
    },
    {
        "text": "and have them work together usually the",
        "start": 54.43,
        "duration": 4.229
    },
    {
        "text": "nodes are organized into interconnected",
        "start": 56.799,
        "duration": 3.991
    },
    {
        "text": "layers you start out with some input say",
        "start": 58.659,
        "duration": 4.351
    },
    {
        "text": "an image and each layer of nodes is",
        "start": 60.79,
        "duration": 3.93
    },
    {
        "text": "designed to modify that image in a",
        "start": 63.01,
        "duration": 3.24
    },
    {
        "text": "particular way by adjusting the",
        "start": 64.72,
        "duration": 3.87
    },
    {
        "text": "parameters or rules for each node you",
        "start": 66.25,
        "duration": 3.87
    },
    {
        "text": "change what it does but what makes",
        "start": 68.59,
        "duration": 2.79
    },
    {
        "text": "neural networks really powerful",
        "start": 70.12,
        "duration": 2.79
    },
    {
        "text": "especially for image recognition is that",
        "start": 71.38,
        "duration": 3.48
    },
    {
        "text": "you can train them which is how Google",
        "start": 72.91,
        "duration": 3.93
    },
    {
        "text": "developed a deep dream first computer",
        "start": 74.86,
        "duration": 4.08
    },
    {
        "text": "scientists took a database of 1.2",
        "start": 76.84,
        "duration": 4.08
    },
    {
        "text": "million images and classified every",
        "start": 78.94,
        "duration": 4.41
    },
    {
        "text": "single one according to about a thousand",
        "start": 80.92,
        "duration": 5.01
    },
    {
        "text": "categories like bird or building and as",
        "start": 83.35,
        "duration": 3.96
    },
    {
        "text": "you probably can imagine that was a",
        "start": 85.93,
        "duration": 3.69
    },
    {
        "text": "pretty big project all by itself then to",
        "start": 87.31,
        "duration": 3.6
    },
    {
        "text": "train the network they fed it those",
        "start": 89.62,
        "duration": 4.23
    },
    {
        "text": "images and asked it to classify them so",
        "start": 90.91,
        "duration": 4.44
    },
    {
        "text": "let's say one of the inputs was a",
        "start": 93.85,
        "duration": 3.059
    },
    {
        "text": "picture of a dog if the network said",
        "start": 95.35,
        "duration": 3.33
    },
    {
        "text": "that it was a dog then great had moved",
        "start": 96.909,
        "duration": 3.211
    },
    {
        "text": "to the next image but if it didn't know",
        "start": 98.68,
        "duration": 2.82
    },
    {
        "text": "what it was or it came up with the wrong",
        "start": 100.12,
        "duration": 3.36
    },
    {
        "text": "category then researchers changed the",
        "start": 101.5,
        "duration": 3.96
    },
    {
        "text": "parameters of different nodes until it",
        "start": 103.48,
        "duration": 4.02
    },
    {
        "text": "did identify the image as a dog it's",
        "start": 105.46,
        "duration": 3.84
    },
    {
        "text": "like the network was learning oh the",
        "start": 107.5,
        "duration": 3.54
    },
    {
        "text": "arrangement of pixels in this picture of",
        "start": 109.3,
        "duration": 3.51
    },
    {
        "text": "a chihuahua is a dog and this",
        "start": 111.04,
        "duration": 3.09
    },
    {
        "text": "arrangement and a picture of a st.",
        "start": 112.81,
        "duration": 3.36
    },
    {
        "text": "Bernard is also a dog the process of",
        "start": 114.13,
        "duration": 3.57
    },
    {
        "text": "teaching neural networks to classify",
        "start": 116.17,
        "duration": 3.69
    },
    {
        "text": "images isn't exactly new but the",
        "start": 117.7,
        "duration": 3.75
    },
    {
        "text": "specific architecture of the network",
        "start": 119.86,
        "duration": 4.02
    },
    {
        "text": "used for deep dream is new and once they",
        "start": 121.45,
        "duration": 4.44
    },
    {
        "text": "were done training it the team wanted to",
        "start": 123.88,
        "duration": 3.75
    },
    {
        "text": "test it out especially wanted to see",
        "start": 125.89,
        "duration": 3.599
    },
    {
        "text": "what qualities the network used to",
        "start": 127.63,
        "duration": 3.96
    },
    {
        "text": "distinguish between one category and",
        "start": 129.489,
        "duration": 3.901
    },
    {
        "text": "another so they fed the network's image",
        "start": 131.59,
        "duration": 3.39
    },
    {
        "text": "isn't asked it to find certain other",
        "start": 133.39,
        "duration": 2.5
    },
    {
        "text": "images",
        "start": 134.98,
        "duration": 2.589
    },
    {
        "text": "I'm using what it thought the defining",
        "start": 135.89,
        "duration": 3.48
    },
    {
        "text": "characteristics of that category would",
        "start": 137.569,
        "duration": 3.601
    },
    {
        "text": "be so say they gave deep dream a picture",
        "start": 139.37,
        "duration": 3.57
    },
    {
        "text": "that had nothing to do with dogs and",
        "start": 141.17,
        "duration": 4.5
    },
    {
        "text": "then told it to find dogs in there to do",
        "start": 142.94,
        "duration": 3.99
    },
    {
        "text": "that it would use a process that",
        "start": 145.67,
        "duration": 3.149
    },
    {
        "text": "developers likened to daydreaming the",
        "start": 146.93,
        "duration": 3.389
    },
    {
        "text": "way you look up at clouds and find",
        "start": 148.819,
        "duration": 3.331
    },
    {
        "text": "shapes of animals in them but deep dream",
        "start": 150.319,
        "duration": 3.721
    },
    {
        "text": "would actually modify the original image",
        "start": 152.15,
        "duration": 3.57
    },
    {
        "text": "highlighting the patterns that it found",
        "start": 154.04,
        "duration": 3.33
    },
    {
        "text": "to fit the category this allowed the",
        "start": 155.72,
        "duration": 3.06
    },
    {
        "text": "developers to actually see what each",
        "start": 157.37,
        "duration": 3.48
    },
    {
        "text": "individual layer was doing to the image",
        "start": 158.78,
        "duration": 3.84
    },
    {
        "text": "whether it was just enhancing certain",
        "start": 160.85,
        "duration": 3.6
    },
    {
        "text": "lines or if it was adding more specific",
        "start": 162.62,
        "duration": 3.6
    },
    {
        "text": "details and in the process it showed the",
        "start": 164.45,
        "duration": 3.24
    },
    {
        "text": "researchers how deep dream defined",
        "start": 166.22,
        "duration": 4.29
    },
    {
        "text": "categories like dog in its digital brain",
        "start": 167.69,
        "duration": 4.68
    },
    {
        "text": "but the fan was the first layer of the",
        "start": 170.51,
        "duration": 3.479
    },
    {
        "text": "network looked for hints of anything",
        "start": 172.37,
        "duration": 3.6
    },
    {
        "text": "that might be a dog just a vague outline",
        "start": 173.989,
        "duration": 4.081
    },
    {
        "text": "or some edges of a shape in reality the",
        "start": 175.97,
        "duration": 3.42
    },
    {
        "text": "curve of what the network thought was a",
        "start": 178.07,
        "duration": 4.199
    },
    {
        "text": "dog's nose might be a human foot but it",
        "start": 179.39,
        "duration": 5.069
    },
    {
        "text": "enhanced that edge anyway and sent the",
        "start": 182.269,
        "duration": 3.631
    },
    {
        "text": "new image off to the next layer for",
        "start": 184.459,
        "duration": 2.971
    },
    {
        "text": "processing then the next layer took",
        "start": 185.9,
        "duration": 3.24
    },
    {
        "text": "those edges and started to fill them in",
        "start": 187.43,
        "duration": 3.63
    },
    {
        "text": "looking for more details that it might",
        "start": 189.14,
        "duration": 3.72
    },
    {
        "text": "be able to interpret as part of a dog",
        "start": 191.06,
        "duration": 3.99
    },
    {
        "text": "and then enhance them and then sent that",
        "start": 192.86,
        "duration": 3.84
    },
    {
        "text": "picture onto the next layer and so on",
        "start": 195.05,
        "duration": 3.54
    },
    {
        "text": "using the system the network was able to",
        "start": 196.7,
        "duration": 4.11
    },
    {
        "text": "turn even a screen full of random static",
        "start": 198.59,
        "duration": 4.26
    },
    {
        "text": "into a picture of bananas now the",
        "start": 200.81,
        "duration": 3.69
    },
    {
        "text": "database happened to have more pictures",
        "start": 202.85,
        "duration": 3.72
    },
    {
        "text": "in some categories than in others which",
        "start": 204.5,
        "duration": 3.9
    },
    {
        "text": "is why you see a lot of things like dogs",
        "start": 206.57,
        "duration": 4.53
    },
    {
        "text": "and eyes and the final deep dream images",
        "start": 208.4,
        "duration": 4.649
    },
    {
        "text": "but beyond just creating trippy pictures",
        "start": 211.1,
        "duration": 3.96
    },
    {
        "text": "the results are useful insights into how",
        "start": 213.049,
        "duration": 3.78
    },
    {
        "text": "the network for lack of a better word",
        "start": 215.06,
        "duration": 3.54
    },
    {
        "text": "thinks for example the researchers",
        "start": 216.829,
        "duration": 3.241
    },
    {
        "text": "noticed that when they asked the network",
        "start": 218.6,
        "duration": 3.21
    },
    {
        "text": "to come up with pictures of dumbbells",
        "start": 220.07,
        "duration": 4.65
    },
    {
        "text": "it also included disembodied human hands",
        "start": 221.81,
        "duration": 4.649
    },
    {
        "text": "grasping the dumbbells that's when they",
        "start": 224.72,
        "duration": 2.85
    },
    {
        "text": "realize that they should probably train",
        "start": 226.459,
        "duration": 2.31
    },
    {
        "text": "it with some pictures of dumbbells",
        "start": 227.57,
        "duration": 3.06
    },
    {
        "text": "without people holding them so these",
        "start": 228.769,
        "duration": 3.451
    },
    {
        "text": "robot dreams are more than just pretty",
        "start": 230.63,
        "duration": 3.21
    },
    {
        "text": "or creepy there are also valuable",
        "start": 232.22,
        "duration": 3.45
    },
    {
        "text": "research tools as scientists teach",
        "start": 233.84,
        "duration": 3.39
    },
    {
        "text": "computers to be better at recognizing",
        "start": 235.67,
        "duration": 3.72
    },
    {
        "text": "objects and images and if you want to",
        "start": 237.23,
        "duration": 3.93
    },
    {
        "text": "generate your own deep dream pictures",
        "start": 239.39,
        "duration": 4.08
    },
    {
        "text": "you can Google just released some of the",
        "start": 241.16,
        "duration": 4.169
    },
    {
        "text": "code and you can install a simulated",
        "start": 243.47,
        "duration": 3.72
    },
    {
        "text": "version of the network on your computer",
        "start": 245.329,
        "duration": 3.271
    },
    {
        "text": "there are links to instructions in the",
        "start": 247.19,
        "duration": 3.09
    },
    {
        "text": "description below we are interested to",
        "start": 248.6,
        "duration": 3.3
    },
    {
        "text": "see what you come up with so tweet us",
        "start": 250.28,
        "duration": 2.94
    },
    {
        "text": "with your pictures thanks for watching",
        "start": 251.9,
        "duration": 2.91
    },
    {
        "text": "this episode of scishow news and thanks",
        "start": 253.22,
        "duration": 3.359
    },
    {
        "text": "especially to our patrons on patreon who",
        "start": 254.81,
        "duration": 3.54
    },
    {
        "text": "make this channel possible if you want",
        "start": 256.579,
        "duration": 3.541
    },
    {
        "text": "to help us keep making this show and get",
        "start": 258.35,
        "duration": 2.759
    },
    {
        "text": "some cool stuff you can go to",
        "start": 260.12,
        "duration": 3.66
    },
    {
        "text": "patreon.com/scishow and if you want to",
        "start": 261.109,
        "duration": 4.521
    },
    {
        "text": "keep getting smarter with us just go to",
        "start": 263.78,
        "duration": 4.01
    },
    {
        "text": "youtube.com/scishow and subscribe",
        "start": 265.63,
        "duration": 4.22
    },
    {
        "text": "you",
        "start": 267.79,
        "duration": 2.06
    },
    {
        "text": "you",
        "start": 272.34,
        "duration": 2.06
    }
]